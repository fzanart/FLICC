{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.realpath(\"__file__\").split('grid_search')[0]\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint='roberta-large'\n",
    "\n",
    "# the commands below didn't work inside for loop and got CUDA out of memory Error.\n",
    "#     with torch.no_grad():\n",
    "#        torch.cuda.empty_cache()\n",
    "#    del data, model, trainer, acc, f1\n",
    "# Instead of running these commands in a loop, execute them cell by cell, restarting between them.\n",
    "# Each cell will print its results. To keep the results and avoid re-running specific cells, skip them intermittently on each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'lr':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = [2,4,8,16]\n",
    "lr = 1.0e-5\n",
    "\n",
    "for g in gamma:\n",
    "    print(f'Grid search {model_checkpoint}, learning rate {lr}, focal loss gamma {g}')\n",
    "    data = ClimateDataset(model_to_train=1,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=32)\n",
    "    data.setup_dataloaders()\n",
    "    model = ClassificationModel(model_checkpoint=data.model_checkpoint,num_labels=data.num_labels)\n",
    "    trainer = Engine(epochs=30,labels=data.labels)\n",
    "    trainer.model = model.model\n",
    "    trainer.device = model.device\n",
    "    test_acc, test_f1, eval_acc, eval_f1 = trainer.run(lr=lr,\n",
    "                                                       wd=0.0,\n",
    "                                                       train_dataloader=data.train_dataloader,\n",
    "                                                       eval_dataloader=data.eval_dataloader,\n",
    "                                                       test_dataloader=data.test_dataloader,\n",
    "                                                       focalloss=True,\n",
    "                                                       gamma=g,\n",
    "                                                       early_stop=3)\n",
    "    results['test_acc'].append(test_acc)\n",
    "    results['test_f1'].append(test_f1)\n",
    "    results['eval_acc'].append(eval_acc)\n",
    "    results['eval_f1'].append(eval_f1)\n",
    "    results['g'].append(g)\n",
    "    print('### '*10)\n",
    "    print(results)\n",
    "    print('### '*10)\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    del data, model, trainer, test_acc, test_f1, eval_acc, eval_f1\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Engine.plot_grid_search(df=results,\n",
    "                        title=f'Learning rates {model_checkpoint}',\n",
    "                        column='lr',\n",
    "                        sci_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
