{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/software/'\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.realpath(\"__file__\").split('grid_search')[0]\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint='EleutherAI/gpt-neo-1.3B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'lr':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65239eb271614d52b6a3a7417deb753f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28983b50955d457b871350896312630f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e967894395734b6aa77203f380b3ea53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac5341a134f4f838c4571e6fbbee355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1324 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c83d0f63f24bfea6a3e398b0746532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5742440a053644a19ffcc1018515d179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.8826\tVal Loss:\t3.1377\tAccuracy:\t0.1657\tF1:\t0.1015\tTest Accuracy:\t0.1534\tTest F1:\t0.1125 *\n",
      "2 / 30: Train Loss:\t0.7742\tVal Loss:\t2.8095\tAccuracy:\t0.1775\tF1:\t0.1152\tTest Accuracy:\t0.1746\tTest F1:\t0.1173 *\n",
      "3 / 30: Train Loss:\t0.6834\tVal Loss:\t2.5230\tAccuracy:\t0.2012\tF1:\t0.1370\tTest Accuracy:\t0.1905\tTest F1:\t0.1427 *\n",
      "4 / 30: Train Loss:\t0.6270\tVal Loss:\t2.3851\tAccuracy:\t0.1893\tF1:\t0.1325\tTest Accuracy:\t0.2169\tTest F1:\t0.1602\n",
      "5 / 30: Train Loss:\t0.6002\tVal Loss:\t2.2996\tAccuracy:\t0.2249\tF1:\t0.1556\tTest Accuracy:\t0.2222\tTest F1:\t0.1532 *\n",
      "6 / 30: Train Loss:\t0.5833\tVal Loss:\t2.2362\tAccuracy:\t0.2396\tF1:\t0.1678\tTest Accuracy:\t0.2328\tTest F1:\t0.1508 *\n",
      "7 / 30: Train Loss:\t0.5671\tVal Loss:\t2.2425\tAccuracy:\t0.2308\tF1:\t0.1599\tTest Accuracy:\t0.2275\tTest F1:\t0.1563\n",
      "8 / 30: Train Loss:\t0.5546\tVal Loss:\t2.1833\tAccuracy:\t0.2367\tF1:\t0.1653\tTest Accuracy:\t0.2646\tTest F1:\t0.1803\n",
      "9 / 30: Train Loss:\t0.5413\tVal Loss:\t2.1307\tAccuracy:\t0.2515\tF1:\t0.1821\tTest Accuracy:\t0.2328\tTest F1:\t0.1770 *\n",
      "10 / 30: Train Loss:\t0.5296\tVal Loss:\t2.1059\tAccuracy:\t0.2604\tF1:\t0.1978\tTest Accuracy:\t0.2593\tTest F1:\t0.1757 *\n",
      "11 / 30: Train Loss:\t0.5161\tVal Loss:\t2.0648\tAccuracy:\t0.2544\tF1:\t0.1951\tTest Accuracy:\t0.2593\tTest F1:\t0.1739\n",
      "12 / 30: Train Loss:\t0.5056\tVal Loss:\t1.9857\tAccuracy:\t0.2840\tF1:\t0.2141\tTest Accuracy:\t0.2857\tTest F1:\t0.1980 *\n",
      "13 / 30: Train Loss:\t0.4939\tVal Loss:\t1.9856\tAccuracy:\t0.2899\tF1:\t0.2234\tTest Accuracy:\t0.2751\tTest F1:\t0.1851 *\n",
      "14 / 30: Train Loss:\t0.4830\tVal Loss:\t1.9245\tAccuracy:\t0.3107\tF1:\t0.2260\tTest Accuracy:\t0.3228\tTest F1:\t0.2236 *\n",
      "15 / 30: Train Loss:\t0.4700\tVal Loss:\t1.9157\tAccuracy:\t0.3047\tF1:\t0.2216\tTest Accuracy:\t0.3175\tTest F1:\t0.2147\n",
      "16 / 30: Train Loss:\t0.4581\tVal Loss:\t1.9082\tAccuracy:\t0.3077\tF1:\t0.2369\tTest Accuracy:\t0.3228\tTest F1:\t0.2257 *\n",
      "17 / 30: Train Loss:\t0.4500\tVal Loss:\t1.8801\tAccuracy:\t0.3343\tF1:\t0.2598\tTest Accuracy:\t0.3492\tTest F1:\t0.2465 *\n",
      "18 / 30: Train Loss:\t0.4376\tVal Loss:\t1.8522\tAccuracy:\t0.3136\tF1:\t0.2399\tTest Accuracy:\t0.3598\tTest F1:\t0.2700\n",
      "19 / 30: Train Loss:\t0.4282\tVal Loss:\t1.8047\tAccuracy:\t0.3402\tF1:\t0.2616\tTest Accuracy:\t0.3545\tTest F1:\t0.2658 *\n",
      "20 / 30: Train Loss:\t0.4183\tVal Loss:\t1.7953\tAccuracy:\t0.3284\tF1:\t0.2561\tTest Accuracy:\t0.3545\tTest F1:\t0.2644\n",
      "21 / 30: Train Loss:\t0.4120\tVal Loss:\t1.7472\tAccuracy:\t0.3432\tF1:\t0.2788\tTest Accuracy:\t0.3651\tTest F1:\t0.2699 *\n",
      "22 / 30: Train Loss:\t0.4002\tVal Loss:\t1.7318\tAccuracy:\t0.3521\tF1:\t0.2733\tTest Accuracy:\t0.4021\tTest F1:\t0.2835\n",
      "23 / 30: Train Loss:\t0.3890\tVal Loss:\t1.7388\tAccuracy:\t0.3550\tF1:\t0.2733\tTest Accuracy:\t0.3862\tTest F1:\t0.2768\n",
      "24 / 30: Train Loss:\t0.3812\tVal Loss:\t1.6966\tAccuracy:\t0.3550\tF1:\t0.2888\tTest Accuracy:\t0.3651\tTest F1:\t0.2746 *\n",
      "25 / 30: Train Loss:\t0.3752\tVal Loss:\t1.6634\tAccuracy:\t0.3935\tF1:\t0.3094\tTest Accuracy:\t0.3915\tTest F1:\t0.2774 *\n",
      "26 / 30: Train Loss:\t0.3650\tVal Loss:\t1.6464\tAccuracy:\t0.4142\tF1:\t0.3290\tTest Accuracy:\t0.3915\tTest F1:\t0.2968 *\n",
      "27 / 30: Train Loss:\t0.3564\tVal Loss:\t1.6407\tAccuracy:\t0.4024\tF1:\t0.3210\tTest Accuracy:\t0.4021\tTest F1:\t0.2827\n",
      "28 / 30: Train Loss:\t0.3425\tVal Loss:\t1.5961\tAccuracy:\t0.4231\tF1:\t0.3361\tTest Accuracy:\t0.3810\tTest F1:\t0.2946 *\n",
      "29 / 30: Train Loss:\t0.3379\tVal Loss:\t1.5850\tAccuracy:\t0.4438\tF1:\t0.3553\tTest Accuracy:\t0.3968\tTest F1:\t0.2875 *\n",
      "30 / 30: Train Loss:\t0.3295\tVal Loss:\t1.5519\tAccuracy:\t0.4556\tF1:\t0.3859\tTest Accuracy:\t0.4180\tTest F1:\t0.3210 *\n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90db1ed7a2a941d6a34c2ebccfe1d30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.7248\tVal Loss:\t2.3298\tAccuracy:\t0.1982\tF1:\t0.1524\tTest Accuracy:\t0.2328\tTest F1:\t0.1583 *\n",
      "2 / 30: Train Loss:\t0.5660\tVal Loss:\t2.1201\tAccuracy:\t0.2426\tF1:\t0.1684\tTest Accuracy:\t0.2646\tTest F1:\t0.1795 *\n",
      "3 / 30: Train Loss:\t0.5093\tVal Loss:\t1.9620\tAccuracy:\t0.2840\tF1:\t0.1964\tTest Accuracy:\t0.3016\tTest F1:\t0.2023 *\n",
      "4 / 30: Train Loss:\t0.4554\tVal Loss:\t1.8250\tAccuracy:\t0.3402\tF1:\t0.2744\tTest Accuracy:\t0.3333\tTest F1:\t0.2338 *\n",
      "5 / 30: Train Loss:\t0.4066\tVal Loss:\t1.7155\tAccuracy:\t0.3669\tF1:\t0.3004\tTest Accuracy:\t0.4074\tTest F1:\t0.3228 *\n",
      "6 / 30: Train Loss:\t0.3642\tVal Loss:\t1.6000\tAccuracy:\t0.4320\tF1:\t0.3529\tTest Accuracy:\t0.4127\tTest F1:\t0.3125 *\n",
      "7 / 30: Train Loss:\t0.3209\tVal Loss:\t1.5016\tAccuracy:\t0.4941\tF1:\t0.4398\tTest Accuracy:\t0.4339\tTest F1:\t0.3392 *\n",
      "8 / 30: Train Loss:\t0.2793\tVal Loss:\t1.4502\tAccuracy:\t0.5000\tF1:\t0.4275\tTest Accuracy:\t0.4392\tTest F1:\t0.3657\n",
      "9 / 30: Train Loss:\t0.2419\tVal Loss:\t1.3735\tAccuracy:\t0.5325\tF1:\t0.4762\tTest Accuracy:\t0.4868\tTest F1:\t0.4052 *\n",
      "10 / 30: Train Loss:\t0.1991\tVal Loss:\t1.3699\tAccuracy:\t0.5296\tF1:\t0.4875\tTest Accuracy:\t0.4974\tTest F1:\t0.4022 *\n",
      "11 / 30: Train Loss:\t0.1667\tVal Loss:\t1.3653\tAccuracy:\t0.5355\tF1:\t0.4952\tTest Accuracy:\t0.5291\tTest F1:\t0.4573 *\n",
      "12 / 30: Train Loss:\t0.1315\tVal Loss:\t1.3852\tAccuracy:\t0.5414\tF1:\t0.4910\tTest Accuracy:\t0.5079\tTest F1:\t0.4050\n",
      "13 / 30: Train Loss:\t0.1039\tVal Loss:\t1.3945\tAccuracy:\t0.5325\tF1:\t0.4960\tTest Accuracy:\t0.5026\tTest F1:\t0.4127 *\n",
      "14 / 30: Train Loss:\t0.0774\tVal Loss:\t1.3643\tAccuracy:\t0.5710\tF1:\t0.5375\tTest Accuracy:\t0.5238\tTest F1:\t0.4177 *\n",
      "15 / 30: Train Loss:\t0.0576\tVal Loss:\t1.3810\tAccuracy:\t0.5562\tF1:\t0.5063\tTest Accuracy:\t0.5344\tTest F1:\t0.4589\n",
      "16 / 30: Train Loss:\t0.0446\tVal Loss:\t1.4216\tAccuracy:\t0.5473\tF1:\t0.4755\tTest Accuracy:\t0.5767\tTest F1:\t0.4832\n",
      "17 / 30: Train Loss:\t0.0354\tVal Loss:\t1.3734\tAccuracy:\t0.5680\tF1:\t0.5219\tTest Accuracy:\t0.5291\tTest F1:\t0.4244\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571cfe287ca74626849624e422c07702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6637\tVal Loss:\t2.1817\tAccuracy:\t0.2456\tF1:\t0.1609\tTest Accuracy:\t0.2434\tTest F1:\t0.1525 *\n",
      "2 / 30: Train Loss:\t0.5002\tVal Loss:\t1.8632\tAccuracy:\t0.3018\tF1:\t0.2519\tTest Accuracy:\t0.3016\tTest F1:\t0.2166 *\n",
      "3 / 30: Train Loss:\t0.4093\tVal Loss:\t1.6472\tAccuracy:\t0.3876\tF1:\t0.3448\tTest Accuracy:\t0.3651\tTest F1:\t0.2743 *\n",
      "4 / 30: Train Loss:\t0.3342\tVal Loss:\t1.4732\tAccuracy:\t0.4763\tF1:\t0.4168\tTest Accuracy:\t0.4180\tTest F1:\t0.3317 *\n",
      "5 / 30: Train Loss:\t0.2600\tVal Loss:\t1.3801\tAccuracy:\t0.5178\tF1:\t0.4821\tTest Accuracy:\t0.4815\tTest F1:\t0.3964 *\n",
      "6 / 30: Train Loss:\t0.1939\tVal Loss:\t1.3410\tAccuracy:\t0.5296\tF1:\t0.4906\tTest Accuracy:\t0.5344\tTest F1:\t0.4541 *\n",
      "7 / 30: Train Loss:\t0.1342\tVal Loss:\t1.3687\tAccuracy:\t0.5710\tF1:\t0.5314\tTest Accuracy:\t0.5450\tTest F1:\t0.4526 *\n",
      "8 / 30: Train Loss:\t0.0869\tVal Loss:\t1.3598\tAccuracy:\t0.5621\tF1:\t0.5159\tTest Accuracy:\t0.5608\tTest F1:\t0.4598\n",
      "9 / 30: Train Loss:\t0.0529\tVal Loss:\t1.4135\tAccuracy:\t0.5355\tF1:\t0.4832\tTest Accuracy:\t0.5397\tTest F1:\t0.4361\n",
      "10 / 30: Train Loss:\t0.0327\tVal Loss:\t1.3834\tAccuracy:\t0.5828\tF1:\t0.5512\tTest Accuracy:\t0.5767\tTest F1:\t0.4872 *\n",
      "11 / 30: Train Loss:\t0.0212\tVal Loss:\t1.4128\tAccuracy:\t0.5888\tF1:\t0.5267\tTest Accuracy:\t0.5767\tTest F1:\t0.4756\n",
      "12 / 30: Train Loss:\t0.0145\tVal Loss:\t1.4081\tAccuracy:\t0.5917\tF1:\t0.5282\tTest Accuracy:\t0.5714\tTest F1:\t0.4873\n",
      "13 / 30: Train Loss:\t0.0106\tVal Loss:\t1.4143\tAccuracy:\t0.6124\tF1:\t0.5728\tTest Accuracy:\t0.6085\tTest F1:\t0.5428 *\n",
      "14 / 30: Train Loss:\t0.0088\tVal Loss:\t1.4316\tAccuracy:\t0.5947\tF1:\t0.5582\tTest Accuracy:\t0.5714\tTest F1:\t0.4457\n",
      "15 / 30: Train Loss:\t0.0067\tVal Loss:\t1.4503\tAccuracy:\t0.6124\tF1:\t0.5748\tTest Accuracy:\t0.5714\tTest F1:\t0.4987 *\n",
      "16 / 30: Train Loss:\t0.0055\tVal Loss:\t1.4247\tAccuracy:\t0.6065\tF1:\t0.5530\tTest Accuracy:\t0.5979\tTest F1:\t0.4919\n",
      "17 / 30: Train Loss:\t0.0045\tVal Loss:\t1.4474\tAccuracy:\t0.6065\tF1:\t0.5533\tTest Accuracy:\t0.5820\tTest F1:\t0.5072\n",
      "18 / 30: Train Loss:\t0.0044\tVal Loss:\t1.4178\tAccuracy:\t0.6154\tF1:\t0.5638\tTest Accuracy:\t0.5661\tTest F1:\t0.4778\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.5020\tVal Loss:\t1.3032\tAccuracy:\t0.5444\tF1:\t0.4658\tTest Accuracy:\t0.5714\tTest F1:\t0.4473 *\n",
      "2 / 30: Train Loss:\t0.2125\tVal Loss:\t1.2415\tAccuracy:\t0.6243\tF1:\t0.6028\tTest Accuracy:\t0.6296\tTest F1:\t0.5646 *\n",
      "3 / 30: Train Loss:\t0.0847\tVal Loss:\t1.4677\tAccuracy:\t0.5769\tF1:\t0.5429\tTest Accuracy:\t0.5820\tTest F1:\t0.4770\n",
      "4 / 30: Train Loss:\t0.0358\tVal Loss:\t1.6939\tAccuracy:\t0.5710\tF1:\t0.5337\tTest Accuracy:\t0.6296\tTest F1:\t0.5579\n",
      "5 / 30: Train Loss:\t0.0212\tVal Loss:\t1.7025\tAccuracy:\t0.5799\tF1:\t0.5369\tTest Accuracy:\t0.5608\tTest F1:\t0.4929\n",
      "No improvement for 3 epochs. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "r = 8\n",
    "a = 8\n",
    "lora_dropout = 0.0\n",
    "\n",
    "learning_rates = [1.0e-5, 5.0e-5 ,1.0e-4, 1.0e-3]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f'Grid search {model_checkpoint}, learning rate {lr}')\n",
    "    data = ClimateDataset(model_to_train=3,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=8)\n",
    "    data.setup_dataloaders()\n",
    "    model = ClassificationModel(model_checkpoint=data.model_checkpoint,\n",
    "                                num_labels=data.num_labels,\n",
    "                                quantized_model=True,\n",
    "                                lora=True,\n",
    "                                r=r,\n",
    "                                alpha=a,\n",
    "                                dropout=lora_dropout)\n",
    "    trainer = Engine(epochs=30,labels=data.labels)\n",
    "    trainer.model = model.model\n",
    "    trainer.run(lr=lr,\n",
    "                wd=0.0,\n",
    "                train_dataloader=data.train_dataloader,\n",
    "                eval_dataloader=data.eval_dataloader,\n",
    "                test_dataloader=data.test_dataloader,\n",
    "                accumulation_steps=4,\n",
    "                early_stop=3,\n",
    "                is_quantized=True)\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    del data, model, trainer\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
