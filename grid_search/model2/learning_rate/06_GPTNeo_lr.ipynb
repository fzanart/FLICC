{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/software/'\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.realpath(\"__file__\").split('grid_search')[0]\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint='EleutherAI/gpt-neo-1.3B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'lr':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c867eb159399459e8ba122a32cb12546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05a8c9efcf6458d8b568298cade60e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bcd39650ad4854a08f8e22b6d1fd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca079f2c3c64446939a6a9a0e11972e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf0e1cd4aa94ac399cb60452bba878a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174f3b27c6004eef9fe8e9dda5c7cb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6008\tVal Loss:\t2.4922\tAccuracy:\t0.3193\tF1:\t0.2546\tTest Accuracy:\t0.2985\tTest F1:\t0.2405 *\n",
      "2 / 30: Train Loss:\t0.5629\tVal Loss:\t2.3229\tAccuracy:\t0.3277\tF1:\t0.2640\tTest Accuracy:\t0.3284\tTest F1:\t0.2670 *\n",
      "3 / 30: Train Loss:\t0.5206\tVal Loss:\t2.1136\tAccuracy:\t0.3361\tF1:\t0.2829\tTest Accuracy:\t0.3284\tTest F1:\t0.3027 *\n",
      "4 / 30: Train Loss:\t0.4756\tVal Loss:\t1.9453\tAccuracy:\t0.3109\tF1:\t0.2538\tTest Accuracy:\t0.3134\tTest F1:\t0.2924\n",
      "5 / 30: Train Loss:\t0.4352\tVal Loss:\t1.8013\tAccuracy:\t0.3193\tF1:\t0.2837\tTest Accuracy:\t0.2985\tTest F1:\t0.2789 *\n",
      "6 / 30: Train Loss:\t0.4013\tVal Loss:\t1.6802\tAccuracy:\t0.3193\tF1:\t0.2990\tTest Accuracy:\t0.2687\tTest F1:\t0.2527 *\n",
      "7 / 30: Train Loss:\t0.3633\tVal Loss:\t1.5894\tAccuracy:\t0.3529\tF1:\t0.3493\tTest Accuracy:\t0.2537\tTest F1:\t0.2439 *\n",
      "8 / 30: Train Loss:\t0.3471\tVal Loss:\t1.5604\tAccuracy:\t0.3445\tF1:\t0.3450\tTest Accuracy:\t0.2687\tTest F1:\t0.2650\n",
      "9 / 30: Train Loss:\t0.3283\tVal Loss:\t1.4418\tAccuracy:\t0.3445\tF1:\t0.3437\tTest Accuracy:\t0.3433\tTest F1:\t0.3351\n",
      "10 / 30: Train Loss:\t0.3205\tVal Loss:\t1.4421\tAccuracy:\t0.3782\tF1:\t0.3785\tTest Accuracy:\t0.3731\tTest F1:\t0.3672 *\n",
      "11 / 30: Train Loss:\t0.3131\tVal Loss:\t1.4468\tAccuracy:\t0.3361\tF1:\t0.3356\tTest Accuracy:\t0.3134\tTest F1:\t0.3099\n",
      "12 / 30: Train Loss:\t0.3093\tVal Loss:\t1.3649\tAccuracy:\t0.3697\tF1:\t0.3679\tTest Accuracy:\t0.2985\tTest F1:\t0.2883\n",
      "13 / 30: Train Loss:\t0.3039\tVal Loss:\t1.4269\tAccuracy:\t0.3613\tF1:\t0.3609\tTest Accuracy:\t0.2985\tTest F1:\t0.2994\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4e23078c184536876d3d923770ad93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.5293\tVal Loss:\t1.8348\tAccuracy:\t0.3361\tF1:\t0.2921\tTest Accuracy:\t0.2836\tTest F1:\t0.2643 *\n",
      "2 / 30: Train Loss:\t0.3656\tVal Loss:\t1.4876\tAccuracy:\t0.3697\tF1:\t0.3653\tTest Accuracy:\t0.2687\tTest F1:\t0.2390 *\n",
      "3 / 30: Train Loss:\t0.3156\tVal Loss:\t1.3574\tAccuracy:\t0.3697\tF1:\t0.3640\tTest Accuracy:\t0.2537\tTest F1:\t0.2387\n",
      "4 / 30: Train Loss:\t0.2942\tVal Loss:\t1.2964\tAccuracy:\t0.4034\tF1:\t0.4040\tTest Accuracy:\t0.4030\tTest F1:\t0.3969 *\n",
      "5 / 30: Train Loss:\t0.2710\tVal Loss:\t1.2203\tAccuracy:\t0.4790\tF1:\t0.4801\tTest Accuracy:\t0.3433\tTest F1:\t0.3266 *\n",
      "6 / 30: Train Loss:\t0.2488\tVal Loss:\t1.1879\tAccuracy:\t0.4202\tF1:\t0.4170\tTest Accuracy:\t0.3731\tTest F1:\t0.3737\n",
      "7 / 30: Train Loss:\t0.2311\tVal Loss:\t1.0977\tAccuracy:\t0.4706\tF1:\t0.4666\tTest Accuracy:\t0.4030\tTest F1:\t0.4068\n",
      "8 / 30: Train Loss:\t0.2112\tVal Loss:\t1.1056\tAccuracy:\t0.4622\tF1:\t0.4628\tTest Accuracy:\t0.3881\tTest F1:\t0.3954\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46d3b0a02964af799f3a4466d5b14b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.4527\tVal Loss:\t1.4940\tAccuracy:\t0.3782\tF1:\t0.3704\tTest Accuracy:\t0.2836\tTest F1:\t0.2435 *\n",
      "2 / 30: Train Loss:\t0.3148\tVal Loss:\t1.3674\tAccuracy:\t0.4118\tF1:\t0.4139\tTest Accuracy:\t0.3433\tTest F1:\t0.3100 *\n",
      "3 / 30: Train Loss:\t0.2824\tVal Loss:\t1.2422\tAccuracy:\t0.4370\tF1:\t0.4413\tTest Accuracy:\t0.4179\tTest F1:\t0.4182 *\n",
      "4 / 30: Train Loss:\t0.2367\tVal Loss:\t1.0952\tAccuracy:\t0.4874\tF1:\t0.4880\tTest Accuracy:\t0.3881\tTest F1:\t0.3843 *\n",
      "5 / 30: Train Loss:\t0.2041\tVal Loss:\t1.0802\tAccuracy:\t0.4454\tF1:\t0.4501\tTest Accuracy:\t0.4328\tTest F1:\t0.4347\n",
      "6 / 30: Train Loss:\t0.1788\tVal Loss:\t0.9681\tAccuracy:\t0.4622\tF1:\t0.4668\tTest Accuracy:\t0.4776\tTest F1:\t0.4814\n",
      "7 / 30: Train Loss:\t0.1461\tVal Loss:\t1.0147\tAccuracy:\t0.5126\tF1:\t0.5126\tTest Accuracy:\t0.4925\tTest F1:\t0.4953 *\n",
      "8 / 30: Train Loss:\t0.1214\tVal Loss:\t0.9010\tAccuracy:\t0.5126\tF1:\t0.5096\tTest Accuracy:\t0.4776\tTest F1:\t0.4786\n",
      "9 / 30: Train Loss:\t0.0937\tVal Loss:\t0.9749\tAccuracy:\t0.5294\tF1:\t0.5335\tTest Accuracy:\t0.4925\tTest F1:\t0.4923 *\n",
      "10 / 30: Train Loss:\t0.0745\tVal Loss:\t0.9316\tAccuracy:\t0.5882\tF1:\t0.5860\tTest Accuracy:\t0.5373\tTest F1:\t0.5384 *\n",
      "11 / 30: Train Loss:\t0.0507\tVal Loss:\t0.8923\tAccuracy:\t0.5966\tF1:\t0.5982\tTest Accuracy:\t0.5224\tTest F1:\t0.5269 *\n",
      "12 / 30: Train Loss:\t0.0366\tVal Loss:\t0.9619\tAccuracy:\t0.6050\tF1:\t0.6099\tTest Accuracy:\t0.5373\tTest F1:\t0.5384 *\n",
      "13 / 30: Train Loss:\t0.0264\tVal Loss:\t0.9443\tAccuracy:\t0.5966\tF1:\t0.5950\tTest Accuracy:\t0.5672\tTest F1:\t0.5679\n",
      "14 / 30: Train Loss:\t0.0189\tVal Loss:\t0.9368\tAccuracy:\t0.6050\tF1:\t0.6023\tTest Accuracy:\t0.5224\tTest F1:\t0.5220\n",
      "15 / 30: Train Loss:\t0.0142\tVal Loss:\t0.9616\tAccuracy:\t0.6303\tF1:\t0.6300\tTest Accuracy:\t0.5522\tTest F1:\t0.5536 *\n",
      "16 / 30: Train Loss:\t0.0107\tVal Loss:\t1.0355\tAccuracy:\t0.5714\tF1:\t0.5725\tTest Accuracy:\t0.5672\tTest F1:\t0.5731\n",
      "17 / 30: Train Loss:\t0.0095\tVal Loss:\t1.0420\tAccuracy:\t0.6050\tF1:\t0.5984\tTest Accuracy:\t0.6119\tTest F1:\t0.6110\n",
      "18 / 30: Train Loss:\t0.0070\tVal Loss:\t1.0299\tAccuracy:\t0.6050\tF1:\t0.6035\tTest Accuracy:\t0.5672\tTest F1:\t0.5643\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.3471\tVal Loss:\t1.0328\tAccuracy:\t0.5210\tF1:\t0.5119\tTest Accuracy:\t0.4776\tTest F1:\t0.4721 *\n",
      "2 / 30: Train Loss:\t0.1899\tVal Loss:\t0.9364\tAccuracy:\t0.6218\tF1:\t0.6301\tTest Accuracy:\t0.5075\tTest F1:\t0.5105 *\n",
      "3 / 30: Train Loss:\t0.0834\tVal Loss:\t0.9792\tAccuracy:\t0.5546\tF1:\t0.5640\tTest Accuracy:\t0.5821\tTest F1:\t0.5868\n",
      "4 / 30: Train Loss:\t0.0323\tVal Loss:\t1.1466\tAccuracy:\t0.6218\tF1:\t0.6180\tTest Accuracy:\t0.5821\tTest F1:\t0.5844\n",
      "5 / 30: Train Loss:\t0.0274\tVal Loss:\t1.4657\tAccuracy:\t0.5714\tF1:\t0.5306\tTest Accuracy:\t0.5970\tTest F1:\t0.5641\n",
      "No improvement for 3 epochs. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "r = 8\n",
    "a = 8\n",
    "lora_dropout = 0.0\n",
    "\n",
    "learning_rates = [1.0e-5, 5.0e-5 ,1.0e-4, 1.0e-3]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print(f'Grid search {model_checkpoint}, learning rate {lr}')\n",
    "    data = ClimateDataset(model_to_train=2,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=8)\n",
    "    data.setup_dataloaders()\n",
    "    model = ClassificationModel(model_checkpoint=data.model_checkpoint,\n",
    "                                num_labels=data.num_labels,\n",
    "                                quantized_model=True,\n",
    "                                lora=True,\n",
    "                                r=r,\n",
    "                                alpha=a,\n",
    "                                dropout=lora_dropout)\n",
    "    trainer = Engine(epochs=30,labels=data.labels)\n",
    "    trainer.model = model.model\n",
    "    trainer.run(lr=lr,\n",
    "                wd=0.0,\n",
    "                train_dataloader=data.train_dataloader,\n",
    "                eval_dataloader=data.eval_dataloader,\n",
    "                test_dataloader=data.test_dataloader,\n",
    "                accumulation_steps=4,\n",
    "                early_stop=3,\n",
    "                is_quantized=True)\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    del data, model, trainer\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
