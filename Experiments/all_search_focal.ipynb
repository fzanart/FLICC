{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/software/'\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.join(os.path.dirname(os.getcwd()), '')\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {'bert-base-uncased':{'lr':5.0e-5},\n",
    "                'roberta-large':{'lr':5.0e-5},\n",
    "                'gpt2':{'lr':5.0e-5},\n",
    "                'bigscience/bloom-560m':{'lr':5.0e-5},\n",
    "                'facebook/opt-350m':{'lr':1.0e-5},\n",
    "                'EleutherAI/gpt-neo-1.3B':{'lr':5.0e-5}, \n",
    "                'microsoft/deberta-base':{'lr':1.0e-5},\n",
    "                'microsoft/deberta-v2-xlarge':{'lr':1.0e-5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'g':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t21.5878\tVal Loss:\t1.8216\tAccuracy:\t0.4026\tF1:\t0.3431 *\n",
      "2 / 30: Train Loss:\t12.3960\tVal Loss:\t1.6948\tAccuracy:\t0.4530\tF1:\t0.4332 *\n",
      "3 / 30: Train Loss:\t6.2709\tVal Loss:\t1.4211\tAccuracy:\t0.5252\tF1:\t0.5152 *\n",
      "4 / 30: Train Loss:\t2.7156\tVal Loss:\t1.2350\tAccuracy:\t0.6018\tF1:\t0.5858 *\n",
      "5 / 30: Train Loss:\t1.1768\tVal Loss:\t1.2149\tAccuracy:\t0.6368\tF1:\t0.6224 *\n",
      "6 / 30: Train Loss:\t0.5279\tVal Loss:\t1.1698\tAccuracy:\t0.6543\tF1:\t0.6415 *\n",
      "7 / 30: Train Loss:\t0.2480\tVal Loss:\t1.1532\tAccuracy:\t0.6630\tF1:\t0.6359\n",
      "8 / 30: Train Loss:\t0.1090\tVal Loss:\t1.1358\tAccuracy:\t0.6586\tF1:\t0.6308\n",
      "9 / 30: Train Loss:\t0.0473\tVal Loss:\t1.1311\tAccuracy:\t0.6630\tF1:\t0.6427 *\n",
      "10 / 30: Train Loss:\t0.0343\tVal Loss:\t1.1182\tAccuracy:\t0.6783\tF1:\t0.6574 *\n",
      "11 / 30: Train Loss:\t0.0320\tVal Loss:\t1.1245\tAccuracy:\t0.6696\tF1:\t0.6398\n",
      "12 / 30: Train Loss:\t0.0250\tVal Loss:\t1.1340\tAccuracy:\t0.6761\tF1:\t0.6510\n",
      "13 / 30: Train Loss:\t0.0174\tVal Loss:\t1.1267\tAccuracy:\t0.6761\tF1:\t0.6507\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.73      0.64      0.68        67\n",
      "               anecdote       0.90      0.86      0.88        43\n",
      "         cherry picking       0.70      0.70      0.70        56\n",
      "      conspiracy theory       0.76      0.87      0.81        39\n",
      "           fake experts       0.82      0.75      0.78        12\n",
      "           false choice       0.56      0.69      0.62        13\n",
      "      false equivalence       0.33      0.21      0.26        14\n",
      "impossible expectations       0.71      0.54      0.62        37\n",
      "      misrepresentation       0.57      0.61      0.59        38\n",
      "     oversimplification       0.79      0.64      0.71        36\n",
      "           single cause       0.57      0.70      0.63        57\n",
      "     slothful induction       0.57      0.67      0.61        45\n",
      "\n",
      "               accuracy                           0.68       457\n",
      "              macro avg       0.67      0.66      0.66       457\n",
      "           weighted avg       0.68      0.68      0.68       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.77      0.81      0.79        37\n",
      "               anecdote       0.83      0.79      0.81        24\n",
      "         cherry picking       0.61      0.55      0.58        31\n",
      "      conspiracy theory       0.73      0.50      0.59        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.33      0.57      0.42         7\n",
      "      false equivalence       0.44      0.50      0.47         8\n",
      "impossible expectations       0.67      0.67      0.67        21\n",
      "      misrepresentation       0.59      0.73      0.65        22\n",
      "     oversimplification       0.76      0.80      0.78        20\n",
      "           single cause       0.64      0.72      0.68        32\n",
      "     slothful induction       0.32      0.24      0.27        25\n",
      "\n",
      "               accuracy                           0.65       256\n",
      "              macro avg       0.64      0.64      0.64       256\n",
      "           weighted avg       0.65      0.65      0.65       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375], 'test_f1': [0.6360817875408947], 'eval_acc': [0.6783369803063457], 'eval_f1': [0.6573832525923866], 'g': [2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t17.7481\tVal Loss:\t1.8447\tAccuracy:\t0.4464\tF1:\t0.3860 *\n",
      "2 / 30: Train Loss:\t9.3680\tVal Loss:\t1.6075\tAccuracy:\t0.4989\tF1:\t0.4667 *\n",
      "3 / 30: Train Loss:\t4.2528\tVal Loss:\t1.4378\tAccuracy:\t0.5295\tF1:\t0.5149 *\n",
      "4 / 30: Train Loss:\t1.8639\tVal Loss:\t1.3205\tAccuracy:\t0.5558\tF1:\t0.5455 *\n",
      "5 / 30: Train Loss:\t0.8342\tVal Loss:\t1.2410\tAccuracy:\t0.6236\tF1:\t0.6083 *\n",
      "6 / 30: Train Loss:\t0.3459\tVal Loss:\t1.1654\tAccuracy:\t0.6346\tF1:\t0.6152 *\n",
      "7 / 30: Train Loss:\t0.1744\tVal Loss:\t1.1782\tAccuracy:\t0.6214\tF1:\t0.5916\n",
      "8 / 30: Train Loss:\t0.1141\tVal Loss:\t1.1194\tAccuracy:\t0.6521\tF1:\t0.6132\n",
      "9 / 30: Train Loss:\t0.0407\tVal Loss:\t1.1247\tAccuracy:\t0.6477\tF1:\t0.6089\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.74      0.58      0.65        67\n",
      "               anecdote       0.85      0.81      0.83        43\n",
      "         cherry picking       0.74      0.57      0.65        56\n",
      "      conspiracy theory       0.75      0.85      0.80        39\n",
      "           fake experts       0.80      0.67      0.73        12\n",
      "           false choice       0.67      0.46      0.55        13\n",
      "      false equivalence       0.27      0.21      0.24        14\n",
      "impossible expectations       0.68      0.46      0.55        37\n",
      "      misrepresentation       0.42      0.61      0.49        38\n",
      "     oversimplification       0.85      0.64      0.73        36\n",
      "           single cause       0.55      0.72      0.63        57\n",
      "     slothful induction       0.46      0.67      0.55        45\n",
      "\n",
      "               accuracy                           0.63       457\n",
      "              macro avg       0.65      0.60      0.62       457\n",
      "           weighted avg       0.66      0.63      0.64       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.83      0.78      0.81        37\n",
      "               anecdote       0.87      0.83      0.85        24\n",
      "         cherry picking       0.70      0.52      0.59        31\n",
      "      conspiracy theory       0.75      0.55      0.63        22\n",
      "           fake experts       1.00      0.71      0.83         7\n",
      "           false choice       0.50      0.57      0.53         7\n",
      "      false equivalence       0.36      0.50      0.42         8\n",
      "impossible expectations       0.77      0.48      0.59        21\n",
      "      misrepresentation       0.45      0.77      0.57        22\n",
      "     oversimplification       0.75      0.75      0.75        20\n",
      "           single cause       0.61      0.69      0.65        32\n",
      "     slothful induction       0.14      0.16      0.15        25\n",
      "\n",
      "               accuracy                           0.62       256\n",
      "              macro avg       0.64      0.61      0.61       256\n",
      "           weighted avg       0.65      0.62      0.62       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875], 'test_f1': [0.6360817875408947, 0.6142845336741297], 'eval_acc': [0.6783369803063457, 0.6345733041575492], 'eval_f1': [0.6573832525923866, 0.6151903501826291], 'g': [2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t11.5883\tVal Loss:\t1.9160\tAccuracy:\t0.3982\tF1:\t0.3449 *\n",
      "2 / 30: Train Loss:\t4.9761\tVal Loss:\t1.7012\tAccuracy:\t0.4989\tF1:\t0.4820 *\n",
      "3 / 30: Train Loss:\t1.9743\tVal Loss:\t1.5282\tAccuracy:\t0.4814\tF1:\t0.4778\n",
      "4 / 30: Train Loss:\t0.7401\tVal Loss:\t1.3385\tAccuracy:\t0.5821\tF1:\t0.5565 *\n",
      "5 / 30: Train Loss:\t0.2250\tVal Loss:\t1.2818\tAccuracy:\t0.6039\tF1:\t0.5866 *\n",
      "6 / 30: Train Loss:\t0.0874\tVal Loss:\t1.2403\tAccuracy:\t0.6368\tF1:\t0.6145 *\n",
      "7 / 30: Train Loss:\t0.0601\tVal Loss:\t1.2451\tAccuracy:\t0.6236\tF1:\t0.6055\n",
      "8 / 30: Train Loss:\t0.0273\tVal Loss:\t1.1987\tAccuracy:\t0.6411\tF1:\t0.6206 *\n",
      "9 / 30: Train Loss:\t0.0173\tVal Loss:\t1.2000\tAccuracy:\t0.6258\tF1:\t0.6065\n",
      "10 / 30: Train Loss:\t0.0108\tVal Loss:\t1.1822\tAccuracy:\t0.6411\tF1:\t0.6243 *\n",
      "11 / 30: Train Loss:\t0.0092\tVal Loss:\t1.1759\tAccuracy:\t0.6389\tF1:\t0.6219\n",
      "12 / 30: Train Loss:\t0.0080\tVal Loss:\t1.1761\tAccuracy:\t0.6455\tF1:\t0.6261 *\n",
      "13 / 30: Train Loss:\t0.0060\tVal Loss:\t1.1690\tAccuracy:\t0.6477\tF1:\t0.6291 *\n",
      "14 / 30: Train Loss:\t0.0049\tVal Loss:\t1.1596\tAccuracy:\t0.6455\tF1:\t0.6273\n",
      "15 / 30: Train Loss:\t0.0038\tVal Loss:\t1.1496\tAccuracy:\t0.6477\tF1:\t0.6313 *\n",
      "16 / 30: Train Loss:\t0.0032\tVal Loss:\t1.1593\tAccuracy:\t0.6346\tF1:\t0.6183\n",
      "17 / 30: Train Loss:\t0.0027\tVal Loss:\t1.1519\tAccuracy:\t0.6455\tF1:\t0.6297\n",
      "18 / 30: Train Loss:\t0.0026\tVal Loss:\t1.1474\tAccuracy:\t0.6411\tF1:\t0.6247\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.64      0.61      0.63        67\n",
      "               anecdote       0.87      0.79      0.83        43\n",
      "         cherry picking       0.65      0.62      0.64        56\n",
      "      conspiracy theory       0.68      0.87      0.76        39\n",
      "           fake experts       0.82      0.75      0.78        12\n",
      "           false choice       0.73      0.62      0.67        13\n",
      "      false equivalence       0.33      0.14      0.20        14\n",
      "impossible expectations       0.62      0.62      0.62        37\n",
      "      misrepresentation       0.59      0.50      0.54        38\n",
      "     oversimplification       0.77      0.64      0.70        36\n",
      "           single cause       0.65      0.63      0.64        57\n",
      "     slothful induction       0.47      0.71      0.57        45\n",
      "\n",
      "               accuracy                           0.65       457\n",
      "              macro avg       0.65      0.63      0.63       457\n",
      "           weighted avg       0.65      0.65      0.64       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.84      0.82        37\n",
      "               anecdote       0.80      0.83      0.82        24\n",
      "         cherry picking       0.56      0.48      0.52        31\n",
      "      conspiracy theory       0.74      0.64      0.68        22\n",
      "           fake experts       0.86      0.86      0.86         7\n",
      "           false choice       0.33      0.43      0.38         7\n",
      "      false equivalence       0.60      0.38      0.46         8\n",
      "impossible expectations       0.62      0.62      0.62        21\n",
      "      misrepresentation       0.76      0.73      0.74        22\n",
      "     oversimplification       0.68      0.75      0.71        20\n",
      "           single cause       0.66      0.66      0.66        32\n",
      "     slothful induction       0.28      0.32      0.30        25\n",
      "\n",
      "               accuracy                           0.64       256\n",
      "              macro avg       0.64      0.63      0.63       256\n",
      "           weighted avg       0.65      0.64      0.65       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037], 'g': [2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t5.4874\tVal Loss:\t1.9578\tAccuracy:\t0.4442\tF1:\t0.3967 *\n",
      "2 / 30: Train Loss:\t1.7973\tVal Loss:\t1.8008\tAccuracy:\t0.4705\tF1:\t0.4402 *\n",
      "3 / 30: Train Loss:\t0.5656\tVal Loss:\t1.5226\tAccuracy:\t0.5799\tF1:\t0.5692 *\n",
      "4 / 30: Train Loss:\t0.1934\tVal Loss:\t1.4833\tAccuracy:\t0.6171\tF1:\t0.6056 *\n",
      "5 / 30: Train Loss:\t0.0639\tVal Loss:\t1.4193\tAccuracy:\t0.6018\tF1:\t0.5829\n",
      "6 / 30: Train Loss:\t0.0219\tVal Loss:\t1.3553\tAccuracy:\t0.6280\tF1:\t0.6007\n",
      "7 / 30: Train Loss:\t0.0135\tVal Loss:\t1.3405\tAccuracy:\t0.6171\tF1:\t0.6010\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.73      0.61      0.67        67\n",
      "               anecdote       0.91      0.67      0.77        43\n",
      "         cherry picking       0.56      0.61      0.58        56\n",
      "      conspiracy theory       0.75      0.69      0.72        39\n",
      "           fake experts       0.64      0.75      0.69        12\n",
      "           false choice       0.57      0.62      0.59        13\n",
      "      false equivalence       0.16      0.29      0.21        14\n",
      "impossible expectations       0.79      0.51      0.62        37\n",
      "      misrepresentation       0.54      0.55      0.55        38\n",
      "     oversimplification       0.87      0.56      0.68        36\n",
      "           single cause       0.58      0.67      0.62        57\n",
      "     slothful induction       0.47      0.71      0.57        45\n",
      "\n",
      "               accuracy                           0.62       457\n",
      "              macro avg       0.63      0.60      0.61       457\n",
      "           weighted avg       0.66      0.62      0.63       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.73      0.76        37\n",
      "               anecdote       0.86      0.75      0.80        24\n",
      "         cherry picking       0.50      0.52      0.51        31\n",
      "      conspiracy theory       0.69      0.50      0.58        22\n",
      "           fake experts       0.83      0.71      0.77         7\n",
      "           false choice       0.23      0.43      0.30         7\n",
      "      false equivalence       0.33      0.50      0.40         8\n",
      "impossible expectations       0.69      0.52      0.59        21\n",
      "      misrepresentation       0.57      0.59      0.58        22\n",
      "     oversimplification       0.81      0.65      0.72        20\n",
      "           single cause       0.54      0.62      0.58        32\n",
      "     slothful induction       0.17      0.20      0.18        25\n",
      "\n",
      "               accuracy                           0.57       256\n",
      "              macro avg       0.58      0.56      0.56       256\n",
      "           weighted avg       0.61      0.57      0.58       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604], 'g': [2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t25.5600\tVal Loss:\t2.5146\tAccuracy:\t0.0306\tF1:\t0.0050 *\n",
      "2 / 30: Train Loss:\t25.6664\tVal Loss:\t2.5075\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "3 / 30: Train Loss:\t25.6679\tVal Loss:\t2.5213\tAccuracy:\t0.0284\tF1:\t0.0046\n",
      "4 / 30: Train Loss:\t25.5668\tVal Loss:\t2.4990\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.03      1.00      0.06        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.03       457\n",
      "              macro avg       0.00      0.08      0.00       457\n",
      "           weighted avg       0.00      0.03      0.00       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.03      1.00      0.06         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.03       256\n",
      "              macro avg       0.00      0.08      0.01       256\n",
      "           weighted avg       0.00      0.03      0.00       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833], 'g': [2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t21.1851\tVal Loss:\t2.5145\tAccuracy:\t0.0284\tF1:\t0.0046 *\n",
      "2 / 30: Train Loss:\t21.6485\tVal Loss:\t2.5322\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "3 / 30: Train Loss:\t21.8272\tVal Loss:\t2.5151\tAccuracy:\t0.0284\tF1:\t0.0046\n",
      "4 / 30: Train Loss:\t21.5902\tVal Loss:\t2.5111\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.03      1.00      0.06        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.03       457\n",
      "              macro avg       0.00      0.08      0.00       457\n",
      "           weighted avg       0.00      0.03      0.00       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.03      1.00      0.05         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.03       256\n",
      "              macro avg       0.00      0.08      0.00       256\n",
      "           weighted avg       0.00      0.03      0.00       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185], 'g': [2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t14.9873\tVal Loss:\t2.1662\tAccuracy:\t0.3042\tF1:\t0.2616 *\n",
      "2 / 30: Train Loss:\t9.2599\tVal Loss:\t1.6561\tAccuracy:\t0.4639\tF1:\t0.4362 *\n",
      "3 / 30: Train Loss:\t5.2970\tVal Loss:\t1.4738\tAccuracy:\t0.5383\tF1:\t0.5447 *\n",
      "4 / 30: Train Loss:\t2.7883\tVal Loss:\t1.3327\tAccuracy:\t0.5492\tF1:\t0.5363\n",
      "5 / 30: Train Loss:\t2.0063\tVal Loss:\t1.5730\tAccuracy:\t0.4442\tF1:\t0.4693\n",
      "6 / 30: Train Loss:\t1.2321\tVal Loss:\t1.1911\tAccuracy:\t0.6127\tF1:\t0.6009 *\n",
      "7 / 30: Train Loss:\t0.4829\tVal Loss:\t1.1570\tAccuracy:\t0.6652\tF1:\t0.6642 *\n",
      "8 / 30: Train Loss:\t0.3539\tVal Loss:\t1.0743\tAccuracy:\t0.6805\tF1:\t0.6624\n",
      "9 / 30: Train Loss:\t0.0812\tVal Loss:\t1.0577\tAccuracy:\t0.6958\tF1:\t0.6743 *\n",
      "10 / 30: Train Loss:\t0.0440\tVal Loss:\t1.0213\tAccuracy:\t0.7155\tF1:\t0.7013 *\n",
      "11 / 30: Train Loss:\t0.0235\tVal Loss:\t1.0026\tAccuracy:\t0.7265\tF1:\t0.7140 *\n",
      "12 / 30: Train Loss:\t0.0236\tVal Loss:\t1.0341\tAccuracy:\t0.7024\tF1:\t0.6819\n",
      "13 / 30: Train Loss:\t0.0175\tVal Loss:\t1.0201\tAccuracy:\t0.7221\tF1:\t0.7029\n",
      "14 / 30: Train Loss:\t0.0087\tVal Loss:\t1.0367\tAccuracy:\t0.6958\tF1:\t0.6802\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.75      0.67      0.71        67\n",
      "               anecdote       0.93      0.86      0.89        43\n",
      "         cherry picking       0.68      0.61      0.64        56\n",
      "      conspiracy theory       0.78      0.90      0.83        39\n",
      "           fake experts       0.79      0.92      0.85        12\n",
      "           false choice       0.77      0.77      0.77        13\n",
      "      false equivalence       0.80      0.29      0.42        14\n",
      "impossible expectations       0.66      0.62      0.64        37\n",
      "      misrepresentation       0.64      0.61      0.62        38\n",
      "     oversimplification       0.71      0.67      0.69        36\n",
      "           single cause       0.76      0.84      0.80        57\n",
      "     slothful induction       0.61      0.84      0.71        45\n",
      "\n",
      "               accuracy                           0.73       457\n",
      "              macro avg       0.74      0.72      0.71       457\n",
      "           weighted avg       0.73      0.73      0.72       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.78      0.78      0.78        37\n",
      "               anecdote       0.91      0.88      0.89        24\n",
      "         cherry picking       0.75      0.68      0.71        31\n",
      "      conspiracy theory       0.75      0.68      0.71        22\n",
      "           fake experts       1.00      1.00      1.00         7\n",
      "           false choice       0.43      0.43      0.43         7\n",
      "      false equivalence       0.60      0.38      0.46         8\n",
      "impossible expectations       0.62      0.71      0.67        21\n",
      "      misrepresentation       0.62      0.73      0.67        22\n",
      "     oversimplification       0.67      0.80      0.73        20\n",
      "           single cause       0.72      0.72      0.72        32\n",
      "     slothful induction       0.52      0.48      0.50        25\n",
      "\n",
      "               accuracy                           0.71       256\n",
      "              macro avg       0.70      0.69      0.69       256\n",
      "           weighted avg       0.71      0.71      0.71       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007], 'g': [2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t8.2210\tVal Loss:\t2.5205\tAccuracy:\t0.0263\tF1:\t0.0043 *\n",
      "2 / 30: Train Loss:\t7.9589\tVal Loss:\t2.5175\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "3 / 30: Train Loss:\t8.0694\tVal Loss:\t2.5122\tAccuracy:\t0.0284\tF1:\t0.0046 *\n",
      "4 / 30: Train Loss:\t7.8820\tVal Loss:\t2.5154\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "5 / 30: Train Loss:\t7.8788\tVal Loss:\t2.5135\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "6 / 30: Train Loss:\t7.8773\tVal Loss:\t2.5142\tAccuracy:\t0.0263\tF1:\t0.0043\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.03      1.00      0.06        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.03       457\n",
      "              macro avg       0.00      0.08      0.00       457\n",
      "           weighted avg       0.00      0.03      0.00       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.03      1.00      0.05         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.03       256\n",
      "              macro avg       0.00      0.08      0.00       256\n",
      "           weighted avg       0.00      0.03      0.00       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185], 'g': [2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t29.0114\tVal Loss:\t2.4796\tAccuracy:\t0.0503\tF1:\t0.0378 *\n",
      "2 / 30: Train Loss:\t24.0249\tVal Loss:\t2.3909\tAccuracy:\t0.1204\tF1:\t0.1164 *\n",
      "3 / 30: Train Loss:\t22.2701\tVal Loss:\t2.2500\tAccuracy:\t0.1685\tF1:\t0.1730 *\n",
      "4 / 30: Train Loss:\t18.4805\tVal Loss:\t2.0144\tAccuracy:\t0.2735\tF1:\t0.2713 *\n",
      "5 / 30: Train Loss:\t14.6018\tVal Loss:\t1.8825\tAccuracy:\t0.3414\tF1:\t0.3447 *\n",
      "6 / 30: Train Loss:\t11.5251\tVal Loss:\t1.8337\tAccuracy:\t0.3523\tF1:\t0.3705 *\n",
      "7 / 30: Train Loss:\t9.0783\tVal Loss:\t1.7135\tAccuracy:\t0.4223\tF1:\t0.4288 *\n",
      "8 / 30: Train Loss:\t7.3557\tVal Loss:\t1.9040\tAccuracy:\t0.4004\tF1:\t0.4063\n",
      "9 / 30: Train Loss:\t6.4608\tVal Loss:\t1.6113\tAccuracy:\t0.4814\tF1:\t0.4768 *\n",
      "10 / 30: Train Loss:\t3.8083\tVal Loss:\t1.6515\tAccuracy:\t0.4792\tF1:\t0.4672\n",
      "11 / 30: Train Loss:\t3.0340\tVal Loss:\t1.6804\tAccuracy:\t0.4595\tF1:\t0.4579\n",
      "12 / 30: Train Loss:\t2.2419\tVal Loss:\t1.6479\tAccuracy:\t0.5120\tF1:\t0.4888 *\n",
      "13 / 30: Train Loss:\t1.6120\tVal Loss:\t1.6438\tAccuracy:\t0.5120\tF1:\t0.4920 *\n",
      "14 / 30: Train Loss:\t1.1143\tVal Loss:\t1.6284\tAccuracy:\t0.5339\tF1:\t0.5057 *\n",
      "15 / 30: Train Loss:\t1.0415\tVal Loss:\t1.6230\tAccuracy:\t0.5536\tF1:\t0.5101 *\n",
      "16 / 30: Train Loss:\t0.6762\tVal Loss:\t1.6596\tAccuracy:\t0.5274\tF1:\t0.5015\n",
      "17 / 30: Train Loss:\t0.6705\tVal Loss:\t1.6979\tAccuracy:\t0.5186\tF1:\t0.5147 *\n",
      "18 / 30: Train Loss:\t0.5906\tVal Loss:\t1.9199\tAccuracy:\t0.4858\tF1:\t0.4818\n",
      "19 / 30: Train Loss:\t0.4220\tVal Loss:\t1.6860\tAccuracy:\t0.5142\tF1:\t0.5026\n",
      "20 / 30: Train Loss:\t0.3474\tVal Loss:\t1.6210\tAccuracy:\t0.5361\tF1:\t0.5255 *\n",
      "21 / 30: Train Loss:\t0.3044\tVal Loss:\t1.6708\tAccuracy:\t0.5405\tF1:\t0.5206\n",
      "22 / 30: Train Loss:\t0.3001\tVal Loss:\t1.7127\tAccuracy:\t0.5274\tF1:\t0.5126\n",
      "23 / 30: Train Loss:\t0.2845\tVal Loss:\t1.7372\tAccuracy:\t0.5230\tF1:\t0.5113\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.62      0.52      0.57        67\n",
      "               anecdote       0.81      0.67      0.73        43\n",
      "         cherry picking       0.86      0.32      0.47        56\n",
      "      conspiracy theory       0.60      0.85      0.70        39\n",
      "           fake experts       0.56      0.42      0.48        12\n",
      "           false choice       0.54      0.54      0.54        13\n",
      "      false equivalence       0.24      0.64      0.35        14\n",
      "impossible expectations       0.40      0.57      0.47        37\n",
      "      misrepresentation       0.38      0.45      0.41        38\n",
      "     oversimplification       0.60      0.58      0.59        36\n",
      "           single cause       0.60      0.51      0.55        57\n",
      "     slothful induction       0.43      0.47      0.45        45\n",
      "\n",
      "               accuracy                           0.54       457\n",
      "              macro avg       0.55      0.54      0.53       457\n",
      "           weighted avg       0.59      0.54      0.54       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.64      0.43      0.52        37\n",
      "               anecdote       0.80      0.83      0.82        24\n",
      "         cherry picking       0.62      0.26      0.36        31\n",
      "      conspiracy theory       0.62      0.91      0.74        22\n",
      "           fake experts       0.60      0.43      0.50         7\n",
      "           false choice       0.38      0.43      0.40         7\n",
      "      false equivalence       0.10      0.25      0.14         8\n",
      "impossible expectations       0.62      0.86      0.72        21\n",
      "      misrepresentation       0.58      0.68      0.62        22\n",
      "     oversimplification       0.42      0.70      0.53        20\n",
      "           single cause       0.59      0.41      0.48        32\n",
      "     slothful induction       0.39      0.28      0.33        25\n",
      "\n",
      "               accuracy                           0.54       256\n",
      "              macro avg       0.53      0.54      0.51       256\n",
      "           weighted avg       0.57      0.54      0.53       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t25.6681\tVal Loss:\t2.4805\tAccuracy:\t0.0481\tF1:\t0.0414 *\n",
      "2 / 30: Train Loss:\t20.0781\tVal Loss:\t2.4035\tAccuracy:\t0.0853\tF1:\t0.0868 *\n",
      "3 / 30: Train Loss:\t18.5970\tVal Loss:\t2.2800\tAccuracy:\t0.1532\tF1:\t0.1611 *\n",
      "4 / 30: Train Loss:\t15.5086\tVal Loss:\t2.0621\tAccuracy:\t0.2801\tF1:\t0.2816 *\n",
      "5 / 30: Train Loss:\t12.2179\tVal Loss:\t1.9339\tAccuracy:\t0.3042\tF1:\t0.3139 *\n",
      "6 / 30: Train Loss:\t9.5236\tVal Loss:\t1.8239\tAccuracy:\t0.3370\tF1:\t0.3547 *\n",
      "7 / 30: Train Loss:\t7.8784\tVal Loss:\t1.7470\tAccuracy:\t0.3589\tF1:\t0.3676 *\n",
      "8 / 30: Train Loss:\t6.4253\tVal Loss:\t1.7554\tAccuracy:\t0.3786\tF1:\t0.3943 *\n",
      "9 / 30: Train Loss:\t5.0203\tVal Loss:\t1.6836\tAccuracy:\t0.4354\tF1:\t0.4368 *\n",
      "10 / 30: Train Loss:\t3.3715\tVal Loss:\t1.6344\tAccuracy:\t0.4595\tF1:\t0.4452 *\n",
      "11 / 30: Train Loss:\t2.6341\tVal Loss:\t1.5245\tAccuracy:\t0.4814\tF1:\t0.4716 *\n",
      "12 / 30: Train Loss:\t2.0983\tVal Loss:\t1.6188\tAccuracy:\t0.4814\tF1:\t0.4693\n",
      "13 / 30: Train Loss:\t1.5451\tVal Loss:\t1.5652\tAccuracy:\t0.5120\tF1:\t0.4967 *\n",
      "14 / 30: Train Loss:\t1.1132\tVal Loss:\t1.5880\tAccuracy:\t0.5055\tF1:\t0.4893\n",
      "15 / 30: Train Loss:\t0.9199\tVal Loss:\t1.6469\tAccuracy:\t0.4486\tF1:\t0.4440\n",
      "16 / 30: Train Loss:\t0.6490\tVal Loss:\t1.6776\tAccuracy:\t0.4464\tF1:\t0.4351\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.66      0.31      0.42        67\n",
      "               anecdote       0.90      0.60      0.72        43\n",
      "         cherry picking       0.68      0.38      0.48        56\n",
      "      conspiracy theory       0.58      0.79      0.67        39\n",
      "           fake experts       0.50      0.50      0.50        12\n",
      "           false choice       0.23      0.46      0.31        13\n",
      "      false equivalence       0.30      0.50      0.38        14\n",
      "impossible expectations       0.44      0.54      0.49        37\n",
      "      misrepresentation       0.42      0.42      0.42        38\n",
      "     oversimplification       0.60      0.58      0.59        36\n",
      "           single cause       0.42      0.74      0.54        57\n",
      "     slothful induction       0.52      0.38      0.44        45\n",
      "\n",
      "               accuracy                           0.51       457\n",
      "              macro avg       0.52      0.52      0.50       457\n",
      "           weighted avg       0.56      0.51      0.51       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.82      0.38      0.52        37\n",
      "               anecdote       0.80      0.67      0.73        24\n",
      "         cherry picking       0.55      0.19      0.29        31\n",
      "      conspiracy theory       0.62      0.82      0.71        22\n",
      "           fake experts       0.43      0.43      0.43         7\n",
      "           false choice       0.19      0.43      0.26         7\n",
      "      false equivalence       0.14      0.25      0.18         8\n",
      "impossible expectations       0.61      0.81      0.69        21\n",
      "      misrepresentation       0.50      0.41      0.45        22\n",
      "     oversimplification       0.56      0.70      0.62        20\n",
      "           single cause       0.33      0.59      0.42        32\n",
      "     slothful induction       0.23      0.12      0.16        25\n",
      "\n",
      "               accuracy                           0.48       256\n",
      "              macro avg       0.48      0.48      0.45       256\n",
      "           weighted avg       0.53      0.48      0.48       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t20.0000\tVal Loss:\t2.4855\tAccuracy:\t0.0481\tF1:\t0.0302 *\n",
      "2 / 30: Train Loss:\t14.1917\tVal Loss:\t2.4203\tAccuracy:\t0.0875\tF1:\t0.0877 *\n",
      "3 / 30: Train Loss:\t12.9548\tVal Loss:\t2.3189\tAccuracy:\t0.1335\tF1:\t0.1445 *\n",
      "4 / 30: Train Loss:\t10.6915\tVal Loss:\t2.1232\tAccuracy:\t0.2407\tF1:\t0.2735 *\n",
      "5 / 30: Train Loss:\t8.2700\tVal Loss:\t1.9837\tAccuracy:\t0.2888\tF1:\t0.3095 *\n",
      "6 / 30: Train Loss:\t6.4008\tVal Loss:\t1.9189\tAccuracy:\t0.2910\tF1:\t0.3070\n",
      "7 / 30: Train Loss:\t4.9913\tVal Loss:\t1.8202\tAccuracy:\t0.3370\tF1:\t0.3502 *\n",
      "8 / 30: Train Loss:\t3.6964\tVal Loss:\t1.6715\tAccuracy:\t0.3851\tF1:\t0.4016 *\n",
      "9 / 30: Train Loss:\t3.3419\tVal Loss:\t1.7256\tAccuracy:\t0.3764\tF1:\t0.3736\n",
      "10 / 30: Train Loss:\t2.3196\tVal Loss:\t1.6507\tAccuracy:\t0.3917\tF1:\t0.3846\n",
      "11 / 30: Train Loss:\t1.8885\tVal Loss:\t1.5880\tAccuracy:\t0.4267\tF1:\t0.4261 *\n",
      "12 / 30: Train Loss:\t1.3761\tVal Loss:\t1.6306\tAccuracy:\t0.4486\tF1:\t0.4432 *\n",
      "13 / 30: Train Loss:\t1.0155\tVal Loss:\t1.5742\tAccuracy:\t0.4748\tF1:\t0.4570 *\n",
      "14 / 30: Train Loss:\t0.6151\tVal Loss:\t1.5830\tAccuracy:\t0.4770\tF1:\t0.4623 *\n",
      "15 / 30: Train Loss:\t0.5981\tVal Loss:\t1.6140\tAccuracy:\t0.4508\tF1:\t0.4442\n",
      "16 / 30: Train Loss:\t0.4098\tVal Loss:\t1.6288\tAccuracy:\t0.4267\tF1:\t0.4250\n",
      "17 / 30: Train Loss:\t0.3545\tVal Loss:\t1.5360\tAccuracy:\t0.5033\tF1:\t0.5017 *\n",
      "18 / 30: Train Loss:\t0.3393\tVal Loss:\t1.6770\tAccuracy:\t0.4420\tF1:\t0.4287\n",
      "19 / 30: Train Loss:\t0.2404\tVal Loss:\t1.5856\tAccuracy:\t0.4661\tF1:\t0.4497\n",
      "20 / 30: Train Loss:\t0.3941\tVal Loss:\t1.6941\tAccuracy:\t0.4508\tF1:\t0.4546\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.64      0.42      0.50        67\n",
      "               anecdote       0.89      0.58      0.70        43\n",
      "         cherry picking       0.61      0.30      0.40        56\n",
      "      conspiracy theory       0.67      0.72      0.69        39\n",
      "           fake experts       0.53      0.75      0.62        12\n",
      "           false choice       0.27      0.54      0.36        13\n",
      "      false equivalence       0.19      0.50      0.28        14\n",
      "impossible expectations       0.61      0.51      0.56        37\n",
      "      misrepresentation       0.33      0.58      0.42        38\n",
      "     oversimplification       0.59      0.56      0.57        36\n",
      "           single cause       0.48      0.56      0.52        57\n",
      "     slothful induction       0.43      0.36      0.39        45\n",
      "\n",
      "               accuracy                           0.50       457\n",
      "              macro avg       0.52      0.53      0.50       457\n",
      "           weighted avg       0.56      0.50      0.51       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.62      0.43      0.51        37\n",
      "               anecdote       0.94      0.62      0.75        24\n",
      "         cherry picking       0.62      0.26      0.36        31\n",
      "      conspiracy theory       0.58      0.64      0.61        22\n",
      "           fake experts       0.50      0.71      0.59         7\n",
      "           false choice       0.25      0.43      0.32         7\n",
      "      false equivalence       0.09      0.25      0.13         8\n",
      "impossible expectations       0.67      0.57      0.62        21\n",
      "      misrepresentation       0.41      0.59      0.48        22\n",
      "     oversimplification       0.52      0.75      0.61        20\n",
      "           single cause       0.37      0.44      0.40        32\n",
      "     slothful induction       0.25      0.16      0.20        25\n",
      "\n",
      "               accuracy                           0.47       256\n",
      "              macro avg       0.48      0.49      0.46       256\n",
      "           weighted avg       0.53      0.47      0.48       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t13.3194\tVal Loss:\t2.4877\tAccuracy:\t0.0613\tF1:\t0.0348 *\n",
      "2 / 30: Train Loss:\t7.4155\tVal Loss:\t2.4527\tAccuracy:\t0.0656\tF1:\t0.0518 *\n",
      "3 / 30: Train Loss:\t6.8128\tVal Loss:\t2.3988\tAccuracy:\t0.0810\tF1:\t0.0880 *\n",
      "4 / 30: Train Loss:\t6.0414\tVal Loss:\t2.3244\tAccuracy:\t0.1291\tF1:\t0.1461 *\n",
      "5 / 30: Train Loss:\t4.8900\tVal Loss:\t2.1968\tAccuracy:\t0.2144\tF1:\t0.2520 *\n",
      "6 / 30: Train Loss:\t4.0430\tVal Loss:\t2.1113\tAccuracy:\t0.2538\tF1:\t0.2873 *\n",
      "7 / 30: Train Loss:\t3.1220\tVal Loss:\t2.0042\tAccuracy:\t0.2932\tF1:\t0.3033 *\n",
      "8 / 30: Train Loss:\t2.5315\tVal Loss:\t1.8996\tAccuracy:\t0.3107\tF1:\t0.3363 *\n",
      "9 / 30: Train Loss:\t2.1274\tVal Loss:\t1.8574\tAccuracy:\t0.3370\tF1:\t0.3457 *\n",
      "10 / 30: Train Loss:\t1.5788\tVal Loss:\t1.8067\tAccuracy:\t0.3545\tF1:\t0.3536 *\n",
      "11 / 30: Train Loss:\t1.5806\tVal Loss:\t1.7579\tAccuracy:\t0.3392\tF1:\t0.3425\n",
      "12 / 30: Train Loss:\t1.1282\tVal Loss:\t1.6648\tAccuracy:\t0.4530\tF1:\t0.4436 *\n",
      "13 / 30: Train Loss:\t0.7817\tVal Loss:\t1.7353\tAccuracy:\t0.4026\tF1:\t0.4015\n",
      "14 / 30: Train Loss:\t0.6873\tVal Loss:\t1.6288\tAccuracy:\t0.4420\tF1:\t0.4315\n",
      "15 / 30: Train Loss:\t0.6107\tVal Loss:\t1.6710\tAccuracy:\t0.4179\tF1:\t0.4120\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.60      0.43      0.50        67\n",
      "               anecdote       0.76      0.65      0.70        43\n",
      "         cherry picking       0.46      0.11      0.17        56\n",
      "      conspiracy theory       0.49      0.72      0.58        39\n",
      "           fake experts       0.62      0.42      0.50        12\n",
      "           false choice       0.38      0.62      0.47        13\n",
      "      false equivalence       0.19      0.29      0.23        14\n",
      "impossible expectations       0.38      0.54      0.44        37\n",
      "      misrepresentation       0.24      0.50      0.33        38\n",
      "     oversimplification       0.49      0.56      0.52        36\n",
      "           single cause       0.59      0.42      0.49        57\n",
      "     slothful induction       0.41      0.36      0.38        45\n",
      "\n",
      "               accuracy                           0.45       457\n",
      "              macro avg       0.47      0.47      0.44       457\n",
      "           weighted avg       0.49      0.45      0.45       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.73      0.59      0.66        37\n",
      "               anecdote       0.61      0.71      0.65        24\n",
      "         cherry picking       0.50      0.10      0.16        31\n",
      "      conspiracy theory       0.59      0.73      0.65        22\n",
      "           fake experts       0.75      0.43      0.55         7\n",
      "           false choice       0.27      0.43      0.33         7\n",
      "      false equivalence       0.11      0.12      0.12         8\n",
      "impossible expectations       0.53      0.90      0.67        21\n",
      "      misrepresentation       0.41      0.68      0.51        22\n",
      "     oversimplification       0.48      0.70      0.57        20\n",
      "           single cause       0.48      0.34      0.40        32\n",
      "     slothful induction       0.38      0.24      0.29        25\n",
      "\n",
      "               accuracy                           0.51       256\n",
      "              macro avg       0.49      0.50      0.46       256\n",
      "           weighted avg       0.52      0.51      0.48       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t102.0945\tVal Loss:\t2.4711\tAccuracy:\t0.3632\tF1:\t0.3459 *\n",
      "2 / 30: Train Loss:\t14.6911\tVal Loss:\t1.5979\tAccuracy:\t0.5602\tF1:\t0.5397 *\n",
      "3 / 30: Train Loss:\t5.1869\tVal Loss:\t2.4140\tAccuracy:\t0.5077\tF1:\t0.5006\n",
      "4 / 30: Train Loss:\t10.5564\tVal Loss:\t3.0940\tAccuracy:\t0.4267\tF1:\t0.4271\n",
      "5 / 30: Train Loss:\t6.0418\tVal Loss:\t2.7342\tAccuracy:\t0.4902\tF1:\t0.4875\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.57      0.58      0.57        67\n",
      "               anecdote       0.71      0.84      0.77        43\n",
      "         cherry picking       0.67      0.25      0.36        56\n",
      "      conspiracy theory       0.63      0.79      0.70        39\n",
      "           fake experts       0.75      0.50      0.60        12\n",
      "           false choice       0.42      0.77      0.54        13\n",
      "      false equivalence       0.33      0.21      0.26        14\n",
      "impossible expectations       0.67      0.54      0.60        37\n",
      "      misrepresentation       0.69      0.24      0.35        38\n",
      "     oversimplification       0.75      0.58      0.66        36\n",
      "           single cause       0.61      0.61      0.61        57\n",
      "     slothful induction       0.33      0.71      0.45        45\n",
      "\n",
      "               accuracy                           0.56       457\n",
      "              macro avg       0.59      0.55      0.54       457\n",
      "           weighted avg       0.61      0.56      0.55       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.65      0.76      0.70        37\n",
      "               anecdote       0.69      0.83      0.75        24\n",
      "         cherry picking       0.44      0.13      0.20        31\n",
      "      conspiracy theory       0.68      0.59      0.63        22\n",
      "           fake experts       1.00      0.57      0.73         7\n",
      "           false choice       0.13      0.29      0.18         7\n",
      "      false equivalence       0.14      0.12      0.13         8\n",
      "impossible expectations       0.58      0.71      0.64        21\n",
      "      misrepresentation       0.75      0.27      0.40        22\n",
      "     oversimplification       0.55      0.60      0.57        20\n",
      "           single cause       0.57      0.53      0.55        32\n",
      "     slothful induction       0.25      0.44      0.32        25\n",
      "\n",
      "               accuracy                           0.52       256\n",
      "              macro avg       0.54      0.49      0.48       256\n",
      "           weighted avg       0.56      0.52      0.51       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t106.4590\tVal Loss:\t1.9401\tAccuracy:\t0.3982\tF1:\t0.3775 *\n",
      "2 / 30: Train Loss:\t15.8555\tVal Loss:\t2.5981\tAccuracy:\t0.4114\tF1:\t0.3818 *\n",
      "3 / 30: Train Loss:\t6.3178\tVal Loss:\t2.3193\tAccuracy:\t0.5011\tF1:\t0.4894 *\n",
      "4 / 30: Train Loss:\t6.1056\tVal Loss:\t3.0187\tAccuracy:\t0.4398\tF1:\t0.4303\n",
      "5 / 30: Train Loss:\t3.6230\tVal Loss:\t2.8803\tAccuracy:\t0.4420\tF1:\t0.4428\n",
      "6 / 30: Train Loss:\t2.6105\tVal Loss:\t2.9753\tAccuracy:\t0.4770\tF1:\t0.4815\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.59      0.43      0.50        67\n",
      "               anecdote       1.00      0.40      0.57        43\n",
      "         cherry picking       0.37      0.50      0.43        56\n",
      "      conspiracy theory       0.77      0.77      0.77        39\n",
      "           fake experts       0.64      0.75      0.69        12\n",
      "           false choice       1.00      0.62      0.76        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.88      0.41      0.56        37\n",
      "      misrepresentation       0.27      0.87      0.41        38\n",
      "     oversimplification       0.61      0.56      0.58        36\n",
      "           single cause       0.49      0.68      0.57        57\n",
      "     slothful induction       1.00      0.02      0.04        45\n",
      "\n",
      "               accuracy                           0.50       457\n",
      "              macro avg       0.63      0.50      0.49       457\n",
      "           weighted avg       0.64      0.50      0.48       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.59      0.68        37\n",
      "               anecdote       1.00      0.58      0.74        24\n",
      "         cherry picking       0.52      0.48      0.50        31\n",
      "      conspiracy theory       0.76      0.59      0.67        22\n",
      "           fake experts       0.80      0.57      0.67         7\n",
      "           false choice       0.67      0.29      0.40         7\n",
      "      false equivalence       1.00      0.12      0.22         8\n",
      "impossible expectations       0.85      0.52      0.65        21\n",
      "      misrepresentation       0.24      0.77      0.37        22\n",
      "     oversimplification       0.50      0.60      0.55        20\n",
      "           single cause       0.51      0.81      0.63        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.54       256\n",
      "              macro avg       0.64      0.50      0.50       256\n",
      "           weighted avg       0.60      0.54      0.53       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t106.8290\tVal Loss:\t2.1779\tAccuracy:\t0.3457\tF1:\t0.3036 *\n",
      "2 / 30: Train Loss:\t12.5890\tVal Loss:\t2.1887\tAccuracy:\t0.3786\tF1:\t0.3915 *\n",
      "3 / 30: Train Loss:\t7.4262\tVal Loss:\t2.6263\tAccuracy:\t0.4333\tF1:\t0.3655\n",
      "4 / 30: Train Loss:\t5.7980\tVal Loss:\t2.3255\tAccuracy:\t0.4442\tF1:\t0.4442 *\n",
      "5 / 30: Train Loss:\t3.8827\tVal Loss:\t2.8876\tAccuracy:\t0.4398\tF1:\t0.4332\n",
      "6 / 30: Train Loss:\t4.0170\tVal Loss:\t2.5209\tAccuracy:\t0.4661\tF1:\t0.4517 *\n",
      "7 / 30: Train Loss:\t3.2462\tVal Loss:\t4.3205\tAccuracy:\t0.3479\tF1:\t0.3050\n",
      "8 / 30: Train Loss:\t2.3075\tVal Loss:\t2.4623\tAccuracy:\t0.5295\tF1:\t0.5453 *\n",
      "9 / 30: Train Loss:\t0.9785\tVal Loss:\t1.8751\tAccuracy:\t0.5886\tF1:\t0.5722 *\n",
      "10 / 30: Train Loss:\t0.5968\tVal Loss:\t1.9179\tAccuracy:\t0.5602\tF1:\t0.5466\n",
      "11 / 30: Train Loss:\t0.8513\tVal Loss:\t2.4548\tAccuracy:\t0.5492\tF1:\t0.5261\n",
      "12 / 30: Train Loss:\t0.9071\tVal Loss:\t2.2775\tAccuracy:\t0.5733\tF1:\t0.5512\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.47      0.76      0.58        67\n",
      "               anecdote       0.88      0.70      0.78        43\n",
      "         cherry picking       0.64      0.45      0.53        56\n",
      "      conspiracy theory       0.76      0.72      0.74        39\n",
      "           fake experts       0.50      0.50      0.50        12\n",
      "           false choice       0.90      0.69      0.78        13\n",
      "      false equivalence       0.25      0.14      0.18        14\n",
      "impossible expectations       0.63      0.51      0.57        37\n",
      "      misrepresentation       0.53      0.47      0.50        38\n",
      "     oversimplification       0.56      0.69      0.62        36\n",
      "           single cause       0.59      0.61      0.60        57\n",
      "     slothful induction       0.51      0.47      0.49        45\n",
      "\n",
      "               accuracy                           0.59       457\n",
      "              macro avg       0.60      0.56      0.57       457\n",
      "           weighted avg       0.61      0.59      0.59       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.48      0.78      0.59        37\n",
      "               anecdote       0.86      0.79      0.83        24\n",
      "         cherry picking       0.58      0.45      0.51        31\n",
      "      conspiracy theory       0.73      0.50      0.59        22\n",
      "           fake experts       0.67      0.57      0.62         7\n",
      "           false choice       0.57      0.57      0.57         7\n",
      "      false equivalence       0.25      0.25      0.25         8\n",
      "impossible expectations       0.67      0.57      0.62        21\n",
      "      misrepresentation       0.59      0.59      0.59        22\n",
      "     oversimplification       0.49      0.85      0.62        20\n",
      "           single cause       0.65      0.53      0.59        32\n",
      "     slothful induction       0.50      0.24      0.32        25\n",
      "\n",
      "               accuracy                           0.58       256\n",
      "              macro avg       0.59      0.56      0.56       256\n",
      "           weighted avg       0.60      0.58      0.57       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t105.0740\tVal Loss:\t2.4627\tAccuracy:\t0.3260\tF1:\t0.3127 *\n",
      "2 / 30: Train Loss:\t8.9022\tVal Loss:\t1.9056\tAccuracy:\t0.4639\tF1:\t0.3918 *\n",
      "3 / 30: Train Loss:\t4.8087\tVal Loss:\t1.9258\tAccuracy:\t0.4311\tF1:\t0.4050 *\n",
      "4 / 30: Train Loss:\t5.7753\tVal Loss:\t1.8913\tAccuracy:\t0.5514\tF1:\t0.5030 *\n",
      "5 / 30: Train Loss:\t4.6854\tVal Loss:\t3.2320\tAccuracy:\t0.3589\tF1:\t0.3908\n",
      "6 / 30: Train Loss:\t5.8892\tVal Loss:\t3.7771\tAccuracy:\t0.4070\tF1:\t0.3954\n",
      "7 / 30: Train Loss:\t5.0823\tVal Loss:\t4.8128\tAccuracy:\t0.3239\tF1:\t0.3202\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.57      0.51      0.54        67\n",
      "               anecdote       0.91      0.72      0.81        43\n",
      "         cherry picking       0.54      0.68      0.60        56\n",
      "      conspiracy theory       0.64      0.69      0.67        39\n",
      "           fake experts       0.40      0.83      0.54        12\n",
      "           false choice       0.33      0.85      0.48        13\n",
      "      false equivalence       0.25      0.07      0.11        14\n",
      "impossible expectations       0.41      0.51      0.46        37\n",
      "      misrepresentation       0.50      0.39      0.44        38\n",
      "     oversimplification       0.67      0.50      0.57        36\n",
      "           single cause       0.54      0.75      0.63        57\n",
      "     slothful induction       0.71      0.11      0.19        45\n",
      "\n",
      "               accuracy                           0.55       457\n",
      "              macro avg       0.54      0.55      0.50       457\n",
      "           weighted avg       0.58      0.55      0.53       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.61      0.62      0.61        37\n",
      "               anecdote       0.89      0.67      0.76        24\n",
      "         cherry picking       0.40      0.55      0.46        31\n",
      "      conspiracy theory       0.74      0.64      0.68        22\n",
      "           fake experts       0.64      1.00      0.78         7\n",
      "           false choice       0.16      0.43      0.23         7\n",
      "      false equivalence       1.00      0.25      0.40         8\n",
      "impossible expectations       0.56      0.67      0.61        21\n",
      "      misrepresentation       0.47      0.41      0.44        22\n",
      "     oversimplification       0.48      0.55      0.51        20\n",
      "           single cause       0.66      0.78      0.71        32\n",
      "     slothful induction       1.00      0.04      0.08        25\n",
      "\n",
      "               accuracy                           0.55       256\n",
      "              macro avg       0.63      0.55      0.52       256\n",
      "           weighted avg       0.64      0.55      0.54       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t29.1126\tVal Loss:\t2.1074\tAccuracy:\t0.2735\tF1:\t0.1988 *\n",
      "2 / 30: Train Loss:\t23.1855\tVal Loss:\t2.1239\tAccuracy:\t0.2691\tF1:\t0.2181 *\n",
      "3 / 30: Train Loss:\t23.4847\tVal Loss:\t2.5224\tAccuracy:\t0.0788\tF1:\t0.0213\n",
      "4 / 30: Train Loss:\t25.2108\tVal Loss:\t2.5524\tAccuracy:\t0.0700\tF1:\t0.0478\n",
      "5 / 30: Train Loss:\t24.3326\tVal Loss:\t2.5646\tAccuracy:\t0.1028\tF1:\t0.0570\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.47      0.86      0.61        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.20      0.82      0.33        39\n",
      "           fake experts       1.00      0.25      0.40        12\n",
      "           false choice       0.57      0.31      0.40        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.18      0.76      0.29        37\n",
      "      misrepresentation       0.23      0.13      0.17        38\n",
      "     oversimplification       0.67      0.11      0.19        36\n",
      "           single cause       0.36      0.18      0.24        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.27       457\n",
      "              macro avg       0.31      0.28      0.22       457\n",
      "           weighted avg       0.23      0.27      0.19       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.46      0.88      0.60        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.21      0.82      0.34        22\n",
      "           fake experts       1.00      0.14      0.25         7\n",
      "           false choice       1.00      0.14      0.25         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.20      0.81      0.31        21\n",
      "      misrepresentation       0.36      0.23      0.28        22\n",
      "     oversimplification       0.33      0.05      0.09        20\n",
      "           single cause       0.30      0.19      0.23        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.27       256\n",
      "              macro avg       0.32      0.27      0.20       256\n",
      "           weighted avg       0.23      0.27      0.18       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t25.5495\tVal Loss:\t2.0333\tAccuracy:\t0.2976\tF1:\t0.2565 *\n",
      "2 / 30: Train Loss:\t20.0294\tVal Loss:\t2.2595\tAccuracy:\t0.2604\tF1:\t0.1929\n",
      "3 / 30: Train Loss:\t22.1518\tVal Loss:\t2.5065\tAccuracy:\t0.1597\tF1:\t0.0770\n",
      "4 / 30: Train Loss:\t22.3698\tVal Loss:\t2.4978\tAccuracy:\t0.1400\tF1:\t0.0972\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.50      0.19      0.28        67\n",
      "               anecdote       0.33      0.88      0.48        43\n",
      "         cherry picking       0.50      0.02      0.03        56\n",
      "      conspiracy theory       0.22      0.79      0.35        39\n",
      "           fake experts       0.70      0.58      0.64        12\n",
      "           false choice       1.00      0.23      0.38        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.25      0.59      0.35        37\n",
      "      misrepresentation       0.22      0.37      0.27        38\n",
      "     oversimplification       0.62      0.14      0.23        36\n",
      "           single cause       1.00      0.04      0.07        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.30       457\n",
      "              macro avg       0.45      0.32      0.26       457\n",
      "           weighted avg       0.44      0.30      0.23       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.80      0.32      0.46        37\n",
      "               anecdote       0.30      0.96      0.46        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.26      0.82      0.40        22\n",
      "           fake experts       1.00      0.14      0.25         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.50      0.12      0.20         8\n",
      "impossible expectations       0.26      0.71      0.38        21\n",
      "      misrepresentation       0.24      0.27      0.26        22\n",
      "     oversimplification       0.60      0.15      0.24        20\n",
      "           single cause       0.25      0.03      0.06        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.31       256\n",
      "              macro avg       0.35      0.29      0.23       256\n",
      "           weighted avg       0.33      0.31      0.24       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t19.9808\tVal Loss:\t2.1320\tAccuracy:\t0.2823\tF1:\t0.2154 *\n",
      "2 / 30: Train Loss:\t14.8263\tVal Loss:\t2.2078\tAccuracy:\t0.2429\tF1:\t0.1962\n",
      "3 / 30: Train Loss:\t15.8789\tVal Loss:\t2.4131\tAccuracy:\t0.1554\tF1:\t0.1063\n",
      "4 / 30: Train Loss:\t18.6087\tVal Loss:\t2.5177\tAccuracy:\t0.0832\tF1:\t0.0221\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.44      0.16      0.24        67\n",
      "               anecdote       0.28      0.86      0.42        43\n",
      "         cherry picking       0.33      0.02      0.03        56\n",
      "      conspiracy theory       0.36      0.72      0.48        39\n",
      "           fake experts       0.12      0.67      0.21        12\n",
      "           false choice       0.33      0.23      0.27        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.24      0.68      0.35        37\n",
      "      misrepresentation       0.21      0.13      0.16        38\n",
      "     oversimplification       0.62      0.14      0.23        36\n",
      "           single cause       0.75      0.11      0.18        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.28       457\n",
      "              macro avg       0.31      0.31      0.22       457\n",
      "           weighted avg       0.35      0.28      0.22       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.71      0.27      0.39        37\n",
      "               anecdote       0.28      0.96      0.44        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.41      0.73      0.52        22\n",
      "           fake experts       0.18      0.86      0.29         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       1.00      0.12      0.22         8\n",
      "impossible expectations       0.26      0.76      0.39        21\n",
      "      misrepresentation       0.25      0.14      0.18        22\n",
      "     oversimplification       0.50      0.10      0.17        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.30       256\n",
      "              macro avg       0.30      0.33      0.22       256\n",
      "           weighted avg       0.28      0.30      0.22       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t13.3147\tVal Loss:\t2.1266\tAccuracy:\t0.2560\tF1:\t0.2241 *\n",
      "2 / 30: Train Loss:\t8.3470\tVal Loss:\t2.2280\tAccuracy:\t0.2166\tF1:\t0.1735\n",
      "3 / 30: Train Loss:\t8.7788\tVal Loss:\t2.3781\tAccuracy:\t0.1554\tF1:\t0.1124\n",
      "4 / 30: Train Loss:\t7.7095\tVal Loss:\t2.2562\tAccuracy:\t0.1488\tF1:\t0.1413\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.40      0.34      0.37        67\n",
      "               anecdote       0.70      0.60      0.65        43\n",
      "         cherry picking       0.17      0.02      0.03        56\n",
      "      conspiracy theory       0.57      0.51      0.54        39\n",
      "           fake experts       0.08      0.83      0.15        12\n",
      "           false choice       0.14      0.08      0.10        13\n",
      "      false equivalence       0.05      0.14      0.07        14\n",
      "impossible expectations       0.20      0.54      0.30        37\n",
      "      misrepresentation       0.17      0.18      0.18        38\n",
      "     oversimplification       0.70      0.19      0.30        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.26       457\n",
      "              macro avg       0.27      0.29      0.22       457\n",
      "           weighted avg       0.29      0.26      0.24       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.55      0.43      0.48        37\n",
      "               anecdote       0.57      0.50      0.53        24\n",
      "         cherry picking       0.25      0.03      0.06        31\n",
      "      conspiracy theory       0.56      0.41      0.47        22\n",
      "           fake experts       0.09      0.86      0.16         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.12      0.38      0.18         8\n",
      "impossible expectations       0.26      0.81      0.40        21\n",
      "      misrepresentation       0.18      0.14      0.15        22\n",
      "     oversimplification       0.33      0.10      0.15        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.27       256\n",
      "              macro avg       0.24      0.30      0.22       256\n",
      "           weighted avg       0.28      0.27      0.24       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t29.8785\tVal Loss:\t2.3619\tAccuracy:\t0.2298\tF1:\t0.1918 *\n",
      "2 / 30: Train Loss:\t17.6342\tVal Loss:\t1.6656\tAccuracy:\t0.4748\tF1:\t0.4455 *\n",
      "3 / 30: Train Loss:\t6.1793\tVal Loss:\t1.5575\tAccuracy:\t0.4967\tF1:\t0.4868 *\n",
      "4 / 30: Train Loss:\t1.9191\tVal Loss:\t1.6292\tAccuracy:\t0.4902\tF1:\t0.4725\n",
      "5 / 30: Train Loss:\t1.8796\tVal Loss:\t1.8009\tAccuracy:\t0.4442\tF1:\t0.4400\n",
      "6 / 30: Train Loss:\t1.5334\tVal Loss:\t1.8423\tAccuracy:\t0.4530\tF1:\t0.4730\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.55      0.36      0.43        67\n",
      "               anecdote       0.82      0.72      0.77        43\n",
      "         cherry picking       0.62      0.46      0.53        56\n",
      "      conspiracy theory       0.68      0.49      0.57        39\n",
      "           fake experts       0.45      0.83      0.59        12\n",
      "           false choice       0.35      0.69      0.46        13\n",
      "      false equivalence       0.20      0.14      0.17        14\n",
      "impossible expectations       0.45      0.57      0.50        37\n",
      "      misrepresentation       0.32      0.68      0.43        38\n",
      "     oversimplification       0.56      0.53      0.54        36\n",
      "           single cause       0.67      0.46      0.54        57\n",
      "     slothful induction       0.31      0.31      0.31        45\n",
      "\n",
      "               accuracy                           0.50       457\n",
      "              macro avg       0.50      0.52      0.49       457\n",
      "           weighted avg       0.54      0.50      0.50       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.54      0.38      0.44        37\n",
      "               anecdote       0.78      0.75      0.77        24\n",
      "         cherry picking       0.67      0.32      0.43        31\n",
      "      conspiracy theory       0.67      0.27      0.39        22\n",
      "           fake experts       0.43      0.43      0.43         7\n",
      "           false choice       0.18      0.57      0.28         7\n",
      "      false equivalence       0.20      0.12      0.15         8\n",
      "impossible expectations       0.72      0.62      0.67        21\n",
      "      misrepresentation       0.29      0.73      0.42        22\n",
      "     oversimplification       0.42      0.55      0.48        20\n",
      "           single cause       0.70      0.44      0.54        32\n",
      "     slothful induction       0.27      0.32      0.29        25\n",
      "\n",
      "               accuracy                           0.46       256\n",
      "              macro avg       0.49      0.46      0.44       256\n",
      "           weighted avg       0.54      0.46      0.47       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t22.7809\tVal Loss:\t2.6079\tAccuracy:\t0.0766\tF1:\t0.0462 *\n",
      "2 / 30: Train Loss:\t23.6462\tVal Loss:\t2.5815\tAccuracy:\t0.0788\tF1:\t0.0280\n",
      "3 / 30: Train Loss:\t22.4995\tVal Loss:\t2.5130\tAccuracy:\t0.0788\tF1:\t0.0418\n",
      "4 / 30: Train Loss:\t21.8150\tVal Loss:\t2.5134\tAccuracy:\t0.0656\tF1:\t0.0429\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       1.00      0.01      0.03        67\n",
      "               anecdote       1.00      0.05      0.09        43\n",
      "         cherry picking       0.08      0.02      0.03        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.03      0.08      0.05        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.07      0.07      0.07        14\n",
      "impossible expectations       0.08      0.03      0.04        37\n",
      "      misrepresentation       0.07      0.34      0.12        38\n",
      "     oversimplification       0.08      0.42      0.13        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.08       457\n",
      "              macro avg       0.20      0.08      0.05       457\n",
      "           weighted avg       0.27      0.08      0.04       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       1.00      0.05      0.09        22\n",
      "           fake experts       0.14      0.43      0.21         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.10      0.45      0.16        22\n",
      "     oversimplification       0.08      0.45      0.14        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.09       256\n",
      "              macro avg       0.11      0.11      0.05       256\n",
      "           weighted avg       0.10      0.09      0.04       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t19.2629\tVal Loss:\t2.3928\tAccuracy:\t0.1838\tF1:\t0.1291 *\n",
      "2 / 30: Train Loss:\t12.1847\tVal Loss:\t1.9488\tAccuracy:\t0.3742\tF1:\t0.3117 *\n",
      "3 / 30: Train Loss:\t5.5638\tVal Loss:\t1.8231\tAccuracy:\t0.4136\tF1:\t0.4234 *\n",
      "4 / 30: Train Loss:\t1.7520\tVal Loss:\t1.7038\tAccuracy:\t0.4530\tF1:\t0.4285 *\n",
      "5 / 30: Train Loss:\t0.4809\tVal Loss:\t1.5959\tAccuracy:\t0.4726\tF1:\t0.4558 *\n",
      "6 / 30: Train Loss:\t0.1713\tVal Loss:\t1.6929\tAccuracy:\t0.4354\tF1:\t0.4255\n",
      "7 / 30: Train Loss:\t0.0631\tVal Loss:\t1.5239\tAccuracy:\t0.5142\tF1:\t0.4997 *\n",
      "8 / 30: Train Loss:\t0.0102\tVal Loss:\t1.5145\tAccuracy:\t0.5252\tF1:\t0.5080 *\n",
      "9 / 30: Train Loss:\t0.0061\tVal Loss:\t1.5157\tAccuracy:\t0.5164\tF1:\t0.4987\n",
      "10 / 30: Train Loss:\t0.0048\tVal Loss:\t1.5158\tAccuracy:\t0.5208\tF1:\t0.5020\n",
      "11 / 30: Train Loss:\t0.0041\tVal Loss:\t1.5165\tAccuracy:\t0.5208\tF1:\t0.5023\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.47      0.52      0.49        67\n",
      "               anecdote       0.86      0.70      0.77        43\n",
      "         cherry picking       0.43      0.52      0.47        56\n",
      "      conspiracy theory       0.68      0.54      0.60        39\n",
      "           fake experts       0.44      0.58      0.50        12\n",
      "           false choice       0.80      0.62      0.70        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.54      0.51      0.53        37\n",
      "      misrepresentation       0.49      0.50      0.49        38\n",
      "     oversimplification       0.71      0.47      0.57        36\n",
      "           single cause       0.55      0.56      0.56        57\n",
      "     slothful induction       0.37      0.51      0.43        45\n",
      "\n",
      "               accuracy                           0.53       457\n",
      "              macro avg       0.53      0.50      0.51       457\n",
      "           weighted avg       0.54      0.53      0.53       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.48      0.59      0.53        37\n",
      "               anecdote       0.94      0.71      0.81        24\n",
      "         cherry picking       0.41      0.52      0.46        31\n",
      "      conspiracy theory       0.83      0.45      0.59        22\n",
      "           fake experts       0.50      0.43      0.46         7\n",
      "           false choice       0.67      0.29      0.40         7\n",
      "      false equivalence       1.00      0.12      0.22         8\n",
      "impossible expectations       0.69      0.52      0.59        21\n",
      "      misrepresentation       0.43      0.59      0.50        22\n",
      "     oversimplification       0.69      0.55      0.61        20\n",
      "           single cause       0.56      0.59      0.58        32\n",
      "     slothful induction       0.23      0.32      0.27        25\n",
      "\n",
      "               accuracy                           0.52       256\n",
      "              macro avg       0.62      0.47      0.50       256\n",
      "           weighted avg       0.58      0.52      0.53       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t11.3591\tVal Loss:\t1.9821\tAccuracy:\t0.3720\tF1:\t0.3429 *\n",
      "2 / 30: Train Loss:\t2.3739\tVal Loss:\t1.6758\tAccuracy:\t0.4354\tF1:\t0.4600 *\n",
      "3 / 30: Train Loss:\t0.4518\tVal Loss:\t1.5973\tAccuracy:\t0.4836\tF1:\t0.4346\n",
      "4 / 30: Train Loss:\t0.0846\tVal Loss:\t1.4610\tAccuracy:\t0.5011\tF1:\t0.4607 *\n",
      "5 / 30: Train Loss:\t0.1125\tVal Loss:\t1.5894\tAccuracy:\t0.4573\tF1:\t0.4702 *\n",
      "6 / 30: Train Loss:\t0.0340\tVal Loss:\t1.4403\tAccuracy:\t0.5186\tF1:\t0.5215 *\n",
      "7 / 30: Train Loss:\t0.0017\tVal Loss:\t1.4175\tAccuracy:\t0.5295\tF1:\t0.5305 *\n",
      "8 / 30: Train Loss:\t0.0003\tVal Loss:\t1.4144\tAccuracy:\t0.5317\tF1:\t0.5319 *\n",
      "9 / 30: Train Loss:\t0.0002\tVal Loss:\t1.4117\tAccuracy:\t0.5339\tF1:\t0.5335 *\n",
      "10 / 30: Train Loss:\t0.0002\tVal Loss:\t1.4095\tAccuracy:\t0.5361\tF1:\t0.5362 *\n",
      "11 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4077\tAccuracy:\t0.5405\tF1:\t0.5400 *\n",
      "12 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4060\tAccuracy:\t0.5405\tF1:\t0.5432 *\n",
      "13 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4046\tAccuracy:\t0.5405\tF1:\t0.5436 *\n",
      "14 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4033\tAccuracy:\t0.5405\tF1:\t0.5435\n",
      "15 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4021\tAccuracy:\t0.5405\tF1:\t0.5444 *\n",
      "16 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4010\tAccuracy:\t0.5405\tF1:\t0.5441\n",
      "17 / 30: Train Loss:\t0.0001\tVal Loss:\t1.4000\tAccuracy:\t0.5405\tF1:\t0.5441\n",
      "18 / 30: Train Loss:\t0.0001\tVal Loss:\t1.3990\tAccuracy:\t0.5427\tF1:\t0.5460 *\n",
      "19 / 30: Train Loss:\t0.0001\tVal Loss:\t1.3981\tAccuracy:\t0.5449\tF1:\t0.5491 *\n",
      "20 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3973\tAccuracy:\t0.5449\tF1:\t0.5491\n",
      "21 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3965\tAccuracy:\t0.5449\tF1:\t0.5493 *\n",
      "22 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3957\tAccuracy:\t0.5449\tF1:\t0.5493\n",
      "23 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3950\tAccuracy:\t0.5449\tF1:\t0.5493\n",
      "24 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3943\tAccuracy:\t0.5470\tF1:\t0.5512 *\n",
      "25 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3937\tAccuracy:\t0.5470\tF1:\t0.5512\n",
      "26 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3931\tAccuracy:\t0.5470\tF1:\t0.5518 *\n",
      "27 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3925\tAccuracy:\t0.5470\tF1:\t0.5518\n",
      "28 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3919\tAccuracy:\t0.5470\tF1:\t0.5518\n",
      "29 / 30: Train Loss:\t0.0000\tVal Loss:\t1.3913\tAccuracy:\t0.5470\tF1:\t0.5518\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.49      0.63      0.55        67\n",
      "               anecdote       0.86      0.72      0.78        43\n",
      "         cherry picking       0.47      0.59      0.52        56\n",
      "      conspiracy theory       0.64      0.59      0.61        39\n",
      "           fake experts       1.00      0.75      0.86        12\n",
      "           false choice       0.42      0.38      0.40        13\n",
      "      false equivalence       0.60      0.21      0.32        14\n",
      "impossible expectations       0.69      0.54      0.61        37\n",
      "      misrepresentation       0.45      0.45      0.45        38\n",
      "     oversimplification       0.87      0.56      0.68        36\n",
      "           single cause       0.48      0.56      0.52        57\n",
      "     slothful induction       0.32      0.33      0.33        45\n",
      "\n",
      "               accuracy                           0.55       457\n",
      "              macro avg       0.61      0.53      0.55       457\n",
      "           weighted avg       0.57      0.55      0.55       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.60      0.68      0.63        37\n",
      "               anecdote       0.85      0.71      0.77        24\n",
      "         cherry picking       0.41      0.42      0.41        31\n",
      "      conspiracy theory       0.53      0.36      0.43        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.33      0.14      0.20         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.61      0.52      0.56        21\n",
      "      misrepresentation       0.50      0.50      0.50        22\n",
      "     oversimplification       0.50      0.60      0.55        20\n",
      "           single cause       0.50      0.66      0.57        32\n",
      "     slothful induction       0.29      0.32      0.30        25\n",
      "\n",
      "               accuracy                           0.52       256\n",
      "              macro avg       0.51      0.48      0.49       256\n",
      "           weighted avg       0.52      0.52      0.51       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t24.8675\tVal Loss:\t2.3753\tAccuracy:\t0.1904\tF1:\t0.1488 *\n",
      "2 / 30: Train Loss:\t20.4916\tVal Loss:\t1.8513\tAccuracy:\t0.4486\tF1:\t0.4032 *\n",
      "3 / 30: Train Loss:\t13.4764\tVal Loss:\t1.5473\tAccuracy:\t0.5164\tF1:\t0.4872 *\n",
      "4 / 30: Train Loss:\t9.2529\tVal Loss:\t1.4663\tAccuracy:\t0.5514\tF1:\t0.5269 *\n",
      "5 / 30: Train Loss:\t6.4986\tVal Loss:\t1.3216\tAccuracy:\t0.5908\tF1:\t0.5728 *\n",
      "6 / 30: Train Loss:\t4.5624\tVal Loss:\t1.2094\tAccuracy:\t0.6214\tF1:\t0.6095 *\n",
      "7 / 30: Train Loss:\t2.9549\tVal Loss:\t1.1804\tAccuracy:\t0.6389\tF1:\t0.6241 *\n",
      "8 / 30: Train Loss:\t2.1415\tVal Loss:\t1.1626\tAccuracy:\t0.6346\tF1:\t0.6266 *\n",
      "9 / 30: Train Loss:\t1.6118\tVal Loss:\t1.1815\tAccuracy:\t0.6258\tF1:\t0.6292 *\n",
      "10 / 30: Train Loss:\t1.1227\tVal Loss:\t1.1290\tAccuracy:\t0.6499\tF1:\t0.6459 *\n",
      "11 / 30: Train Loss:\t0.8260\tVal Loss:\t1.1151\tAccuracy:\t0.6565\tF1:\t0.6570 *\n",
      "12 / 30: Train Loss:\t0.7516\tVal Loss:\t1.1442\tAccuracy:\t0.6455\tF1:\t0.6390\n",
      "13 / 30: Train Loss:\t0.5624\tVal Loss:\t1.1248\tAccuracy:\t0.6608\tF1:\t0.6538\n",
      "14 / 30: Train Loss:\t0.3865\tVal Loss:\t1.1674\tAccuracy:\t0.6586\tF1:\t0.6559\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.84      0.63      0.72        67\n",
      "               anecdote       0.88      0.84      0.86        43\n",
      "         cherry picking       0.53      0.68      0.59        56\n",
      "      conspiracy theory       0.63      0.79      0.70        39\n",
      "           fake experts       0.71      0.83      0.77        12\n",
      "           false choice       0.82      0.69      0.75        13\n",
      "      false equivalence       0.37      0.50      0.42        14\n",
      "impossible expectations       0.66      0.57      0.61        37\n",
      "      misrepresentation       0.50      0.58      0.54        38\n",
      "     oversimplification       0.77      0.56      0.65        36\n",
      "           single cause       0.83      0.60      0.69        57\n",
      "     slothful induction       0.52      0.67      0.58        45\n",
      "\n",
      "               accuracy                           0.66       457\n",
      "              macro avg       0.67      0.66      0.66       457\n",
      "           weighted avg       0.69      0.66      0.66       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.82      0.73      0.77        37\n",
      "               anecdote       0.83      0.79      0.81        24\n",
      "         cherry picking       0.61      0.61      0.61        31\n",
      "      conspiracy theory       0.83      0.86      0.84        22\n",
      "           fake experts       1.00      0.71      0.83         7\n",
      "           false choice       0.57      0.57      0.57         7\n",
      "      false equivalence       0.27      0.50      0.35         8\n",
      "impossible expectations       0.76      0.62      0.68        21\n",
      "      misrepresentation       0.49      0.77      0.60        22\n",
      "     oversimplification       0.70      0.70      0.70        20\n",
      "           single cause       0.81      0.41      0.54        32\n",
      "     slothful induction       0.35      0.44      0.39        25\n",
      "\n",
      "               accuracy                           0.64       256\n",
      "              macro avg       0.67      0.64      0.64       256\n",
      "           weighted avg       0.69      0.64      0.65       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t20.7712\tVal Loss:\t2.3022\tAccuracy:\t0.2604\tF1:\t0.2384 *\n",
      "2 / 30: Train Loss:\t14.3586\tVal Loss:\t1.7887\tAccuracy:\t0.4726\tF1:\t0.4379 *\n",
      "3 / 30: Train Loss:\t8.9665\tVal Loss:\t1.6031\tAccuracy:\t0.5317\tF1:\t0.5107 *\n",
      "4 / 30: Train Loss:\t6.0754\tVal Loss:\t1.5065\tAccuracy:\t0.5361\tF1:\t0.5142 *\n",
      "5 / 30: Train Loss:\t3.9394\tVal Loss:\t1.3128\tAccuracy:\t0.6018\tF1:\t0.5840 *\n",
      "6 / 30: Train Loss:\t2.7325\tVal Loss:\t1.2417\tAccuracy:\t0.6171\tF1:\t0.6114 *\n",
      "7 / 30: Train Loss:\t1.7973\tVal Loss:\t1.2195\tAccuracy:\t0.6214\tF1:\t0.6084\n",
      "8 / 30: Train Loss:\t1.2369\tVal Loss:\t1.1788\tAccuracy:\t0.6433\tF1:\t0.6398 *\n",
      "9 / 30: Train Loss:\t0.8964\tVal Loss:\t1.1190\tAccuracy:\t0.6433\tF1:\t0.6350\n",
      "10 / 30: Train Loss:\t0.6157\tVal Loss:\t1.1029\tAccuracy:\t0.6521\tF1:\t0.6481 *\n",
      "11 / 30: Train Loss:\t0.5081\tVal Loss:\t1.1176\tAccuracy:\t0.6499\tF1:\t0.6496 *\n",
      "12 / 30: Train Loss:\t0.4067\tVal Loss:\t1.1580\tAccuracy:\t0.6389\tF1:\t0.6425\n",
      "13 / 30: Train Loss:\t0.3185\tVal Loss:\t1.1169\tAccuracy:\t0.6411\tF1:\t0.6383\n",
      "14 / 30: Train Loss:\t0.3944\tVal Loss:\t1.1852\tAccuracy:\t0.6324\tF1:\t0.6269\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.81      0.63      0.71        67\n",
      "               anecdote       0.86      0.86      0.86        43\n",
      "         cherry picking       0.64      0.52      0.57        56\n",
      "      conspiracy theory       0.58      0.85      0.69        39\n",
      "           fake experts       0.64      0.75      0.69        12\n",
      "           false choice       0.91      0.77      0.83        13\n",
      "      false equivalence       0.38      0.43      0.40        14\n",
      "impossible expectations       0.64      0.57      0.60        37\n",
      "      misrepresentation       0.47      0.61      0.53        38\n",
      "     oversimplification       0.75      0.58      0.66        36\n",
      "           single cause       0.80      0.56      0.66        57\n",
      "     slothful induction       0.49      0.76      0.60        45\n",
      "\n",
      "               accuracy                           0.65       457\n",
      "              macro avg       0.66      0.66      0.65       457\n",
      "           weighted avg       0.68      0.65      0.65       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.83      0.68      0.75        37\n",
      "               anecdote       0.83      0.83      0.83        24\n",
      "         cherry picking       0.81      0.42      0.55        31\n",
      "      conspiracy theory       0.74      0.91      0.82        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.57      0.57      0.57         7\n",
      "      false equivalence       0.19      0.38      0.25         8\n",
      "impossible expectations       0.76      0.76      0.76        21\n",
      "      misrepresentation       0.46      0.82      0.59        22\n",
      "     oversimplification       0.64      0.70      0.67        20\n",
      "           single cause       0.60      0.38      0.46        32\n",
      "     slothful induction       0.32      0.36      0.34        25\n",
      "\n",
      "               accuracy                           0.62       256\n",
      "              macro avg       0.65      0.64      0.63       256\n",
      "           weighted avg       0.67      0.62      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t14.6062\tVal Loss:\t2.3014\tAccuracy:\t0.2823\tF1:\t0.2700 *\n",
      "2 / 30: Train Loss:\t9.0579\tVal Loss:\t1.8742\tAccuracy:\t0.4683\tF1:\t0.4425 *\n",
      "3 / 30: Train Loss:\t5.1939\tVal Loss:\t1.6992\tAccuracy:\t0.5361\tF1:\t0.5209 *\n",
      "4 / 30: Train Loss:\t3.2965\tVal Loss:\t1.5460\tAccuracy:\t0.5711\tF1:\t0.5471 *\n",
      "5 / 30: Train Loss:\t2.0122\tVal Loss:\t1.4079\tAccuracy:\t0.6105\tF1:\t0.5992 *\n",
      "6 / 30: Train Loss:\t1.3812\tVal Loss:\t1.3512\tAccuracy:\t0.6214\tF1:\t0.6185 *\n",
      "7 / 30: Train Loss:\t0.9007\tVal Loss:\t1.2890\tAccuracy:\t0.6236\tF1:\t0.6194 *\n",
      "8 / 30: Train Loss:\t0.5572\tVal Loss:\t1.2505\tAccuracy:\t0.6324\tF1:\t0.6322 *\n",
      "9 / 30: Train Loss:\t0.3865\tVal Loss:\t1.2221\tAccuracy:\t0.6302\tF1:\t0.6301\n",
      "10 / 30: Train Loss:\t0.2774\tVal Loss:\t1.2045\tAccuracy:\t0.6389\tF1:\t0.6349 *\n",
      "11 / 30: Train Loss:\t0.2335\tVal Loss:\t1.2263\tAccuracy:\t0.6455\tF1:\t0.6408 *\n",
      "12 / 30: Train Loss:\t0.1650\tVal Loss:\t1.2261\tAccuracy:\t0.6346\tF1:\t0.6341\n",
      "13 / 30: Train Loss:\t0.1376\tVal Loss:\t1.1718\tAccuracy:\t0.6543\tF1:\t0.6532 *\n",
      "14 / 30: Train Loss:\t0.1043\tVal Loss:\t1.1744\tAccuracy:\t0.6674\tF1:\t0.6687 *\n",
      "15 / 30: Train Loss:\t0.1438\tVal Loss:\t1.1629\tAccuracy:\t0.6565\tF1:\t0.6447\n",
      "16 / 30: Train Loss:\t0.0793\tVal Loss:\t1.1436\tAccuracy:\t0.6608\tF1:\t0.6491\n",
      "17 / 30: Train Loss:\t0.0601\tVal Loss:\t1.1647\tAccuracy:\t0.6499\tF1:\t0.6440\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.78      0.67      0.72        67\n",
      "               anecdote       0.86      0.88      0.87        43\n",
      "         cherry picking       0.67      0.68      0.67        56\n",
      "      conspiracy theory       0.66      0.74      0.70        39\n",
      "           fake experts       0.77      0.83      0.80        12\n",
      "           false choice       0.82      0.69      0.75        13\n",
      "      false equivalence       0.83      0.36      0.50        14\n",
      "impossible expectations       0.58      0.59      0.59        37\n",
      "      misrepresentation       0.64      0.55      0.59        38\n",
      "     oversimplification       0.76      0.53      0.62        36\n",
      "           single cause       0.71      0.61      0.66        57\n",
      "     slothful induction       0.43      0.76      0.55        45\n",
      "\n",
      "               accuracy                           0.67       457\n",
      "              macro avg       0.71      0.66      0.67       457\n",
      "           weighted avg       0.69      0.67      0.67       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.82      0.73      0.77        37\n",
      "               anecdote       0.86      0.79      0.83        24\n",
      "         cherry picking       0.63      0.55      0.59        31\n",
      "      conspiracy theory       0.82      0.82      0.82        22\n",
      "           fake experts       1.00      0.71      0.83         7\n",
      "           false choice       0.57      0.57      0.57         7\n",
      "      false equivalence       0.38      0.38      0.38         8\n",
      "impossible expectations       0.63      0.81      0.71        21\n",
      "      misrepresentation       0.67      0.82      0.73        22\n",
      "     oversimplification       0.83      0.75      0.79        20\n",
      "           single cause       0.63      0.38      0.47        32\n",
      "     slothful induction       0.29      0.48      0.36        25\n",
      "\n",
      "               accuracy                           0.65       256\n",
      "              macro avg       0.68      0.65      0.65       256\n",
      "           weighted avg       0.68      0.65      0.66       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625, 0.65234375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229, 0.6540326367892599], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628, 0.6673960612691466], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433, 0.6687380006811098], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t7.3677\tVal Loss:\t2.4007\tAccuracy:\t0.1116\tF1:\t0.0703 *\n",
      "2 / 30: Train Loss:\t4.7185\tVal Loss:\t2.0234\tAccuracy:\t0.4398\tF1:\t0.4327 *\n",
      "3 / 30: Train Loss:\t2.3875\tVal Loss:\t1.7930\tAccuracy:\t0.5449\tF1:\t0.5202 *\n",
      "4 / 30: Train Loss:\t1.3864\tVal Loss:\t1.6952\tAccuracy:\t0.5492\tF1:\t0.5249 *\n",
      "5 / 30: Train Loss:\t0.8274\tVal Loss:\t1.6075\tAccuracy:\t0.5777\tF1:\t0.5716 *\n",
      "6 / 30: Train Loss:\t0.5805\tVal Loss:\t1.5458\tAccuracy:\t0.5908\tF1:\t0.5907 *\n",
      "7 / 30: Train Loss:\t0.3494\tVal Loss:\t1.4966\tAccuracy:\t0.6171\tF1:\t0.6120 *\n",
      "8 / 30: Train Loss:\t0.2219\tVal Loss:\t1.4797\tAccuracy:\t0.5908\tF1:\t0.5953\n",
      "9 / 30: Train Loss:\t0.1611\tVal Loss:\t1.4489\tAccuracy:\t0.5930\tF1:\t0.5974\n",
      "10 / 30: Train Loss:\t0.1289\tVal Loss:\t1.4304\tAccuracy:\t0.5952\tF1:\t0.5922\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.71      0.52      0.60        67\n",
      "               anecdote       0.85      0.79      0.82        43\n",
      "         cherry picking       0.60      0.64      0.62        56\n",
      "      conspiracy theory       0.64      0.64      0.64        39\n",
      "           fake experts       0.69      0.75      0.72        12\n",
      "           false choice       0.56      0.77      0.65        13\n",
      "      false equivalence       0.36      0.36      0.36        14\n",
      "impossible expectations       0.58      0.59      0.59        37\n",
      "      misrepresentation       0.54      0.50      0.52        38\n",
      "     oversimplification       0.72      0.58      0.65        36\n",
      "           single cause       0.70      0.61      0.65        57\n",
      "     slothful induction       0.43      0.69      0.53        45\n",
      "\n",
      "               accuracy                           0.62       457\n",
      "              macro avg       0.62      0.62      0.61       457\n",
      "           weighted avg       0.64      0.62      0.62       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.78      0.68      0.72        37\n",
      "               anecdote       0.82      0.75      0.78        24\n",
      "         cherry picking       0.45      0.45      0.45        31\n",
      "      conspiracy theory       0.70      0.64      0.67        22\n",
      "           fake experts       1.00      0.57      0.73         7\n",
      "           false choice       0.40      0.57      0.47         7\n",
      "      false equivalence       0.38      0.38      0.38         8\n",
      "impossible expectations       0.68      0.62      0.65        21\n",
      "      misrepresentation       0.44      0.55      0.49        22\n",
      "     oversimplification       0.58      0.75      0.65        20\n",
      "           single cause       0.55      0.53      0.54        32\n",
      "     slothful induction       0.19      0.20      0.20        25\n",
      "\n",
      "               accuracy                           0.56       256\n",
      "              macro avg       0.58      0.56      0.56       256\n",
      "           weighted avg       0.58      0.56      0.57       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625, 0.65234375, 0.5625], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229, 0.6540326367892599, 0.5605098093114022], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628, 0.6673960612691466, 0.6170678336980306], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433, 0.6687380006811098, 0.6120194519480379], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t22.2779\tVal Loss:\t1.5979\tAccuracy:\t0.4792\tF1:\t0.4281 *\n",
      "2 / 30: Train Loss:\t10.7043\tVal Loss:\t1.2150\tAccuracy:\t0.5996\tF1:\t0.5600 *\n",
      "3 / 30: Train Loss:\t5.4903\tVal Loss:\t0.9698\tAccuracy:\t0.6849\tF1:\t0.6660 *\n",
      "4 / 30: Train Loss:\t2.9622\tVal Loss:\t0.9316\tAccuracy:\t0.7046\tF1:\t0.6992 *\n",
      "5 / 30: Train Loss:\t1.7452\tVal Loss:\t0.8855\tAccuracy:\t0.7287\tF1:\t0.7216 *\n",
      "6 / 30: Train Loss:\t0.8486\tVal Loss:\t0.8750\tAccuracy:\t0.7177\tF1:\t0.7108\n",
      "7 / 30: Train Loss:\t0.4912\tVal Loss:\t0.8630\tAccuracy:\t0.7133\tF1:\t0.7025\n",
      "8 / 30: Train Loss:\t0.2571\tVal Loss:\t0.8602\tAccuracy:\t0.7374\tF1:\t0.7286 *\n",
      "9 / 30: Train Loss:\t0.2032\tVal Loss:\t0.8560\tAccuracy:\t0.7287\tF1:\t0.7139\n",
      "10 / 30: Train Loss:\t0.1469\tVal Loss:\t0.8704\tAccuracy:\t0.7243\tF1:\t0.7133\n",
      "11 / 30: Train Loss:\t0.1178\tVal Loss:\t0.9646\tAccuracy:\t0.7046\tF1:\t0.6958\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.83      0.64      0.72        67\n",
      "               anecdote       0.97      0.91      0.94        43\n",
      "         cherry picking       0.59      0.80      0.68        56\n",
      "      conspiracy theory       0.87      0.85      0.86        39\n",
      "           fake experts       0.77      0.83      0.80        12\n",
      "           false choice       0.77      0.77      0.77        13\n",
      "      false equivalence       0.55      0.43      0.48        14\n",
      "impossible expectations       0.81      0.70      0.75        37\n",
      "      misrepresentation       0.58      0.66      0.62        38\n",
      "     oversimplification       0.70      0.58      0.64        36\n",
      "           single cause       0.77      0.82      0.80        57\n",
      "     slothful induction       0.67      0.71      0.69        45\n",
      "\n",
      "               accuracy                           0.74       457\n",
      "              macro avg       0.74      0.73      0.73       457\n",
      "           weighted avg       0.75      0.74      0.74       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.85      0.76      0.80        37\n",
      "               anecdote       0.85      0.92      0.88        24\n",
      "         cherry picking       0.67      0.77      0.72        31\n",
      "      conspiracy theory       0.79      0.86      0.83        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.45      0.71      0.56         7\n",
      "      false equivalence       0.50      0.38      0.43         8\n",
      "impossible expectations       0.78      0.67      0.72        21\n",
      "      misrepresentation       0.68      0.68      0.68        22\n",
      "     oversimplification       0.64      0.70      0.67        20\n",
      "           single cause       0.83      0.78      0.81        32\n",
      "     slothful induction       0.41      0.36      0.38        25\n",
      "\n",
      "               accuracy                           0.72       256\n",
      "              macro avg       0.70      0.70      0.70       256\n",
      "           weighted avg       0.72      0.72      0.72       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625, 0.65234375, 0.5625, 0.71875], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229, 0.6540326367892599, 0.5605098093114022, 0.6987977230762046], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628, 0.6673960612691466, 0.6170678336980306, 0.737417943107221], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433, 0.6687380006811098, 0.6120194519480379, 0.7285577423213029], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t21.0395\tVal Loss:\t2.1011\tAccuracy:\t0.2867\tF1:\t0.1971 *\n",
      "2 / 30: Train Loss:\t10.1067\tVal Loss:\t1.2699\tAccuracy:\t0.6171\tF1:\t0.6000 *\n",
      "3 / 30: Train Loss:\t4.0454\tVal Loss:\t1.0741\tAccuracy:\t0.6389\tF1:\t0.6283 *\n",
      "4 / 30: Train Loss:\t1.9878\tVal Loss:\t0.9700\tAccuracy:\t0.6652\tF1:\t0.6700 *\n",
      "5 / 30: Train Loss:\t1.1254\tVal Loss:\t0.9061\tAccuracy:\t0.7068\tF1:\t0.7002 *\n",
      "6 / 30: Train Loss:\t0.4867\tVal Loss:\t0.8808\tAccuracy:\t0.7155\tF1:\t0.7219 *\n",
      "7 / 30: Train Loss:\t0.2945\tVal Loss:\t0.8893\tAccuracy:\t0.7090\tF1:\t0.7130\n",
      "8 / 30: Train Loss:\t0.2070\tVal Loss:\t0.9257\tAccuracy:\t0.7002\tF1:\t0.7013\n",
      "9 / 30: Train Loss:\t0.2254\tVal Loss:\t0.9679\tAccuracy:\t0.7002\tF1:\t0.6907\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.81      0.63      0.71        67\n",
      "               anecdote       0.97      0.84      0.90        43\n",
      "         cherry picking       0.63      0.71      0.67        56\n",
      "      conspiracy theory       0.72      0.87      0.79        39\n",
      "           fake experts       0.85      0.92      0.88        12\n",
      "           false choice       0.71      0.77      0.74        13\n",
      "      false equivalence       0.64      0.50      0.56        14\n",
      "impossible expectations       0.80      0.65      0.72        37\n",
      "      misrepresentation       0.52      0.68      0.59        38\n",
      "     oversimplification       0.85      0.61      0.71        36\n",
      "           single cause       0.86      0.67      0.75        57\n",
      "     slothful induction       0.53      0.82      0.64        45\n",
      "\n",
      "               accuracy                           0.72       457\n",
      "              macro avg       0.74      0.72      0.72       457\n",
      "           weighted avg       0.75      0.72      0.72       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.87      0.73      0.79        37\n",
      "               anecdote       0.92      0.92      0.92        24\n",
      "         cherry picking       0.73      0.71      0.72        31\n",
      "      conspiracy theory       0.74      0.91      0.82        22\n",
      "           fake experts       1.00      1.00      1.00         7\n",
      "           false choice       0.62      0.71      0.67         7\n",
      "      false equivalence       0.30      0.38      0.33         8\n",
      "impossible expectations       0.71      0.71      0.71        21\n",
      "      misrepresentation       0.65      0.77      0.71        22\n",
      "     oversimplification       0.83      0.75      0.79        20\n",
      "           single cause       0.95      0.62      0.75        32\n",
      "     slothful induction       0.48      0.64      0.55        25\n",
      "\n",
      "               accuracy                           0.74       256\n",
      "              macro avg       0.74      0.74      0.73       256\n",
      "           weighted avg       0.76      0.74      0.74       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625, 0.65234375, 0.5625, 0.71875, 0.73828125], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229, 0.6540326367892599, 0.5605098093114022, 0.6987977230762046, 0.7305796808866879], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628, 0.6673960612691466, 0.6170678336980306, 0.737417943107221, 0.7155361050328227], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433, 0.6687380006811098, 0.6120194519480379, 0.7285577423213029, 0.7218789670641298], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t11.8173\tVal Loss:\t1.5854\tAccuracy:\t0.5580\tF1:\t0.5152 *\n",
      "2 / 30: Train Loss:\t5.0966\tVal Loss:\t1.6952\tAccuracy:\t0.5317\tF1:\t0.5115\n",
      "3 / 30: Train Loss:\t2.7530\tVal Loss:\t1.1896\tAccuracy:\t0.6630\tF1:\t0.6555 *\n",
      "4 / 30: Train Loss:\t1.8121\tVal Loss:\t1.1379\tAccuracy:\t0.6696\tF1:\t0.6509\n",
      "5 / 30: Train Loss:\t2.8761\tVal Loss:\t1.1428\tAccuracy:\t0.6608\tF1:\t0.6301\n",
      "6 / 30: Train Loss:\t2.8735\tVal Loss:\t1.1391\tAccuracy:\t0.6608\tF1:\t0.6444\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.76      0.67      0.71        67\n",
      "               anecdote       1.00      0.81      0.90        43\n",
      "         cherry picking       0.71      0.64      0.67        56\n",
      "      conspiracy theory       0.69      0.87      0.77        39\n",
      "           fake experts       0.56      0.75      0.64        12\n",
      "           false choice       0.60      0.69      0.64        13\n",
      "      false equivalence       0.18      0.71      0.29        14\n",
      "impossible expectations       0.73      0.65      0.69        37\n",
      "      misrepresentation       0.65      0.63      0.64        38\n",
      "     oversimplification       0.76      0.69      0.72        36\n",
      "           single cause       0.75      0.42      0.54        57\n",
      "     slothful induction       0.67      0.62      0.64        45\n",
      "\n",
      "               accuracy                           0.66       457\n",
      "              macro avg       0.67      0.68      0.66       457\n",
      "           weighted avg       0.72      0.66      0.68       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.83      0.68      0.75        37\n",
      "               anecdote       0.94      0.71      0.81        24\n",
      "         cherry picking       0.70      0.52      0.59        31\n",
      "      conspiracy theory       0.70      0.86      0.78        22\n",
      "           fake experts       0.88      1.00      0.93         7\n",
      "           false choice       0.33      0.29      0.31         7\n",
      "      false equivalence       0.14      0.62      0.23         8\n",
      "impossible expectations       0.70      0.67      0.68        21\n",
      "      misrepresentation       0.60      0.68      0.64        22\n",
      "     oversimplification       0.70      0.80      0.74        20\n",
      "           single cause       0.72      0.56      0.63        32\n",
      "     slothful induction       0.60      0.36      0.45        25\n",
      "\n",
      "               accuracy                           0.64       256\n",
      "              macro avg       0.65      0.65      0.63       256\n",
      "           weighted avg       0.70      0.64      0.66       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625, 0.65234375, 0.5625, 0.71875, 0.73828125, 0.63671875], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229, 0.6540326367892599, 0.5605098093114022, 0.6987977230762046, 0.7305796808866879, 0.6282652772251324], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628, 0.6673960612691466, 0.6170678336980306, 0.737417943107221, 0.7155361050328227, 0.6630196936542669], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433, 0.6687380006811098, 0.6120194519480379, 0.7285577423213029, 0.7218789670641298, 0.6555226174482081], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t6.3958\tVal Loss:\t1.7630\tAccuracy:\t0.5252\tF1:\t0.4835 *\n",
      "2 / 30: Train Loss:\t2.1492\tVal Loss:\t1.5539\tAccuracy:\t0.5930\tF1:\t0.5705 *\n",
      "3 / 30: Train Loss:\t0.8571\tVal Loss:\t1.3015\tAccuracy:\t0.6674\tF1:\t0.6626 *\n",
      "4 / 30: Train Loss:\t0.4105\tVal Loss:\t1.2486\tAccuracy:\t0.6740\tF1:\t0.6725 *\n",
      "5 / 30: Train Loss:\t0.2148\tVal Loss:\t1.1620\tAccuracy:\t0.7112\tF1:\t0.7002 *\n",
      "6 / 30: Train Loss:\t0.0963\tVal Loss:\t1.1113\tAccuracy:\t0.6980\tF1:\t0.6820\n",
      "7 / 30: Train Loss:\t0.0507\tVal Loss:\t1.0751\tAccuracy:\t0.7155\tF1:\t0.6975\n",
      "8 / 30: Train Loss:\t0.0248\tVal Loss:\t1.0321\tAccuracy:\t0.7243\tF1:\t0.7067 *\n",
      "9 / 30: Train Loss:\t0.0324\tVal Loss:\t1.0372\tAccuracy:\t0.6980\tF1:\t0.6916\n",
      "10 / 30: Train Loss:\t0.0139\tVal Loss:\t1.0196\tAccuracy:\t0.7243\tF1:\t0.7129 *\n",
      "11 / 30: Train Loss:\t0.0136\tVal Loss:\t1.0242\tAccuracy:\t0.7265\tF1:\t0.7125\n",
      "12 / 30: Train Loss:\t0.0078\tVal Loss:\t1.0191\tAccuracy:\t0.7221\tF1:\t0.7123\n",
      "13 / 30: Train Loss:\t0.0079\tVal Loss:\t1.0079\tAccuracy:\t0.7199\tF1:\t0.7064\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.72      0.69      0.70        67\n",
      "               anecdote       0.95      0.91      0.93        43\n",
      "         cherry picking       0.66      0.71      0.68        56\n",
      "      conspiracy theory       0.74      0.79      0.77        39\n",
      "           fake experts       0.77      0.83      0.80        12\n",
      "           false choice       0.83      0.77      0.80        13\n",
      "      false equivalence       0.36      0.36      0.36        14\n",
      "impossible expectations       0.67      0.76      0.71        37\n",
      "      misrepresentation       0.71      0.66      0.68        38\n",
      "     oversimplification       0.78      0.58      0.67        36\n",
      "           single cause       0.86      0.75      0.80        57\n",
      "     slothful induction       0.59      0.73      0.65        45\n",
      "\n",
      "               accuracy                           0.72       457\n",
      "              macro avg       0.72      0.71      0.71       457\n",
      "           weighted avg       0.73      0.72      0.73       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.84      0.82        37\n",
      "               anecdote       0.92      0.96      0.94        24\n",
      "         cherry picking       0.71      0.71      0.71        31\n",
      "      conspiracy theory       0.77      0.77      0.77        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.50      0.43      0.46         7\n",
      "      false equivalence       0.44      0.50      0.47         8\n",
      "impossible expectations       0.65      0.81      0.72        21\n",
      "      misrepresentation       0.65      0.59      0.62        22\n",
      "     oversimplification       0.70      0.80      0.74        20\n",
      "           single cause       0.72      0.66      0.69        32\n",
      "     slothful induction       0.45      0.36      0.40        25\n",
      "\n",
      "               accuracy                           0.71       256\n",
      "              macro avg       0.69      0.69      0.69       256\n",
      "           weighted avg       0.71      0.71      0.71       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.6484375, 0.6171875, 0.64453125, 0.5703125, 0.03125, 0.02734375, 0.70703125, 0.02734375, 0.54296875, 0.484375, 0.47265625, 0.5078125, 0.51953125, 0.53515625, 0.578125, 0.5546875, 0.2734375, 0.3125, 0.30078125, 0.26953125, 0.4609375, 0.08984375, 0.51953125, 0.51953125, 0.64453125, 0.625, 0.65234375, 0.5625, 0.71875, 0.73828125, 0.63671875, 0.7109375], 'test_f1': [0.6360817875408947, 0.6142845336741297, 0.6296692673081391, 0.5644000789341944, 0.005050505050505051, 0.004435994930291508, 0.6894180730701421, 0.004435994930291508, 0.5133378811439441, 0.45457198269672233, 0.46432163091056405, 0.4634561364346384, 0.48402014043942226, 0.5044942940559662, 0.5577857605888233, 0.5230606777596839, 0.19582841555086564, 0.2252194121874973, 0.21692738093060315, 0.21615568438089858, 0.4400369588926821, 0.050131641153551454, 0.5014094228835547, 0.4877381585764677, 0.6420917029671284, 0.626126830881229, 0.6540326367892599, 0.5605098093114022, 0.6987977230762046, 0.7305796808866879, 0.6282652772251324, 0.6889446505768531], 'eval_acc': [0.6783369803063457, 0.6345733041575492, 0.6477024070021882, 0.6170678336980306, 0.030634573304157548, 0.028446389496717725, 0.7264770240700219, 0.028446389496717725, 0.5361050328227571, 0.5120350109409191, 0.5032822757111597, 0.45295404814004375, 0.5601750547045952, 0.5010940919037199, 0.5886214442013129, 0.5514223194748359, 0.26914660831509846, 0.2975929978118162, 0.28227571115973743, 0.25601750547045954, 0.49671772428884026, 0.07658643326039387, 0.5251641137855579, 0.5470459518599562, 0.6564551422319475, 0.649890590809628, 0.6673960612691466, 0.6170678336980306, 0.737417943107221, 0.7155361050328227, 0.6630196936542669, 0.7242888402625821], 'eval_f1': [0.6573832525923866, 0.6151903501826291, 0.6312986432817037, 0.6055765865945604, 0.004953998584571833, 0.004609929078014185, 0.7140010722249007, 0.004609929078014185, 0.5255030266274913, 0.49671192376140155, 0.5016822045668551, 0.4435844447421117, 0.5397393683023696, 0.4894237700494934, 0.5721609327410172, 0.5029565556601051, 0.21809930256255508, 0.2565086704798338, 0.2153791458398172, 0.22409576295931366, 0.48675413595761086, 0.04617210326918018, 0.5079984356761547, 0.5518093509147721, 0.6569753628604537, 0.6495847162742433, 0.6687380006811098, 0.6120194519480379, 0.7285577423213029, 0.7218789670641298, 0.6555226174482081, 0.7129049784897995], 'g': [2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16, 2, 4, 8, 16]}\n",
      "### ### ### ### ### ### ### ### ### ### \n"
     ]
    }
   ],
   "source": [
    "gamma = [2,4,8,16]\n",
    "\n",
    "for model_checkpoint in best_config.keys():\n",
    "    for g in gamma:\n",
    "        print(f'Grid search {model_checkpoint}, learning rate {best_config[model_checkpoint][\"lr\"]}')\n",
    "        data = ClimateDataset(model_to_train=4,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=32)\n",
    "        data.setup_dataloaders()\n",
    "        model = ClassificationModel(model_checkpoint=data.model_checkpoint,num_labels=data.num_labels)\n",
    "        trainer = Engine(epochs=30,labels=data.labels)\n",
    "        trainer.model = model.model\n",
    "        trainer.dataset_encoded = data.dataset_encoded\n",
    "        test_acc, test_f1, eval_acc, eval_f1 = trainer.run(lr=best_config[model_checkpoint]['lr'],\n",
    "                                                            wd=0.0,\n",
    "                                                            train_dataloader=data.train_dataloader,\n",
    "                                                            eval_dataloader=data.eval_dataloader,\n",
    "                                                            test_dataloader=data.test_dataloader,\n",
    "                                                            focalloss=True,\n",
    "                                                            gamma=g,\n",
    "                                                            early_stop=3)\n",
    "        results['test_acc'].append(test_acc)\n",
    "        results['test_f1'].append(test_f1)\n",
    "        results['eval_acc'].append(eval_acc)\n",
    "        results['eval_f1'].append(eval_f1)\n",
    "        results['g'].append(g)\n",
    "        print('### '*10)\n",
    "        print(results)\n",
    "        print('### '*10)\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        del data, model, trainer\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
