{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/software/'\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.join(os.path.dirname(os.getcwd()), '')\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints = ['bert-base-uncased',\n",
    "                   'roberta-large',\n",
    "                   'gpt2',\n",
    "                   'bigscience/bloom-560m',\n",
    "                   'facebook/opt-350m',\n",
    "                   'EleutherAI/gpt-neo-1.3B', \n",
    "                   'microsoft/deberta-base',\n",
    "                   'microsoft/deberta-v2-xlarge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'lr':[],\n",
    "           'model':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search bert-base-uncased, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.3806\tVal Loss:\t2.1792\tAccuracy:\t0.2976\tF1:\t0.1813 *\n",
      "2 / 30: Train Loss:\t2.0266\tVal Loss:\t1.8814\tAccuracy:\t0.4354\tF1:\t0.3076 *\n",
      "3 / 30: Train Loss:\t1.7194\tVal Loss:\t1.6721\tAccuracy:\t0.4923\tF1:\t0.3687 *\n",
      "4 / 30: Train Loss:\t1.4581\tVal Loss:\t1.5409\tAccuracy:\t0.5405\tF1:\t0.4116 *\n",
      "5 / 30: Train Loss:\t1.2442\tVal Loss:\t1.4461\tAccuracy:\t0.5755\tF1:\t0.4443 *\n",
      "6 / 30: Train Loss:\t1.0456\tVal Loss:\t1.3050\tAccuracy:\t0.5952\tF1:\t0.4636 *\n",
      "7 / 30: Train Loss:\t0.8667\tVal Loss:\t1.2323\tAccuracy:\t0.6258\tF1:\t0.5165 *\n",
      "8 / 30: Train Loss:\t0.6978\tVal Loss:\t1.2087\tAccuracy:\t0.6346\tF1:\t0.5496 *\n",
      "9 / 30: Train Loss:\t0.5722\tVal Loss:\t1.1688\tAccuracy:\t0.6346\tF1:\t0.5366\n",
      "10 / 30: Train Loss:\t0.4586\tVal Loss:\t1.1584\tAccuracy:\t0.6411\tF1:\t0.5581 *\n",
      "11 / 30: Train Loss:\t0.3750\tVal Loss:\t1.1686\tAccuracy:\t0.6346\tF1:\t0.5640 *\n",
      "12 / 30: Train Loss:\t0.3041\tVal Loss:\t1.1892\tAccuracy:\t0.6324\tF1:\t0.5840 *\n",
      "13 / 30: Train Loss:\t0.2513\tVal Loss:\t1.2038\tAccuracy:\t0.6543\tF1:\t0.6189 *\n",
      "14 / 30: Train Loss:\t0.2072\tVal Loss:\t1.2132\tAccuracy:\t0.6674\tF1:\t0.6354 *\n",
      "15 / 30: Train Loss:\t0.1592\tVal Loss:\t1.2315\tAccuracy:\t0.6433\tF1:\t0.6180\n",
      "16 / 30: Train Loss:\t0.1311\tVal Loss:\t1.2560\tAccuracy:\t0.6499\tF1:\t0.6152\n",
      "17 / 30: Train Loss:\t0.1109\tVal Loss:\t1.2554\tAccuracy:\t0.6477\tF1:\t0.6084\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.75      0.66      0.70        67\n",
      "               anecdote       0.92      0.79      0.85        43\n",
      "         cherry picking       0.73      0.59      0.65        56\n",
      "      conspiracy theory       0.70      0.79      0.75        39\n",
      "           fake experts       0.62      0.67      0.64        12\n",
      "           false choice       0.67      0.31      0.42        13\n",
      "      false equivalence       0.67      0.29      0.40        14\n",
      "impossible expectations       0.81      0.57      0.67        37\n",
      "      misrepresentation       0.55      0.61      0.57        38\n",
      "     oversimplification       0.85      0.61      0.71        36\n",
      "           single cause       0.55      0.82      0.66        57\n",
      "     slothful induction       0.50      0.76      0.60        45\n",
      "\n",
      "               accuracy                           0.67       457\n",
      "              macro avg       0.69      0.62      0.64       457\n",
      "           weighted avg       0.70      0.67      0.67       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.77      0.73      0.75        37\n",
      "               anecdote       0.81      0.88      0.84        24\n",
      "         cherry picking       0.73      0.52      0.60        31\n",
      "      conspiracy theory       0.78      0.64      0.70        22\n",
      "           fake experts       1.00      0.43      0.60         7\n",
      "           false choice       0.33      0.14      0.20         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.68      0.62      0.65        21\n",
      "      misrepresentation       0.56      0.68      0.61        22\n",
      "     oversimplification       0.79      0.75      0.77        20\n",
      "           single cause       0.49      0.69      0.57        32\n",
      "     slothful induction       0.39      0.56      0.46        25\n",
      "\n",
      "               accuracy                           0.63       256\n",
      "              macro avg       0.61      0.55      0.56       256\n",
      "           weighted avg       0.64      0.63      0.62       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625], 'test_f1': [0.5629745180805673], 'eval_acc': [0.6673960612691466], 'eval_f1': [0.6354170380704479], 'lr': [1e-05], 'model': ['bert-base-uncased']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.0734\tVal Loss:\t1.5805\tAccuracy:\t0.5164\tF1:\t0.3812 *\n",
      "2 / 30: Train Loss:\t1.2720\tVal Loss:\t1.2624\tAccuracy:\t0.5886\tF1:\t0.5053 *\n",
      "3 / 30: Train Loss:\t0.7652\tVal Loss:\t1.2007\tAccuracy:\t0.6193\tF1:\t0.5654 *\n",
      "4 / 30: Train Loss:\t0.4265\tVal Loss:\t1.2871\tAccuracy:\t0.6171\tF1:\t0.5642\n",
      "5 / 30: Train Loss:\t0.2667\tVal Loss:\t1.4833\tAccuracy:\t0.6083\tF1:\t0.5814 *\n",
      "6 / 30: Train Loss:\t0.1595\tVal Loss:\t1.4199\tAccuracy:\t0.6368\tF1:\t0.6064 *\n",
      "7 / 30: Train Loss:\t0.0882\tVal Loss:\t1.3384\tAccuracy:\t0.6521\tF1:\t0.6236 *\n",
      "8 / 30: Train Loss:\t0.0407\tVal Loss:\t1.4377\tAccuracy:\t0.6696\tF1:\t0.6335 *\n",
      "9 / 30: Train Loss:\t0.0269\tVal Loss:\t1.4970\tAccuracy:\t0.6543\tF1:\t0.6271\n",
      "10 / 30: Train Loss:\t0.0185\tVal Loss:\t1.4649\tAccuracy:\t0.6652\tF1:\t0.6306\n",
      "11 / 30: Train Loss:\t0.0177\tVal Loss:\t1.5012\tAccuracy:\t0.6521\tF1:\t0.6136\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.69      0.66      0.67        67\n",
      "               anecdote       0.91      0.72      0.81        43\n",
      "         cherry picking       0.66      0.66      0.66        56\n",
      "      conspiracy theory       0.69      0.90      0.78        39\n",
      "           fake experts       0.64      0.58      0.61        12\n",
      "           false choice       0.67      0.62      0.64        13\n",
      "      false equivalence       0.50      0.14      0.22        14\n",
      "impossible expectations       0.70      0.57      0.63        37\n",
      "      misrepresentation       0.67      0.47      0.55        38\n",
      "     oversimplification       0.74      0.64      0.69        36\n",
      "           single cause       0.76      0.72      0.74        57\n",
      "     slothful induction       0.47      0.87      0.61        45\n",
      "\n",
      "               accuracy                           0.67       457\n",
      "              macro avg       0.67      0.63      0.63       457\n",
      "           weighted avg       0.69      0.67      0.67       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.84      0.82        37\n",
      "               anecdote       0.86      0.75      0.80        24\n",
      "         cherry picking       0.59      0.52      0.55        31\n",
      "      conspiracy theory       0.87      0.59      0.70        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.27      0.43      0.33         7\n",
      "      false equivalence       0.43      0.38      0.40         8\n",
      "impossible expectations       0.88      0.67      0.76        21\n",
      "      misrepresentation       0.58      0.64      0.61        22\n",
      "     oversimplification       0.76      0.80      0.78        20\n",
      "           single cause       0.79      0.69      0.73        32\n",
      "     slothful induction       0.29      0.48      0.36        25\n",
      "\n",
      "               accuracy                           0.66       256\n",
      "              macro avg       0.68      0.64      0.65       256\n",
      "           weighted avg       0.70      0.66      0.67       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625], 'test_f1': [0.5629745180805673, 0.6474613734588849], 'eval_acc': [0.6673960612691466, 0.6695842450765864], 'eval_f1': [0.6354170380704479, 0.6334794330566359], 'lr': [1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bert-base-uncased, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t1.9084\tVal Loss:\t1.4854\tAccuracy:\t0.5295\tF1:\t0.3998 *\n",
      "2 / 30: Train Loss:\t1.1017\tVal Loss:\t1.4341\tAccuracy:\t0.5602\tF1:\t0.5157 *\n",
      "3 / 30: Train Loss:\t0.6575\tVal Loss:\t1.2939\tAccuracy:\t0.6105\tF1:\t0.5584 *\n",
      "4 / 30: Train Loss:\t0.3754\tVal Loss:\t1.2815\tAccuracy:\t0.6433\tF1:\t0.6067 *\n",
      "5 / 30: Train Loss:\t0.2356\tVal Loss:\t1.4374\tAccuracy:\t0.6543\tF1:\t0.6102 *\n",
      "6 / 30: Train Loss:\t0.1206\tVal Loss:\t1.5037\tAccuracy:\t0.6346\tF1:\t0.6226 *\n",
      "7 / 30: Train Loss:\t0.0652\tVal Loss:\t1.6122\tAccuracy:\t0.6368\tF1:\t0.6123\n",
      "8 / 30: Train Loss:\t0.0393\tVal Loss:\t1.5840\tAccuracy:\t0.6433\tF1:\t0.6311 *\n",
      "9 / 30: Train Loss:\t0.0641\tVal Loss:\t1.7202\tAccuracy:\t0.6149\tF1:\t0.6014\n",
      "10 / 30: Train Loss:\t0.0921\tVal Loss:\t2.0348\tAccuracy:\t0.5952\tF1:\t0.5788\n",
      "11 / 30: Train Loss:\t0.1538\tVal Loss:\t1.8333\tAccuracy:\t0.6083\tF1:\t0.5873\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.68      0.75      0.71        67\n",
      "               anecdote       0.94      0.77      0.85        43\n",
      "         cherry picking       0.66      0.70      0.68        56\n",
      "      conspiracy theory       0.68      0.82      0.74        39\n",
      "           fake experts       0.82      0.75      0.78        12\n",
      "           false choice       0.67      0.62      0.64        13\n",
      "      false equivalence       0.20      0.36      0.26        14\n",
      "impossible expectations       0.61      0.59      0.60        37\n",
      "      misrepresentation       0.58      0.68      0.63        38\n",
      "     oversimplification       0.82      0.50      0.62        36\n",
      "           single cause       0.87      0.35      0.50        57\n",
      "     slothful induction       0.46      0.71      0.56        45\n",
      "\n",
      "               accuracy                           0.64       457\n",
      "              macro avg       0.67      0.63      0.63       457\n",
      "           weighted avg       0.69      0.64      0.65       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.70      0.81      0.75        37\n",
      "               anecdote       0.87      0.83      0.85        24\n",
      "         cherry picking       0.67      0.65      0.66        31\n",
      "      conspiracy theory       0.82      0.64      0.72        22\n",
      "           fake experts       0.75      0.43      0.55         7\n",
      "           false choice       0.33      0.43      0.38         7\n",
      "      false equivalence       0.21      0.38      0.27         8\n",
      "impossible expectations       0.58      0.67      0.62        21\n",
      "      misrepresentation       0.59      0.73      0.65        22\n",
      "     oversimplification       0.65      0.65      0.65        20\n",
      "           single cause       0.92      0.38      0.53        32\n",
      "     slothful induction       0.34      0.44      0.39        25\n",
      "\n",
      "               accuracy                           0.62       256\n",
      "              macro avg       0.62      0.58      0.58       256\n",
      "           weighted avg       0.67      0.62      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802], 'lr': [1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.2349\tVal Loss:\t1.6003\tAccuracy:\t0.5033\tF1:\t0.3722 *\n",
      "2 / 30: Train Loss:\t1.3532\tVal Loss:\t1.1752\tAccuracy:\t0.6149\tF1:\t0.5104 *\n",
      "3 / 30: Train Loss:\t0.8966\tVal Loss:\t0.9958\tAccuracy:\t0.6805\tF1:\t0.6482 *\n",
      "4 / 30: Train Loss:\t0.6150\tVal Loss:\t0.9477\tAccuracy:\t0.7068\tF1:\t0.6980 *\n",
      "5 / 30: Train Loss:\t0.4273\tVal Loss:\t0.9666\tAccuracy:\t0.7155\tF1:\t0.7054 *\n",
      "6 / 30: Train Loss:\t0.3208\tVal Loss:\t1.2816\tAccuracy:\t0.6718\tF1:\t0.6485\n",
      "7 / 30: Train Loss:\t0.2258\tVal Loss:\t1.0949\tAccuracy:\t0.7287\tF1:\t0.6992\n",
      "8 / 30: Train Loss:\t0.1275\tVal Loss:\t1.1484\tAccuracy:\t0.7287\tF1:\t0.7112 *\n",
      "9 / 30: Train Loss:\t0.0960\tVal Loss:\t1.2356\tAccuracy:\t0.7090\tF1:\t0.7097\n",
      "10 / 30: Train Loss:\t0.0722\tVal Loss:\t1.2278\tAccuracy:\t0.7155\tF1:\t0.7070\n",
      "11 / 30: Train Loss:\t0.0483\tVal Loss:\t1.2260\tAccuracy:\t0.7177\tF1:\t0.6995\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.73      0.76        67\n",
      "               anecdote       0.86      0.86      0.86        43\n",
      "         cherry picking       0.64      0.82      0.72        56\n",
      "      conspiracy theory       0.81      0.90      0.85        39\n",
      "           fake experts       0.82      0.75      0.78        12\n",
      "           false choice       0.77      0.77      0.77        13\n",
      "      false equivalence       0.50      0.36      0.42        14\n",
      "impossible expectations       0.69      0.68      0.68        37\n",
      "      misrepresentation       0.69      0.58      0.63        38\n",
      "     oversimplification       0.71      0.56      0.63        36\n",
      "           single cause       0.76      0.68      0.72        57\n",
      "     slothful induction       0.64      0.80      0.71        45\n",
      "\n",
      "               accuracy                           0.73       457\n",
      "              macro avg       0.72      0.71      0.71       457\n",
      "           weighted avg       0.73      0.73      0.73       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.85      0.76      0.80        37\n",
      "               anecdote       0.88      0.92      0.90        24\n",
      "         cherry picking       0.60      0.68      0.64        31\n",
      "      conspiracy theory       0.75      0.82      0.78        22\n",
      "           fake experts       1.00      0.71      0.83         7\n",
      "           false choice       0.60      0.43      0.50         7\n",
      "      false equivalence       0.50      0.12      0.20         8\n",
      "impossible expectations       0.71      0.81      0.76        21\n",
      "      misrepresentation       0.70      0.64      0.67        22\n",
      "     oversimplification       0.67      0.80      0.73        20\n",
      "           single cause       0.75      0.66      0.70        32\n",
      "     slothful induction       0.42      0.52      0.46        25\n",
      "\n",
      "               accuracy                           0.70       256\n",
      "              macro avg       0.70      0.65      0.66       256\n",
      "           weighted avg       0.71      0.70      0.70       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286], 'lr': [1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t1.8926\tVal Loss:\t1.3415\tAccuracy:\t0.5514\tF1:\t0.4446 *\n",
      "2 / 30: Train Loss:\t1.1432\tVal Loss:\t1.1086\tAccuracy:\t0.6565\tF1:\t0.6078 *\n",
      "3 / 30: Train Loss:\t0.8291\tVal Loss:\t1.0573\tAccuracy:\t0.6915\tF1:\t0.6545 *\n",
      "4 / 30: Train Loss:\t0.4967\tVal Loss:\t1.1628\tAccuracy:\t0.6871\tF1:\t0.6634 *\n",
      "5 / 30: Train Loss:\t0.3243\tVal Loss:\t1.1722\tAccuracy:\t0.6871\tF1:\t0.6774 *\n",
      "6 / 30: Train Loss:\t0.2365\tVal Loss:\t1.2276\tAccuracy:\t0.6718\tF1:\t0.6496\n",
      "7 / 30: Train Loss:\t0.2223\tVal Loss:\t1.3473\tAccuracy:\t0.6783\tF1:\t0.6610\n",
      "8 / 30: Train Loss:\t0.1503\tVal Loss:\t1.2293\tAccuracy:\t0.7133\tF1:\t0.7068 *\n",
      "9 / 30: Train Loss:\t0.1215\tVal Loss:\t1.2906\tAccuracy:\t0.7046\tF1:\t0.6964\n",
      "10 / 30: Train Loss:\t0.0811\tVal Loss:\t1.5512\tAccuracy:\t0.6783\tF1:\t0.6678\n",
      "11 / 30: Train Loss:\t0.0829\tVal Loss:\t1.5122\tAccuracy:\t0.6740\tF1:\t0.6426\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.85      0.60      0.70        67\n",
      "               anecdote       0.84      0.84      0.84        43\n",
      "         cherry picking       0.61      0.82      0.70        56\n",
      "      conspiracy theory       0.80      0.90      0.84        39\n",
      "           fake experts       0.80      1.00      0.89        12\n",
      "           false choice       0.75      0.69      0.72        13\n",
      "      false equivalence       0.37      0.50      0.42        14\n",
      "impossible expectations       0.88      0.57      0.69        37\n",
      "      misrepresentation       0.60      0.68      0.64        38\n",
      "     oversimplification       0.68      0.58      0.63        36\n",
      "           single cause       0.77      0.75      0.76        57\n",
      "     slothful induction       0.62      0.67      0.65        45\n",
      "\n",
      "               accuracy                           0.71       457\n",
      "              macro avg       0.71      0.72      0.71       457\n",
      "           weighted avg       0.73      0.71      0.71       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.69      0.68      0.68        37\n",
      "               anecdote       0.81      0.92      0.86        24\n",
      "         cherry picking       0.77      0.77      0.77        31\n",
      "      conspiracy theory       0.65      0.59      0.62        22\n",
      "           fake experts       1.00      1.00      1.00         7\n",
      "           false choice       0.80      0.57      0.67         7\n",
      "      false equivalence       0.20      0.25      0.22         8\n",
      "impossible expectations       0.81      0.62      0.70        21\n",
      "      misrepresentation       0.63      0.77      0.69        22\n",
      "     oversimplification       0.62      0.75      0.68        20\n",
      "           single cause       0.74      0.72      0.73        32\n",
      "     slothful induction       0.50      0.44      0.47        25\n",
      "\n",
      "               accuracy                           0.69       256\n",
      "              macro avg       0.69      0.67      0.68       256\n",
      "           weighted avg       0.69      0.69      0.69       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4353\tVal Loss:\t2.3808\tAccuracy:\t0.1466\tF1:\t0.0213 *\n",
      "2 / 30: Train Loss:\t2.4132\tVal Loss:\t2.3784\tAccuracy:\t0.1466\tF1:\t0.0213\n",
      "3 / 30: Train Loss:\t2.4127\tVal Loss:\t2.3805\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "4 / 30: Train Loss:\t2.4002\tVal Loss:\t2.3823\tAccuracy:\t0.1466\tF1:\t0.0213\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.15      1.00      0.26        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.15       457\n",
      "              macro avg       0.01      0.08      0.02       457\n",
      "           weighted avg       0.02      0.15      0.04       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.14      1.00      0.25        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.14       256\n",
      "              macro avg       0.01      0.08      0.02       256\n",
      "           weighted avg       0.02      0.14      0.04       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t3.0621\tVal Loss:\t2.5606\tAccuracy:\t0.1269\tF1:\t0.0794 *\n",
      "2 / 30: Train Loss:\t2.5522\tVal Loss:\t2.4449\tAccuracy:\t0.1466\tF1:\t0.0785\n",
      "3 / 30: Train Loss:\t2.4509\tVal Loss:\t2.3903\tAccuracy:\t0.1532\tF1:\t0.0802 *\n",
      "4 / 30: Train Loss:\t2.4074\tVal Loss:\t2.3565\tAccuracy:\t0.1816\tF1:\t0.0896 *\n",
      "5 / 30: Train Loss:\t2.4024\tVal Loss:\t2.3291\tAccuracy:\t0.2101\tF1:\t0.1032 *\n",
      "6 / 30: Train Loss:\t2.3667\tVal Loss:\t2.3008\tAccuracy:\t0.2254\tF1:\t0.1145 *\n",
      "7 / 30: Train Loss:\t2.3151\tVal Loss:\t2.2692\tAccuracy:\t0.2429\tF1:\t0.1272 *\n",
      "8 / 30: Train Loss:\t2.2843\tVal Loss:\t2.2361\tAccuracy:\t0.2385\tF1:\t0.1324 *\n",
      "9 / 30: Train Loss:\t2.2478\tVal Loss:\t2.1835\tAccuracy:\t0.2626\tF1:\t0.1542 *\n",
      "10 / 30: Train Loss:\t2.1792\tVal Loss:\t2.1250\tAccuracy:\t0.3107\tF1:\t0.2018 *\n",
      "11 / 30: Train Loss:\t2.0999\tVal Loss:\t2.0360\tAccuracy:\t0.3239\tF1:\t0.2205 *\n",
      "12 / 30: Train Loss:\t2.0076\tVal Loss:\t1.9080\tAccuracy:\t0.3654\tF1:\t0.2574 *\n",
      "13 / 30: Train Loss:\t1.8858\tVal Loss:\t1.8251\tAccuracy:\t0.3917\tF1:\t0.2826 *\n",
      "14 / 30: Train Loss:\t1.7937\tVal Loss:\t1.7686\tAccuracy:\t0.4092\tF1:\t0.3049 *\n",
      "15 / 30: Train Loss:\t1.6771\tVal Loss:\t1.6694\tAccuracy:\t0.4376\tF1:\t0.3628 *\n",
      "16 / 30: Train Loss:\t1.5744\tVal Loss:\t1.6239\tAccuracy:\t0.4376\tF1:\t0.3709 *\n",
      "17 / 30: Train Loss:\t1.5052\tVal Loss:\t1.5961\tAccuracy:\t0.4486\tF1:\t0.4003 *\n",
      "18 / 30: Train Loss:\t1.4395\tVal Loss:\t1.5458\tAccuracy:\t0.4792\tF1:\t0.4441 *\n",
      "19 / 30: Train Loss:\t1.3467\tVal Loss:\t1.5623\tAccuracy:\t0.4814\tF1:\t0.4505 *\n",
      "20 / 30: Train Loss:\t1.2897\tVal Loss:\t1.5725\tAccuracy:\t0.4880\tF1:\t0.4542 *\n",
      "21 / 30: Train Loss:\t1.2479\tVal Loss:\t1.5391\tAccuracy:\t0.4989\tF1:\t0.4570 *\n",
      "22 / 30: Train Loss:\t1.1728\tVal Loss:\t1.5285\tAccuracy:\t0.5120\tF1:\t0.4895 *\n",
      "23 / 30: Train Loss:\t1.1030\tVal Loss:\t1.5762\tAccuracy:\t0.4967\tF1:\t0.4641\n",
      "24 / 30: Train Loss:\t1.0348\tVal Loss:\t1.5749\tAccuracy:\t0.5098\tF1:\t0.4859\n",
      "25 / 30: Train Loss:\t0.9865\tVal Loss:\t1.5216\tAccuracy:\t0.5164\tF1:\t0.4862\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.68      0.37      0.48        67\n",
      "               anecdote       0.76      0.72      0.74        43\n",
      "         cherry picking       0.61      0.39      0.48        56\n",
      "      conspiracy theory       0.52      0.79      0.63        39\n",
      "           fake experts       0.57      0.67      0.62        12\n",
      "           false choice       0.50      0.46      0.48        13\n",
      "      false equivalence       0.21      0.21      0.21        14\n",
      "impossible expectations       0.33      0.62      0.43        37\n",
      "      misrepresentation       0.29      0.32      0.30        38\n",
      "     oversimplification       0.58      0.58      0.58        36\n",
      "           single cause       0.52      0.75      0.61        57\n",
      "     slothful induction       0.64      0.20      0.31        45\n",
      "\n",
      "               accuracy                           0.51       457\n",
      "              macro avg       0.52      0.51      0.49       457\n",
      "           weighted avg       0.55      0.51      0.50       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.70      0.38      0.49        37\n",
      "               anecdote       0.70      0.88      0.78        24\n",
      "         cherry picking       0.46      0.19      0.27        31\n",
      "      conspiracy theory       0.60      0.82      0.69        22\n",
      "           fake experts       0.57      0.57      0.57         7\n",
      "           false choice       0.17      0.29      0.21         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.43      0.71      0.54        21\n",
      "      misrepresentation       0.35      0.32      0.33        22\n",
      "     oversimplification       0.50      0.65      0.57        20\n",
      "           single cause       0.39      0.53      0.45        32\n",
      "     slothful induction       0.25      0.16      0.20        25\n",
      "\n",
      "               accuracy                           0.47       256\n",
      "              macro avg       0.43      0.46      0.42       256\n",
      "           weighted avg       0.47      0.47      0.45       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.6266\tVal Loss:\t2.3424\tAccuracy:\t0.2013\tF1:\t0.0824 *\n",
      "2 / 30: Train Loss:\t2.3336\tVal Loss:\t2.2754\tAccuracy:\t0.2276\tF1:\t0.1327 *\n",
      "3 / 30: Train Loss:\t2.1797\tVal Loss:\t2.0540\tAccuracy:\t0.3085\tF1:\t0.2483 *\n",
      "4 / 30: Train Loss:\t1.7936\tVal Loss:\t1.7507\tAccuracy:\t0.4026\tF1:\t0.3460 *\n",
      "5 / 30: Train Loss:\t1.4829\tVal Loss:\t1.5700\tAccuracy:\t0.4595\tF1:\t0.4094 *\n",
      "6 / 30: Train Loss:\t1.2146\tVal Loss:\t1.5907\tAccuracy:\t0.4748\tF1:\t0.4251 *\n",
      "7 / 30: Train Loss:\t1.0116\tVal Loss:\t1.6436\tAccuracy:\t0.4814\tF1:\t0.4558 *\n",
      "8 / 30: Train Loss:\t0.7988\tVal Loss:\t1.8927\tAccuracy:\t0.4902\tF1:\t0.4747 *\n",
      "9 / 30: Train Loss:\t0.7213\tVal Loss:\t1.7884\tAccuracy:\t0.5055\tF1:\t0.5044 *\n",
      "10 / 30: Train Loss:\t0.4975\tVal Loss:\t1.8117\tAccuracy:\t0.5427\tF1:\t0.5258 *\n",
      "11 / 30: Train Loss:\t0.3648\tVal Loss:\t2.0342\tAccuracy:\t0.4967\tF1:\t0.4913\n",
      "12 / 30: Train Loss:\t0.2508\tVal Loss:\t1.7090\tAccuracy:\t0.5667\tF1:\t0.5528 *\n",
      "13 / 30: Train Loss:\t0.1629\tVal Loss:\t1.7114\tAccuracy:\t0.5624\tF1:\t0.5420\n",
      "14 / 30: Train Loss:\t0.1069\tVal Loss:\t1.7619\tAccuracy:\t0.5733\tF1:\t0.5600 *\n",
      "15 / 30: Train Loss:\t0.1061\tVal Loss:\t1.7670\tAccuracy:\t0.5777\tF1:\t0.5580\n",
      "16 / 30: Train Loss:\t0.0709\tVal Loss:\t1.8905\tAccuracy:\t0.5470\tF1:\t0.5355\n",
      "17 / 30: Train Loss:\t0.0647\tVal Loss:\t1.7761\tAccuracy:\t0.5864\tF1:\t0.5721 *\n",
      "18 / 30: Train Loss:\t0.0624\tVal Loss:\t1.9759\tAccuracy:\t0.5799\tF1:\t0.5638\n",
      "19 / 30: Train Loss:\t0.0376\tVal Loss:\t1.9348\tAccuracy:\t0.5602\tF1:\t0.5476\n",
      "20 / 30: Train Loss:\t0.0382\tVal Loss:\t1.9227\tAccuracy:\t0.5821\tF1:\t0.5620\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.69      0.51      0.59        67\n",
      "               anecdote       0.77      0.77      0.77        43\n",
      "         cherry picking       0.69      0.36      0.47        56\n",
      "      conspiracy theory       0.59      0.85      0.69        39\n",
      "           fake experts       0.64      0.58      0.61        12\n",
      "           false choice       0.35      0.62      0.44        13\n",
      "      false equivalence       0.30      0.57      0.39        14\n",
      "impossible expectations       0.53      0.57      0.55        37\n",
      "      misrepresentation       0.42      0.58      0.48        38\n",
      "     oversimplification       0.65      0.67      0.66        36\n",
      "           single cause       0.68      0.53      0.59        57\n",
      "     slothful induction       0.62      0.62      0.62        45\n",
      "\n",
      "               accuracy                           0.59       457\n",
      "              macro avg       0.58      0.60      0.57       457\n",
      "           weighted avg       0.62      0.59      0.59       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.83      0.54      0.66        37\n",
      "               anecdote       0.79      0.92      0.85        24\n",
      "         cherry picking       0.71      0.32      0.44        31\n",
      "      conspiracy theory       0.63      0.86      0.73        22\n",
      "           fake experts       0.83      0.71      0.77         7\n",
      "           false choice       0.20      0.43      0.27         7\n",
      "      false equivalence       0.20      0.25      0.22         8\n",
      "impossible expectations       0.64      0.76      0.70        21\n",
      "      misrepresentation       0.52      0.68      0.59        22\n",
      "     oversimplification       0.47      0.80      0.59        20\n",
      "           single cause       0.63      0.53      0.58        32\n",
      "     slothful induction       0.50      0.28      0.36        25\n",
      "\n",
      "               accuracy                           0.59       256\n",
      "              macro avg       0.58      0.59      0.56       256\n",
      "           weighted avg       0.63      0.59      0.59       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.5868\tVal Loss:\t2.3106\tAccuracy:\t0.2254\tF1:\t0.1095 *\n",
      "2 / 30: Train Loss:\t2.2675\tVal Loss:\t2.2539\tAccuracy:\t0.2079\tF1:\t0.1578 *\n",
      "3 / 30: Train Loss:\t1.8849\tVal Loss:\t1.8168\tAccuracy:\t0.4136\tF1:\t0.3592 *\n",
      "4 / 30: Train Loss:\t1.4383\tVal Loss:\t1.4891\tAccuracy:\t0.4967\tF1:\t0.4465 *\n",
      "5 / 30: Train Loss:\t1.0646\tVal Loss:\t1.4957\tAccuracy:\t0.5164\tF1:\t0.4691 *\n",
      "6 / 30: Train Loss:\t0.7738\tVal Loss:\t1.5035\tAccuracy:\t0.5602\tF1:\t0.5453 *\n",
      "7 / 30: Train Loss:\t0.5478\tVal Loss:\t1.8897\tAccuracy:\t0.5427\tF1:\t0.5283\n",
      "8 / 30: Train Loss:\t0.3619\tVal Loss:\t2.3268\tAccuracy:\t0.5077\tF1:\t0.4838\n",
      "9 / 30: Train Loss:\t0.2915\tVal Loss:\t2.3947\tAccuracy:\t0.4792\tF1:\t0.4628\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.79      0.45      0.57        67\n",
      "               anecdote       0.93      0.65      0.77        43\n",
      "         cherry picking       0.60      0.55      0.57        56\n",
      "      conspiracy theory       0.76      0.79      0.77        39\n",
      "           fake experts       0.83      0.42      0.56        12\n",
      "           false choice       0.47      0.69      0.56        13\n",
      "      false equivalence       0.33      0.21      0.26        14\n",
      "impossible expectations       0.43      0.65      0.52        37\n",
      "      misrepresentation       0.30      0.66      0.41        38\n",
      "     oversimplification       0.51      0.64      0.57        36\n",
      "           single cause       0.62      0.61      0.62        57\n",
      "     slothful induction       0.57      0.27      0.36        45\n",
      "\n",
      "               accuracy                           0.56       457\n",
      "              macro avg       0.60      0.55      0.55       457\n",
      "           weighted avg       0.62      0.56      0.56       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.67      0.43      0.52        37\n",
      "               anecdote       0.81      0.71      0.76        24\n",
      "         cherry picking       0.48      0.32      0.38        31\n",
      "      conspiracy theory       0.74      0.64      0.68        22\n",
      "           fake experts       0.67      0.29      0.40         7\n",
      "           false choice       0.20      0.43      0.27         7\n",
      "      false equivalence       0.50      0.25      0.33         8\n",
      "impossible expectations       0.55      0.76      0.64        21\n",
      "      misrepresentation       0.33      0.77      0.46        22\n",
      "     oversimplification       0.45      0.75      0.57        20\n",
      "           single cause       0.55      0.53      0.54        32\n",
      "     slothful induction       0.50      0.08      0.14        25\n",
      "\n",
      "               accuracy                           0.51       256\n",
      "              macro avg       0.54      0.50      0.47       256\n",
      "           weighted avg       0.56      0.51      0.50       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t12.2972\tVal Loss:\t2.2351\tAccuracy:\t0.3786\tF1:\t0.3392 *\n",
      "2 / 30: Train Loss:\t1.3793\tVal Loss:\t1.9890\tAccuracy:\t0.4508\tF1:\t0.3930 *\n",
      "3 / 30: Train Loss:\t0.8893\tVal Loss:\t2.4685\tAccuracy:\t0.5230\tF1:\t0.4992 *\n",
      "4 / 30: Train Loss:\t0.4955\tVal Loss:\t3.0003\tAccuracy:\t0.4945\tF1:\t0.4638\n",
      "5 / 30: Train Loss:\t0.2619\tVal Loss:\t2.7601\tAccuracy:\t0.5449\tF1:\t0.5247 *\n",
      "6 / 30: Train Loss:\t0.0903\tVal Loss:\t2.7333\tAccuracy:\t0.5558\tF1:\t0.5433 *\n",
      "7 / 30: Train Loss:\t0.0480\tVal Loss:\t2.7850\tAccuracy:\t0.5777\tF1:\t0.5656 *\n",
      "8 / 30: Train Loss:\t0.0248\tVal Loss:\t2.5086\tAccuracy:\t0.5886\tF1:\t0.5879 *\n",
      "9 / 30: Train Loss:\t0.0193\tVal Loss:\t2.4669\tAccuracy:\t0.6193\tF1:\t0.6104 *\n",
      "10 / 30: Train Loss:\t0.0011\tVal Loss:\t2.3923\tAccuracy:\t0.6061\tF1:\t0.5911\n",
      "11 / 30: Train Loss:\t0.0034\tVal Loss:\t2.4107\tAccuracy:\t0.6061\tF1:\t0.5813\n",
      "12 / 30: Train Loss:\t0.0005\tVal Loss:\t2.3802\tAccuracy:\t0.6149\tF1:\t0.6047\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.58      0.63      0.60        67\n",
      "               anecdote       0.80      0.86      0.83        43\n",
      "         cherry picking       0.68      0.41      0.51        56\n",
      "      conspiracy theory       0.65      0.62      0.63        39\n",
      "           fake experts       0.73      0.67      0.70        12\n",
      "           false choice       0.88      0.54      0.67        13\n",
      "      false equivalence       0.44      0.29      0.35        14\n",
      "impossible expectations       0.62      0.43      0.51        37\n",
      "      misrepresentation       0.57      0.68      0.62        38\n",
      "     oversimplification       0.79      0.64      0.71        36\n",
      "           single cause       0.55      0.77      0.64        57\n",
      "     slothful induction       0.50      0.64      0.56        45\n",
      "\n",
      "               accuracy                           0.62       457\n",
      "              macro avg       0.65      0.60      0.61       457\n",
      "           weighted avg       0.63      0.62      0.61       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.62      0.68      0.65        37\n",
      "               anecdote       0.75      0.88      0.81        24\n",
      "         cherry picking       0.67      0.32      0.43        31\n",
      "      conspiracy theory       0.73      0.50      0.59        22\n",
      "           fake experts       1.00      0.29      0.44         7\n",
      "           false choice       0.57      0.57      0.57         7\n",
      "      false equivalence       0.17      0.12      0.14         8\n",
      "impossible expectations       0.59      0.62      0.60        21\n",
      "      misrepresentation       0.65      0.68      0.67        22\n",
      "     oversimplification       0.65      0.75      0.70        20\n",
      "           single cause       0.50      0.72      0.59        32\n",
      "     slothful induction       0.24      0.28      0.26        25\n",
      "\n",
      "               accuracy                           0.57       256\n",
      "              macro avg       0.60      0.53      0.54       256\n",
      "           weighted avg       0.59      0.57      0.57       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t9.2221\tVal Loss:\t2.2887\tAccuracy:\t0.3457\tF1:\t0.2619 *\n",
      "2 / 30: Train Loss:\t1.4755\tVal Loss:\t2.1322\tAccuracy:\t0.4748\tF1:\t0.4130 *\n",
      "3 / 30: Train Loss:\t0.7979\tVal Loss:\t2.6738\tAccuracy:\t0.5164\tF1:\t0.4612 *\n",
      "4 / 30: Train Loss:\t0.5484\tVal Loss:\t2.9105\tAccuracy:\t0.5405\tF1:\t0.4975 *\n",
      "5 / 30: Train Loss:\t0.2611\tVal Loss:\t3.1601\tAccuracy:\t0.5164\tF1:\t0.4945\n",
      "6 / 30: Train Loss:\t0.1980\tVal Loss:\t3.2558\tAccuracy:\t0.5252\tF1:\t0.5158 *\n",
      "7 / 30: Train Loss:\t0.1809\tVal Loss:\t2.3788\tAccuracy:\t0.6324\tF1:\t0.6269 *\n",
      "8 / 30: Train Loss:\t0.0702\tVal Loss:\t2.3745\tAccuracy:\t0.5952\tF1:\t0.5744\n",
      "9 / 30: Train Loss:\t0.0384\tVal Loss:\t2.3497\tAccuracy:\t0.6149\tF1:\t0.5933\n",
      "10 / 30: Train Loss:\t0.0024\tVal Loss:\t2.3741\tAccuracy:\t0.6521\tF1:\t0.6334 *\n",
      "11 / 30: Train Loss:\t0.0006\tVal Loss:\t2.3648\tAccuracy:\t0.6565\tF1:\t0.6361 *\n",
      "12 / 30: Train Loss:\t0.0001\tVal Loss:\t2.3564\tAccuracy:\t0.6543\tF1:\t0.6366 *\n",
      "13 / 30: Train Loss:\t0.0001\tVal Loss:\t2.3535\tAccuracy:\t0.6521\tF1:\t0.6346\n",
      "14 / 30: Train Loss:\t0.0001\tVal Loss:\t2.3527\tAccuracy:\t0.6521\tF1:\t0.6327\n",
      "15 / 30: Train Loss:\t0.0000\tVal Loss:\t2.3530\tAccuracy:\t0.6521\tF1:\t0.6327\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.68      0.64      0.66        67\n",
      "               anecdote       0.92      0.79      0.85        43\n",
      "         cherry picking       0.57      0.62      0.60        56\n",
      "      conspiracy theory       0.67      0.85      0.75        39\n",
      "           fake experts       0.70      0.58      0.64        12\n",
      "           false choice       0.75      0.69      0.72        13\n",
      "      false equivalence       0.43      0.21      0.29        14\n",
      "impossible expectations       0.69      0.59      0.64        37\n",
      "      misrepresentation       0.58      0.58      0.58        38\n",
      "     oversimplification       0.78      0.58      0.67        36\n",
      "           single cause       0.58      0.70      0.63        57\n",
      "     slothful induction       0.58      0.67      0.62        45\n",
      "\n",
      "               accuracy                           0.65       457\n",
      "              macro avg       0.66      0.63      0.64       457\n",
      "           weighted avg       0.66      0.65      0.65       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.68      0.62      0.65        37\n",
      "               anecdote       0.83      0.83      0.83        24\n",
      "         cherry picking       0.45      0.68      0.54        31\n",
      "      conspiracy theory       0.58      0.68      0.62        22\n",
      "           fake experts       1.00      0.43      0.60         7\n",
      "           false choice       0.30      0.43      0.35         7\n",
      "      false equivalence       0.25      0.12      0.17         8\n",
      "impossible expectations       0.71      0.57      0.63        21\n",
      "      misrepresentation       0.61      0.64      0.62        22\n",
      "     oversimplification       0.58      0.70      0.64        20\n",
      "           single cause       0.58      0.59      0.58        32\n",
      "     slothful induction       0.45      0.20      0.28        25\n",
      "\n",
      "               accuracy                           0.59       256\n",
      "              macro avg       0.58      0.54      0.54       256\n",
      "           weighted avg       0.60      0.59      0.58       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t11.6967\tVal Loss:\t2.8080\tAccuracy:\t0.1422\tF1:\t0.0351 *\n",
      "2 / 30: Train Loss:\t2.7533\tVal Loss:\t3.2294\tAccuracy:\t0.1028\tF1:\t0.0444 *\n",
      "3 / 30: Train Loss:\t2.2044\tVal Loss:\t2.6389\tAccuracy:\t0.2735\tF1:\t0.2048 *\n",
      "4 / 30: Train Loss:\t1.3879\tVal Loss:\t2.1067\tAccuracy:\t0.4814\tF1:\t0.4497 *\n",
      "5 / 30: Train Loss:\t0.8036\tVal Loss:\t6.4966\tAccuracy:\t0.2823\tF1:\t0.2372\n",
      "6 / 30: Train Loss:\t0.4473\tVal Loss:\t4.4695\tAccuracy:\t0.4551\tF1:\t0.3930\n",
      "7 / 30: Train Loss:\t0.2795\tVal Loss:\t3.7140\tAccuracy:\t0.5033\tF1:\t0.4478\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.59      0.51      0.54        67\n",
      "               anecdote       0.89      0.58      0.70        43\n",
      "         cherry picking       0.72      0.41      0.52        56\n",
      "      conspiracy theory       0.77      0.51      0.62        39\n",
      "           fake experts       0.22      0.17      0.19        12\n",
      "           false choice       0.39      0.54      0.45        13\n",
      "      false equivalence       0.22      0.14      0.17        14\n",
      "impossible expectations       0.40      0.43      0.42        37\n",
      "      misrepresentation       0.62      0.26      0.37        38\n",
      "     oversimplification       0.49      0.61      0.54        36\n",
      "           single cause       0.47      0.54      0.50        57\n",
      "     slothful induction       0.25      0.62      0.36        45\n",
      "\n",
      "               accuracy                           0.48       457\n",
      "              macro avg       0.50      0.44      0.45       457\n",
      "           weighted avg       0.55      0.48      0.49       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.57      0.43      0.49        37\n",
      "               anecdote       0.74      0.58      0.65        24\n",
      "         cherry picking       0.47      0.29      0.36        31\n",
      "      conspiracy theory       0.46      0.27      0.34        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.11      0.14      0.12         7\n",
      "      false equivalence       0.11      0.12      0.12         8\n",
      "impossible expectations       0.38      0.43      0.40        21\n",
      "      misrepresentation       0.56      0.23      0.32        22\n",
      "     oversimplification       0.52      0.70      0.60        20\n",
      "           single cause       0.29      0.31      0.30        32\n",
      "     slothful induction       0.18      0.44      0.26        25\n",
      "\n",
      "               accuracy                           0.38       256\n",
      "              macro avg       0.37      0.33      0.33       256\n",
      "           weighted avg       0.43      0.38      0.38       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.5073\tVal Loss:\t1.9581\tAccuracy:\t0.2910\tF1:\t0.1980 *\n",
      "2 / 30: Train Loss:\t2.1399\tVal Loss:\t2.1875\tAccuracy:\t0.2604\tF1:\t0.1461\n",
      "3 / 30: Train Loss:\t2.0063\tVal Loss:\t2.1887\tAccuracy:\t0.2429\tF1:\t0.1349\n",
      "4 / 30: Train Loss:\t2.3225\tVal Loss:\t2.4007\tAccuracy:\t0.1794\tF1:\t0.0925\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.45      0.34      0.39        67\n",
      "               anecdote       0.62      0.79      0.69        43\n",
      "         cherry picking       0.54      0.25      0.34        56\n",
      "      conspiracy theory       0.17      0.67      0.27        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.22      0.65      0.32        37\n",
      "      misrepresentation       0.18      0.24      0.20        38\n",
      "     oversimplification       0.75      0.08      0.15        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.29       457\n",
      "              macro avg       0.24      0.25      0.20       457\n",
      "           weighted avg       0.30      0.29      0.24       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.60      0.41      0.48        37\n",
      "               anecdote       0.60      0.75      0.67        24\n",
      "         cherry picking       0.44      0.26      0.33        31\n",
      "      conspiracy theory       0.16      0.64      0.26        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       1.00      0.12      0.22         8\n",
      "impossible expectations       0.22      0.76      0.34        21\n",
      "      misrepresentation       0.29      0.23      0.26        22\n",
      "     oversimplification       0.50      0.05      0.09        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.17      0.04      0.06        25\n",
      "\n",
      "               accuracy                           0.31       256\n",
      "              macro avg       0.33      0.27      0.23       256\n",
      "           weighted avg       0.34      0.31      0.27       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.8147\tVal Loss:\t2.2915\tAccuracy:\t0.1751\tF1:\t0.1088 *\n",
      "2 / 30: Train Loss:\t2.4144\tVal Loss:\t2.7027\tAccuracy:\t0.1028\tF1:\t0.0401\n",
      "3 / 30: Train Loss:\t2.4304\tVal Loss:\t2.3900\tAccuracy:\t0.1466\tF1:\t0.0213\n",
      "4 / 30: Train Loss:\t2.4025\tVal Loss:\t2.3781\tAccuracy:\t0.1050\tF1:\t0.0364\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.20      0.03      0.05        67\n",
      "               anecdote       0.54      0.33      0.41        43\n",
      "         cherry picking       0.25      0.23      0.24        56\n",
      "      conspiracy theory       0.13      0.82      0.23        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.19      0.30      0.23        37\n",
      "      misrepresentation       0.11      0.21      0.15        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.18       457\n",
      "              macro avg       0.12      0.16      0.11       457\n",
      "           weighted avg       0.15      0.18      0.13       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.54      0.29      0.38        24\n",
      "         cherry picking       0.28      0.32      0.30        31\n",
      "      conspiracy theory       0.13      0.82      0.23        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.26      0.38      0.31        21\n",
      "      misrepresentation       0.19      0.32      0.24        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.20       256\n",
      "              macro avg       0.12      0.18      0.12       256\n",
      "           weighted avg       0.13      0.20      0.14       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.9144\tVal Loss:\t2.4279\tAccuracy:\t0.0832\tF1:\t0.0128 *\n",
      "2 / 30: Train Loss:\t2.4379\tVal Loss:\t2.3951\tAccuracy:\t0.1466\tF1:\t0.0213 *\n",
      "3 / 30: Train Loss:\t2.4229\tVal Loss:\t2.3958\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "4 / 30: Train Loss:\t2.4139\tVal Loss:\t2.3937\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "5 / 30: Train Loss:\t2.4134\tVal Loss:\t2.3916\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.15      1.00      0.26        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.15       457\n",
      "              macro avg       0.01      0.08      0.02       457\n",
      "           weighted avg       0.02      0.15      0.04       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.14      1.00      0.25        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.14       256\n",
      "              macro avg       0.01      0.08      0.02       256\n",
      "           weighted avg       0.02      0.14      0.04       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4305\tVal Loss:\t1.9503\tAccuracy:\t0.3632\tF1:\t0.2714 *\n",
      "2 / 30: Train Loss:\t1.1990\tVal Loss:\t1.7496\tAccuracy:\t0.4158\tF1:\t0.3547 *\n",
      "3 / 30: Train Loss:\t0.4360\tVal Loss:\t1.9091\tAccuracy:\t0.4376\tF1:\t0.3923 *\n",
      "4 / 30: Train Loss:\t0.2173\tVal Loss:\t1.8900\tAccuracy:\t0.4420\tF1:\t0.4053 *\n",
      "5 / 30: Train Loss:\t0.0731\tVal Loss:\t1.9910\tAccuracy:\t0.4661\tF1:\t0.4276 *\n",
      "6 / 30: Train Loss:\t0.0305\tVal Loss:\t1.8254\tAccuracy:\t0.4792\tF1:\t0.4418 *\n",
      "7 / 30: Train Loss:\t0.0124\tVal Loss:\t1.8738\tAccuracy:\t0.4770\tF1:\t0.4422 *\n",
      "8 / 30: Train Loss:\t0.0072\tVal Loss:\t1.8539\tAccuracy:\t0.4683\tF1:\t0.4273\n",
      "9 / 30: Train Loss:\t0.0020\tVal Loss:\t1.8749\tAccuracy:\t0.4639\tF1:\t0.4075\n",
      "10 / 30: Train Loss:\t0.0015\tVal Loss:\t1.8845\tAccuracy:\t0.4705\tF1:\t0.4129\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.41      0.69      0.51        67\n",
      "               anecdote       0.67      0.70      0.68        43\n",
      "         cherry picking       0.54      0.39      0.45        56\n",
      "      conspiracy theory       0.61      0.51      0.56        39\n",
      "           fake experts       0.50      0.17      0.25        12\n",
      "           false choice       0.67      0.31      0.42        13\n",
      "      false equivalence       0.29      0.14      0.19        14\n",
      "impossible expectations       0.38      0.38      0.38        37\n",
      "      misrepresentation       0.48      0.37      0.42        38\n",
      "     oversimplification       0.77      0.56      0.65        36\n",
      "           single cause       0.45      0.46      0.45        57\n",
      "     slothful induction       0.31      0.40      0.35        45\n",
      "\n",
      "               accuracy                           0.48       457\n",
      "              macro avg       0.50      0.42      0.44       457\n",
      "           weighted avg       0.50      0.48      0.47       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.47      0.70      0.57        37\n",
      "               anecdote       0.80      0.83      0.82        24\n",
      "         cherry picking       0.42      0.26      0.32        31\n",
      "      conspiracy theory       0.65      0.50      0.56        22\n",
      "           fake experts       0.67      0.29      0.40         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.62      0.62      0.62        21\n",
      "      misrepresentation       0.65      0.50      0.56        22\n",
      "     oversimplification       0.60      0.60      0.60        20\n",
      "           single cause       0.49      0.62      0.55        32\n",
      "     slothful induction       0.21      0.28      0.24        25\n",
      "\n",
      "               accuracy                           0.51       256\n",
      "              macro avg       0.46      0.43      0.44       256\n",
      "           weighted avg       0.50      0.51      0.49       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.1048\tVal Loss:\t1.3876\tAccuracy:\t0.5208\tF1:\t0.4536 *\n",
      "2 / 30: Train Loss:\t1.0011\tVal Loss:\t1.5238\tAccuracy:\t0.5449\tF1:\t0.5398 *\n",
      "3 / 30: Train Loss:\t0.3424\tVal Loss:\t1.8086\tAccuracy:\t0.5624\tF1:\t0.5324\n",
      "4 / 30: Train Loss:\t0.1723\tVal Loss:\t1.7508\tAccuracy:\t0.5842\tF1:\t0.5740 *\n",
      "5 / 30: Train Loss:\t0.0632\tVal Loss:\t1.7771\tAccuracy:\t0.5864\tF1:\t0.5726\n",
      "6 / 30: Train Loss:\t0.0336\tVal Loss:\t1.9801\tAccuracy:\t0.5886\tF1:\t0.5747 *\n",
      "7 / 30: Train Loss:\t0.0128\tVal Loss:\t1.7419\tAccuracy:\t0.5974\tF1:\t0.5930 *\n",
      "8 / 30: Train Loss:\t0.0010\tVal Loss:\t1.7660\tAccuracy:\t0.6018\tF1:\t0.6029 *\n",
      "9 / 30: Train Loss:\t0.0003\tVal Loss:\t1.7666\tAccuracy:\t0.6083\tF1:\t0.6073 *\n",
      "10 / 30: Train Loss:\t0.0002\tVal Loss:\t1.7755\tAccuracy:\t0.6127\tF1:\t0.6107 *\n",
      "11 / 30: Train Loss:\t0.0002\tVal Loss:\t1.7841\tAccuracy:\t0.6127\tF1:\t0.6101\n",
      "12 / 30: Train Loss:\t0.0002\tVal Loss:\t1.7922\tAccuracy:\t0.6105\tF1:\t0.6100\n",
      "13 / 30: Train Loss:\t0.0001\tVal Loss:\t1.7997\tAccuracy:\t0.6127\tF1:\t0.6114 *\n",
      "14 / 30: Train Loss:\t0.0001\tVal Loss:\t1.8067\tAccuracy:\t0.6127\tF1:\t0.6059\n",
      "15 / 30: Train Loss:\t0.0001\tVal Loss:\t1.8133\tAccuracy:\t0.6149\tF1:\t0.6076\n",
      "16 / 30: Train Loss:\t0.0001\tVal Loss:\t1.8195\tAccuracy:\t0.6127\tF1:\t0.6062\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.58      0.63      0.60        67\n",
      "               anecdote       0.74      0.72      0.73        43\n",
      "         cherry picking       0.55      0.62      0.58        56\n",
      "      conspiracy theory       0.73      0.77      0.75        39\n",
      "           fake experts       0.82      0.75      0.78        12\n",
      "           false choice       0.88      0.54      0.67        13\n",
      "      false equivalence       0.43      0.21      0.29        14\n",
      "impossible expectations       0.59      0.59      0.59        37\n",
      "      misrepresentation       0.52      0.58      0.55        38\n",
      "     oversimplification       0.82      0.64      0.72        36\n",
      "           single cause       0.62      0.60      0.61        57\n",
      "     slothful induction       0.45      0.49      0.47        45\n",
      "\n",
      "               accuracy                           0.61       457\n",
      "              macro avg       0.64      0.60      0.61       457\n",
      "           weighted avg       0.62      0.61      0.61       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.66      0.78      0.72        37\n",
      "               anecdote       0.80      0.83      0.82        24\n",
      "         cherry picking       0.53      0.55      0.54        31\n",
      "      conspiracy theory       0.81      0.59      0.68        22\n",
      "           fake experts       1.00      0.71      0.83         7\n",
      "           false choice       0.60      0.43      0.50         7\n",
      "      false equivalence       0.75      0.38      0.50         8\n",
      "impossible expectations       0.79      0.71      0.75        21\n",
      "      misrepresentation       0.80      0.73      0.76        22\n",
      "     oversimplification       0.60      0.75      0.67        20\n",
      "           single cause       0.62      0.72      0.67        32\n",
      "     slothful induction       0.33      0.32      0.33        25\n",
      "\n",
      "               accuracy                           0.65       256\n",
      "              macro avg       0.69      0.63      0.65       256\n",
      "           weighted avg       0.66      0.65      0.65       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.3253\tVal Loss:\t1.3558\tAccuracy:\t0.5470\tF1:\t0.4867 *\n",
      "2 / 30: Train Loss:\t1.0557\tVal Loss:\t1.4081\tAccuracy:\t0.5733\tF1:\t0.5305 *\n",
      "3 / 30: Train Loss:\t0.2916\tVal Loss:\t1.8979\tAccuracy:\t0.5799\tF1:\t0.5657 *\n",
      "4 / 30: Train Loss:\t0.3797\tVal Loss:\t1.8018\tAccuracy:\t0.5274\tF1:\t0.4964\n",
      "5 / 30: Train Loss:\t0.4702\tVal Loss:\t2.1181\tAccuracy:\t0.5602\tF1:\t0.5621\n",
      "6 / 30: Train Loss:\t0.0981\tVal Loss:\t2.3121\tAccuracy:\t0.5886\tF1:\t0.5848 *\n",
      "7 / 30: Train Loss:\t0.0275\tVal Loss:\t2.1508\tAccuracy:\t0.5864\tF1:\t0.5904 *\n",
      "8 / 30: Train Loss:\t0.0092\tVal Loss:\t2.1661\tAccuracy:\t0.6018\tF1:\t0.6046 *\n",
      "9 / 30: Train Loss:\t0.0003\tVal Loss:\t2.1413\tAccuracy:\t0.6018\tF1:\t0.6091 *\n",
      "10 / 30: Train Loss:\t0.0001\tVal Loss:\t2.1503\tAccuracy:\t0.6018\tF1:\t0.6100 *\n",
      "11 / 30: Train Loss:\t0.0001\tVal Loss:\t2.1588\tAccuracy:\t0.6018\tF1:\t0.6100\n",
      "12 / 30: Train Loss:\t0.0001\tVal Loss:\t2.1669\tAccuracy:\t0.6018\tF1:\t0.6100\n",
      "13 / 30: Train Loss:\t0.0001\tVal Loss:\t2.1747\tAccuracy:\t0.6061\tF1:\t0.6161 *\n",
      "14 / 30: Train Loss:\t0.0001\tVal Loss:\t2.1821\tAccuracy:\t0.6061\tF1:\t0.6161\n",
      "15 / 30: Train Loss:\t0.0001\tVal Loss:\t2.1892\tAccuracy:\t0.6061\tF1:\t0.6159\n",
      "16 / 30: Train Loss:\t0.0000\tVal Loss:\t2.1961\tAccuracy:\t0.6061\tF1:\t0.6159\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.54      0.66      0.59        67\n",
      "               anecdote       0.74      0.67      0.71        43\n",
      "         cherry picking       0.52      0.57      0.55        56\n",
      "      conspiracy theory       0.66      0.69      0.68        39\n",
      "           fake experts       1.00      0.67      0.80        12\n",
      "           false choice       0.80      0.62      0.70        13\n",
      "      false equivalence       0.80      0.29      0.42        14\n",
      "impossible expectations       0.57      0.62      0.60        37\n",
      "      misrepresentation       0.68      0.50      0.58        38\n",
      "     oversimplification       0.65      0.61      0.63        36\n",
      "           single cause       0.66      0.58      0.62        57\n",
      "     slothful induction       0.47      0.62      0.54        45\n",
      "\n",
      "               accuracy                           0.61       457\n",
      "              macro avg       0.67      0.59      0.62       457\n",
      "           weighted avg       0.63      0.61      0.61       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.62      0.68      0.65        37\n",
      "               anecdote       0.85      0.92      0.88        24\n",
      "         cherry picking       0.62      0.58      0.60        31\n",
      "      conspiracy theory       0.65      0.50      0.56        22\n",
      "           fake experts       0.71      0.71      0.71         7\n",
      "           false choice       0.50      0.29      0.36         7\n",
      "      false equivalence       0.50      0.25      0.33         8\n",
      "impossible expectations       0.64      0.67      0.65        21\n",
      "      misrepresentation       0.63      0.55      0.59        22\n",
      "     oversimplification       0.54      0.65      0.59        20\n",
      "           single cause       0.62      0.62      0.62        32\n",
      "     slothful induction       0.34      0.44      0.39        25\n",
      "\n",
      "               accuracy                           0.61       256\n",
      "              macro avg       0.60      0.57      0.58       256\n",
      "           weighted avg       0.61      0.61      0.60       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.3660\tVal Loss:\t2.0162\tAccuracy:\t0.3479\tF1:\t0.2233 *\n",
      "2 / 30: Train Loss:\t1.7856\tVal Loss:\t1.5339\tAccuracy:\t0.4967\tF1:\t0.3598 *\n",
      "3 / 30: Train Loss:\t1.3403\tVal Loss:\t1.3740\tAccuracy:\t0.5558\tF1:\t0.4308 *\n",
      "4 / 30: Train Loss:\t1.0307\tVal Loss:\t1.2275\tAccuracy:\t0.5952\tF1:\t0.4759 *\n",
      "5 / 30: Train Loss:\t0.7939\tVal Loss:\t1.1535\tAccuracy:\t0.6346\tF1:\t0.5753 *\n",
      "6 / 30: Train Loss:\t0.6244\tVal Loss:\t1.1471\tAccuracy:\t0.6433\tF1:\t0.6115 *\n",
      "7 / 30: Train Loss:\t0.4842\tVal Loss:\t1.2059\tAccuracy:\t0.6346\tF1:\t0.6076\n",
      "8 / 30: Train Loss:\t0.3819\tVal Loss:\t1.2881\tAccuracy:\t0.6389\tF1:\t0.6108\n",
      "9 / 30: Train Loss:\t0.2976\tVal Loss:\t1.2358\tAccuracy:\t0.6652\tF1:\t0.6583 *\n",
      "10 / 30: Train Loss:\t0.2419\tVal Loss:\t1.2372\tAccuracy:\t0.6674\tF1:\t0.6585 *\n",
      "11 / 30: Train Loss:\t0.1931\tVal Loss:\t1.2493\tAccuracy:\t0.6783\tF1:\t0.6765 *\n",
      "12 / 30: Train Loss:\t0.1533\tVal Loss:\t1.3459\tAccuracy:\t0.6586\tF1:\t0.6496\n",
      "13 / 30: Train Loss:\t0.1115\tVal Loss:\t1.3537\tAccuracy:\t0.6630\tF1:\t0.6578\n",
      "14 / 30: Train Loss:\t0.0767\tVal Loss:\t1.3391\tAccuracy:\t0.6849\tF1:\t0.6778 *\n",
      "15 / 30: Train Loss:\t0.0596\tVal Loss:\t1.3692\tAccuracy:\t0.6696\tF1:\t0.6580\n",
      "16 / 30: Train Loss:\t0.0568\tVal Loss:\t1.4204\tAccuracy:\t0.6740\tF1:\t0.6700\n",
      "17 / 30: Train Loss:\t0.0374\tVal Loss:\t1.4011\tAccuracy:\t0.6740\tF1:\t0.6694\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.76      0.63      0.69        67\n",
      "               anecdote       0.88      0.86      0.87        43\n",
      "         cherry picking       0.68      0.64      0.66        56\n",
      "      conspiracy theory       0.72      0.74      0.73        39\n",
      "           fake experts       0.67      0.83      0.74        12\n",
      "           false choice       0.64      0.54      0.58        13\n",
      "      false equivalence       0.67      0.57      0.62        14\n",
      "impossible expectations       0.75      0.57      0.65        37\n",
      "      misrepresentation       0.59      0.58      0.59        38\n",
      "     oversimplification       0.83      0.56      0.67        36\n",
      "           single cause       0.69      0.75      0.72        57\n",
      "     slothful induction       0.49      0.84      0.62        45\n",
      "\n",
      "               accuracy                           0.68       457\n",
      "              macro avg       0.70      0.68      0.68       457\n",
      "           weighted avg       0.71      0.68      0.69       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.84      0.86      0.85        37\n",
      "               anecdote       0.80      0.83      0.82        24\n",
      "         cherry picking       0.85      0.55      0.67        31\n",
      "      conspiracy theory       0.90      0.82      0.86        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.27      0.43      0.33         7\n",
      "      false equivalence       0.33      0.38      0.35         8\n",
      "impossible expectations       0.71      0.57      0.63        21\n",
      "      misrepresentation       0.57      0.73      0.64        22\n",
      "     oversimplification       0.72      0.65      0.68        20\n",
      "           single cause       0.83      0.75      0.79        32\n",
      "     slothful induction       0.40      0.56      0.47        25\n",
      "\n",
      "               accuracy                           0.70       256\n",
      "              macro avg       0.69      0.67      0.67       256\n",
      "           weighted avg       0.73      0.70      0.70       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875, 0.6953125], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219, 0.6676801839073718], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315, 0.6849015317286652], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158, 0.6777801352334527], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t1.9577\tVal Loss:\t1.6383\tAccuracy:\t0.4726\tF1:\t0.3842 *\n",
      "2 / 30: Train Loss:\t1.1880\tVal Loss:\t1.2219\tAccuracy:\t0.5930\tF1:\t0.5188 *\n",
      "3 / 30: Train Loss:\t0.7498\tVal Loss:\t1.2800\tAccuracy:\t0.6061\tF1:\t0.5416 *\n",
      "4 / 30: Train Loss:\t0.4882\tVal Loss:\t1.3398\tAccuracy:\t0.6280\tF1:\t0.5853 *\n",
      "5 / 30: Train Loss:\t0.3088\tVal Loss:\t1.2540\tAccuracy:\t0.6543\tF1:\t0.6262 *\n",
      "6 / 30: Train Loss:\t0.2196\tVal Loss:\t1.3769\tAccuracy:\t0.6543\tF1:\t0.6378 *\n",
      "7 / 30: Train Loss:\t0.1764\tVal Loss:\t1.4553\tAccuracy:\t0.6608\tF1:\t0.6395 *\n",
      "8 / 30: Train Loss:\t0.1145\tVal Loss:\t1.4185\tAccuracy:\t0.6783\tF1:\t0.6684 *\n",
      "9 / 30: Train Loss:\t0.0847\tVal Loss:\t1.7438\tAccuracy:\t0.6083\tF1:\t0.5953\n",
      "10 / 30: Train Loss:\t0.1049\tVal Loss:\t1.4977\tAccuracy:\t0.6761\tF1:\t0.6549\n",
      "11 / 30: Train Loss:\t0.0915\tVal Loss:\t1.6758\tAccuracy:\t0.6127\tF1:\t0.6173\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.69      0.57      0.62        67\n",
      "               anecdote       0.90      0.88      0.89        43\n",
      "         cherry picking       0.60      0.73      0.66        56\n",
      "      conspiracy theory       0.67      0.87      0.76        39\n",
      "           fake experts       0.56      0.75      0.64        12\n",
      "           false choice       0.67      0.77      0.71        13\n",
      "      false equivalence       0.33      0.57      0.42        14\n",
      "impossible expectations       0.70      0.62      0.66        37\n",
      "      misrepresentation       0.66      0.61      0.63        38\n",
      "     oversimplification       0.77      0.64      0.70        36\n",
      "           single cause       0.83      0.60      0.69        57\n",
      "     slothful induction       0.62      0.64      0.63        45\n",
      "\n",
      "               accuracy                           0.68       457\n",
      "              macro avg       0.67      0.69      0.67       457\n",
      "           weighted avg       0.70      0.68      0.68       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.84      0.70      0.76        37\n",
      "               anecdote       0.80      0.83      0.82        24\n",
      "         cherry picking       0.67      0.65      0.66        31\n",
      "      conspiracy theory       0.72      0.82      0.77        22\n",
      "           fake experts       0.67      0.86      0.75         7\n",
      "           false choice       0.33      0.43      0.38         7\n",
      "      false equivalence       0.23      0.38      0.29         8\n",
      "impossible expectations       0.70      0.67      0.68        21\n",
      "      misrepresentation       0.65      0.77      0.71        22\n",
      "     oversimplification       0.74      0.70      0.72        20\n",
      "           single cause       0.73      0.59      0.66        32\n",
      "     slothful induction       0.39      0.36      0.37        25\n",
      "\n",
      "               accuracy                           0.66       256\n",
      "              macro avg       0.62      0.65      0.63       256\n",
      "           weighted avg       0.67      0.66      0.66       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875, 0.6953125, 0.66015625], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219, 0.6676801839073718, 0.6294019287291218], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315, 0.6849015317286652, 0.6783369803063457], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158, 0.6777801352334527, 0.6683893089693324], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t1.9289\tVal Loss:\t1.6456\tAccuracy:\t0.4464\tF1:\t0.3756 *\n",
      "2 / 30: Train Loss:\t1.2828\tVal Loss:\t1.4576\tAccuracy:\t0.5711\tF1:\t0.4716 *\n",
      "3 / 30: Train Loss:\t0.8443\tVal Loss:\t1.3532\tAccuracy:\t0.5886\tF1:\t0.5077 *\n",
      "4 / 30: Train Loss:\t0.5607\tVal Loss:\t1.6290\tAccuracy:\t0.5821\tF1:\t0.5728 *\n",
      "5 / 30: Train Loss:\t0.3970\tVal Loss:\t1.6619\tAccuracy:\t0.5974\tF1:\t0.5865 *\n",
      "6 / 30: Train Loss:\t0.2629\tVal Loss:\t1.5617\tAccuracy:\t0.6389\tF1:\t0.6201 *\n",
      "7 / 30: Train Loss:\t0.2199\tVal Loss:\t1.6901\tAccuracy:\t0.6258\tF1:\t0.5993\n",
      "8 / 30: Train Loss:\t0.1640\tVal Loss:\t1.5278\tAccuracy:\t0.6543\tF1:\t0.6425 *\n",
      "9 / 30: Train Loss:\t0.1366\tVal Loss:\t1.8228\tAccuracy:\t0.6236\tF1:\t0.6050\n",
      "10 / 30: Train Loss:\t0.1692\tVal Loss:\t1.6195\tAccuracy:\t0.6236\tF1:\t0.6048\n",
      "11 / 30: Train Loss:\t0.1723\tVal Loss:\t1.5422\tAccuracy:\t0.6565\tF1:\t0.6417\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.75      0.58      0.66        67\n",
      "               anecdote       0.97      0.79      0.87        43\n",
      "         cherry picking       0.52      0.82      0.63        56\n",
      "      conspiracy theory       0.76      0.82      0.79        39\n",
      "           fake experts       0.62      0.67      0.64        12\n",
      "           false choice       0.57      0.62      0.59        13\n",
      "      false equivalence       0.30      0.79      0.43        14\n",
      "impossible expectations       0.72      0.49      0.58        37\n",
      "      misrepresentation       0.71      0.63      0.67        38\n",
      "     oversimplification       0.59      0.64      0.61        36\n",
      "           single cause       0.74      0.61      0.67        57\n",
      "     slothful induction       0.70      0.47      0.56        45\n",
      "\n",
      "               accuracy                           0.65       457\n",
      "              macro avg       0.66      0.66      0.64       457\n",
      "           weighted avg       0.70      0.65      0.66       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.83      0.65      0.73        37\n",
      "               anecdote       0.88      0.88      0.88        24\n",
      "         cherry picking       0.50      0.61      0.55        31\n",
      "      conspiracy theory       0.73      0.73      0.73        22\n",
      "           fake experts       1.00      0.86      0.92         7\n",
      "           false choice       0.40      0.57      0.47         7\n",
      "      false equivalence       0.20      0.50      0.29         8\n",
      "impossible expectations       0.92      0.57      0.71        21\n",
      "      misrepresentation       0.64      0.64      0.64        22\n",
      "     oversimplification       0.50      0.85      0.63        20\n",
      "           single cause       0.69      0.56      0.62        32\n",
      "     slothful induction       0.50      0.24      0.32        25\n",
      "\n",
      "               accuracy                           0.63       256\n",
      "              macro avg       0.65      0.64      0.62       256\n",
      "           weighted avg       0.67      0.63      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875, 0.6953125, 0.66015625, 0.62890625], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219, 0.6676801839073718, 0.6294019287291218, 0.6230449278952601], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315, 0.6849015317286652, 0.6783369803063457, 0.6542669584245077], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158, 0.6777801352334527, 0.6683893089693324, 0.6424625415049233], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-base']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.0129\tVal Loss:\t1.2845\tAccuracy:\t0.5733\tF1:\t0.4359 *\n",
      "2 / 30: Train Loss:\t1.0848\tVal Loss:\t0.9379\tAccuracy:\t0.6937\tF1:\t0.6550 *\n",
      "3 / 30: Train Loss:\t0.6729\tVal Loss:\t0.8689\tAccuracy:\t0.7177\tF1:\t0.7139 *\n",
      "4 / 30: Train Loss:\t0.4314\tVal Loss:\t0.8517\tAccuracy:\t0.7505\tF1:\t0.7359 *\n",
      "5 / 30: Train Loss:\t0.2699\tVal Loss:\t0.9026\tAccuracy:\t0.7593\tF1:\t0.7468 *\n",
      "6 / 30: Train Loss:\t0.1613\tVal Loss:\t1.0972\tAccuracy:\t0.7352\tF1:\t0.7294\n",
      "7 / 30: Train Loss:\t0.1045\tVal Loss:\t1.1819\tAccuracy:\t0.7265\tF1:\t0.7225\n",
      "8 / 30: Train Loss:\t0.0722\tVal Loss:\t1.1893\tAccuracy:\t0.7396\tF1:\t0.7142\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.81      0.75      0.78        67\n",
      "               anecdote       0.95      0.88      0.92        43\n",
      "         cherry picking       0.72      0.73      0.73        56\n",
      "      conspiracy theory       0.83      0.87      0.85        39\n",
      "           fake experts       0.91      0.83      0.87        12\n",
      "           false choice       0.83      0.77      0.80        13\n",
      "      false equivalence       0.62      0.36      0.45        14\n",
      "impossible expectations       0.85      0.59      0.70        37\n",
      "      misrepresentation       0.54      0.82      0.65        38\n",
      "     oversimplification       0.74      0.64      0.69        36\n",
      "           single cause       0.76      0.89      0.82        57\n",
      "     slothful induction       0.71      0.71      0.71        45\n",
      "\n",
      "               accuracy                           0.76       457\n",
      "              macro avg       0.77      0.74      0.75       457\n",
      "           weighted avg       0.77      0.76      0.76       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.80      0.76      0.78        37\n",
      "               anecdote       0.91      0.88      0.89        24\n",
      "         cherry picking       0.72      0.58      0.64        31\n",
      "      conspiracy theory       0.75      0.82      0.78        22\n",
      "           fake experts       1.00      0.71      0.83         7\n",
      "           false choice       0.40      0.29      0.33         7\n",
      "      false equivalence       0.67      0.50      0.57         8\n",
      "impossible expectations       0.76      0.62      0.68        21\n",
      "      misrepresentation       0.47      0.68      0.56        22\n",
      "     oversimplification       0.52      0.85      0.64        20\n",
      "           single cause       0.74      0.81      0.78        32\n",
      "     slothful induction       0.62      0.40      0.49        25\n",
      "\n",
      "               accuracy                           0.69       256\n",
      "              macro avg       0.70      0.66      0.67       256\n",
      "           weighted avg       0.71      0.69      0.69       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875, 0.6953125, 0.66015625, 0.62890625, 0.69140625], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219, 0.6676801839073718, 0.6294019287291218, 0.6230449278952601, 0.6650129727105328], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315, 0.6849015317286652, 0.6783369803063457, 0.6542669584245077, 0.7592997811816192], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158, 0.6777801352334527, 0.6683893089693324, 0.6424625415049233, 0.7468278363012093], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-v2-xlarge']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.0304\tVal Loss:\t1.4738\tAccuracy:\t0.5208\tF1:\t0.3938 *\n",
      "2 / 30: Train Loss:\t1.8828\tVal Loss:\t2.3789\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "3 / 30: Train Loss:\t2.3911\tVal Loss:\t2.3776\tAccuracy:\t0.1466\tF1:\t0.0213\n",
      "4 / 30: Train Loss:\t2.3942\tVal Loss:\t2.3752\tAccuracy:\t0.1466\tF1:\t0.0213\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.65      0.55      0.60        67\n",
      "               anecdote       0.79      0.88      0.84        43\n",
      "         cherry picking       0.37      0.71      0.48        56\n",
      "      conspiracy theory       0.56      0.92      0.70        39\n",
      "           fake experts       0.50      0.08      0.14        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.31      0.65      0.42        37\n",
      "      misrepresentation       0.90      0.24      0.38        38\n",
      "     oversimplification       0.56      0.67      0.61        36\n",
      "           single cause       0.63      0.51      0.56        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.52       457\n",
      "              macro avg       0.44      0.43      0.39       457\n",
      "           weighted avg       0.50      0.52      0.47       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.86      0.65      0.74        37\n",
      "               anecdote       0.73      1.00      0.84        24\n",
      "         cherry picking       0.31      0.61      0.41        31\n",
      "      conspiracy theory       0.64      0.82      0.72        22\n",
      "           fake experts       1.00      0.14      0.25         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.41      0.81      0.55        21\n",
      "      misrepresentation       0.80      0.18      0.30        22\n",
      "     oversimplification       0.54      0.75      0.63        20\n",
      "           single cause       0.53      0.50      0.52        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.54       256\n",
      "              macro avg       0.48      0.46      0.41       256\n",
      "           weighted avg       0.52      0.54      0.49       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875, 0.6953125, 0.66015625, 0.62890625, 0.69140625, 0.5390625], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219, 0.6676801839073718, 0.6294019287291218, 0.6230449278952601, 0.6650129727105328, 0.4120817814571352], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315, 0.6849015317286652, 0.6783369803063457, 0.6542669584245077, 0.7592997811816192, 0.5207877461706784], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158, 0.6777801352334527, 0.6683893089693324, 0.6424625415049233, 0.7468278363012093, 0.39378567891972954], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-v2-xlarge', 'microsoft/deberta-v2-xlarge']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4197\tVal Loss:\t2.3865\tAccuracy:\t0.1225\tF1:\t0.0182 *\n",
      "2 / 30: Train Loss:\t2.3963\tVal Loss:\t2.3895\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "3 / 30: Train Loss:\t2.3947\tVal Loss:\t2.3887\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "4 / 30: Train Loss:\t2.3949\tVal Loss:\t2.3859\tAccuracy:\t0.1225\tF1:\t0.0182\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.12      1.00      0.22        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.12       457\n",
      "              macro avg       0.01      0.08      0.02       457\n",
      "           weighted avg       0.02      0.12      0.03       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.12      1.00      0.22        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.12       256\n",
      "              macro avg       0.01      0.08      0.02       256\n",
      "           weighted avg       0.01      0.12      0.03       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.62890625, 0.65625, 0.62109375, 0.69921875, 0.6875, 0.14453125, 0.47265625, 0.59375, 0.51171875, 0.57421875, 0.5859375, 0.375, 0.30859375, 0.1953125, 0.14453125, 0.5078125, 0.65234375, 0.60546875, 0.6953125, 0.66015625, 0.62890625, 0.69140625, 0.5390625, 0.12109375], 'test_f1': [0.5629745180805673, 0.6474613734588849, 0.5843761469301547, 0.6636704594002731, 0.6755374111079281, 0.02104664391353811, 0.4243959235691948, 0.562750924708678, 0.47473827574234, 0.538595451344019, 0.5430706672686025, 0.3301351189061111, 0.2264078508102798, 0.12057219036253947, 0.02104664391353811, 0.43651009874946833, 0.6467809183452459, 0.578592606021219, 0.6676801839073718, 0.6294019287291218, 0.6230449278952601, 0.6650129727105328, 0.4120817814571352, 0.018002322880371662], 'eval_acc': [0.6673960612691466, 0.6695842450765864, 0.6433260393873085, 0.7286652078774617, 0.7133479212253829, 0.14660831509846828, 0.5120350109409191, 0.5864332603938731, 0.5601750547045952, 0.6192560175054704, 0.6542669584245077, 0.4814004376367615, 0.2910284463894967, 0.175054704595186, 0.14660831509846828, 0.47702407002188185, 0.612691466083151, 0.6061269146608315, 0.6849015317286652, 0.6783369803063457, 0.6542669584245077, 0.7592997811816192, 0.5207877461706784, 0.12253829321663019], 'eval_f1': [0.6354170380704479, 0.6334794330566359, 0.6311036952205802, 0.7112221793055286, 0.7067789482838771, 0.021310432569974558, 0.48946015168748125, 0.5720953947652325, 0.5452935647109665, 0.6103678881157802, 0.6365566260305462, 0.44973828359448914, 0.19795226666591723, 0.10883251578943624, 0.021310432569974558, 0.4422300425479245, 0.6113589420160643, 0.6161375018847158, 0.6777801352334527, 0.6683893089693324, 0.6424625415049233, 0.7468278363012093, 0.39378567891972954, 0.01819363222871995], 'lr': [1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001, 1e-05, 5e-05, 0.0001], 'model': ['bert-base-uncased', 'bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-v2-xlarge', 'microsoft/deberta-v2-xlarge', 'microsoft/deberta-v2-xlarge']}\n",
      "### ### ### ### ### ### ### ### ### ### \n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1.0e-5, 5.0e-5 ,1.0e-4]\n",
    "for model_checkpoint in model_checkpoints:\n",
    "    for lr in learning_rates:\n",
    "        print(f'Grid search {model_checkpoint}, learning rate {lr}')\n",
    "        data = ClimateDataset(model_to_train=4,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=32)\n",
    "        data.setup_dataloaders()\n",
    "        model = ClassificationModel(model_checkpoint=data.model_checkpoint,num_labels=data.num_labels)\n",
    "        trainer = Engine(epochs=30,labels=data.labels)\n",
    "        trainer.model = model.model\n",
    "        test_acc, test_f1, eval_acc, eval_f1 = trainer.run(lr=lr,\n",
    "                                                            wd=0.0,\n",
    "                                                            train_dataloader=data.train_dataloader,\n",
    "                                                            eval_dataloader=data.eval_dataloader,\n",
    "                                                            test_dataloader=data.test_dataloader,\n",
    "                                                            # accumulation_steps=32,\n",
    "                                                            early_stop=3)\n",
    "        results['test_acc'].append(test_acc)\n",
    "        results['test_f1'].append(test_f1)\n",
    "        results['eval_acc'].append(eval_acc)\n",
    "        results['eval_f1'].append(eval_f1)\n",
    "        results['lr'].append(lr)\n",
    "        results['model'].append(model_checkpoint)\n",
    "        print('### '*10)\n",
    "        print(results)\n",
    "        print('### '*10)\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        del data, model, trainer\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>eval_acc</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>lr</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.628906</td>\n",
       "      <td>0.562975</td>\n",
       "      <td>0.667396</td>\n",
       "      <td>0.635417</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.647461</td>\n",
       "      <td>0.669584</td>\n",
       "      <td>0.633479</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.621094</td>\n",
       "      <td>0.584376</td>\n",
       "      <td>0.643326</td>\n",
       "      <td>0.631104</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.663670</td>\n",
       "      <td>0.728665</td>\n",
       "      <td>0.711222</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>roberta-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.675537</td>\n",
       "      <td>0.713348</td>\n",
       "      <td>0.706779</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>roberta-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>0.146608</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>roberta-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.512035</td>\n",
       "      <td>0.489460</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.562751</td>\n",
       "      <td>0.586433</td>\n",
       "      <td>0.572095</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.511719</td>\n",
       "      <td>0.474738</td>\n",
       "      <td>0.560175</td>\n",
       "      <td>0.545294</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.574219</td>\n",
       "      <td>0.538595</td>\n",
       "      <td>0.619256</td>\n",
       "      <td>0.610368</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>bigscience/bloom-560m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.543071</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.636557</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>bigscience/bloom-560m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.330135</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.449738</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>bigscience/bloom-560m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.308594</td>\n",
       "      <td>0.226408</td>\n",
       "      <td>0.291028</td>\n",
       "      <td>0.197952</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.195312</td>\n",
       "      <td>0.120572</td>\n",
       "      <td>0.175055</td>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.144531</td>\n",
       "      <td>0.021047</td>\n",
       "      <td>0.146608</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.436510</td>\n",
       "      <td>0.477024</td>\n",
       "      <td>0.442230</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.646781</td>\n",
       "      <td>0.612691</td>\n",
       "      <td>0.611359</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.578593</td>\n",
       "      <td>0.606127</td>\n",
       "      <td>0.616138</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.695312</td>\n",
       "      <td>0.667680</td>\n",
       "      <td>0.684902</td>\n",
       "      <td>0.677780</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.660156</td>\n",
       "      <td>0.629402</td>\n",
       "      <td>0.678337</td>\n",
       "      <td>0.668389</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.628906</td>\n",
       "      <td>0.623045</td>\n",
       "      <td>0.654267</td>\n",
       "      <td>0.642463</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.665013</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>0.746828</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>microsoft/deberta-v2-xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.412082</td>\n",
       "      <td>0.520788</td>\n",
       "      <td>0.393786</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>microsoft/deberta-v2-xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.121094</td>\n",
       "      <td>0.018002</td>\n",
       "      <td>0.122538</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>microsoft/deberta-v2-xlarge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_acc   test_f1  eval_acc   eval_f1       lr  \\\n",
       "0   0.628906  0.562975  0.667396  0.635417  0.00001   \n",
       "1   0.656250  0.647461  0.669584  0.633479  0.00005   \n",
       "2   0.621094  0.584376  0.643326  0.631104  0.00010   \n",
       "3   0.699219  0.663670  0.728665  0.711222  0.00001   \n",
       "4   0.687500  0.675537  0.713348  0.706779  0.00005   \n",
       "5   0.144531  0.021047  0.146608  0.021310  0.00010   \n",
       "6   0.472656  0.424396  0.512035  0.489460  0.00001   \n",
       "7   0.593750  0.562751  0.586433  0.572095  0.00005   \n",
       "8   0.511719  0.474738  0.560175  0.545294  0.00010   \n",
       "9   0.574219  0.538595  0.619256  0.610368  0.00001   \n",
       "10  0.585938  0.543071  0.654267  0.636557  0.00005   \n",
       "11  0.375000  0.330135  0.481400  0.449738  0.00010   \n",
       "12  0.308594  0.226408  0.291028  0.197952  0.00001   \n",
       "13  0.195312  0.120572  0.175055  0.108833  0.00005   \n",
       "14  0.144531  0.021047  0.146608  0.021310  0.00010   \n",
       "15  0.507812  0.436510  0.477024  0.442230  0.00001   \n",
       "16  0.652344  0.646781  0.612691  0.611359  0.00005   \n",
       "17  0.605469  0.578593  0.606127  0.616138  0.00010   \n",
       "18  0.695312  0.667680  0.684902  0.677780  0.00001   \n",
       "19  0.660156  0.629402  0.678337  0.668389  0.00005   \n",
       "20  0.628906  0.623045  0.654267  0.642463  0.00010   \n",
       "21  0.691406  0.665013  0.759300  0.746828  0.00001   \n",
       "22  0.539062  0.412082  0.520788  0.393786  0.00005   \n",
       "23  0.121094  0.018002  0.122538  0.018194  0.00010   \n",
       "\n",
       "                          model  \n",
       "0             bert-base-uncased  \n",
       "1             bert-base-uncased  \n",
       "2             bert-base-uncased  \n",
       "3                 roberta-large  \n",
       "4                 roberta-large  \n",
       "5                 roberta-large  \n",
       "6                          gpt2  \n",
       "7                          gpt2  \n",
       "8                          gpt2  \n",
       "9         bigscience/bloom-560m  \n",
       "10        bigscience/bloom-560m  \n",
       "11        bigscience/bloom-560m  \n",
       "12            facebook/opt-350m  \n",
       "13            facebook/opt-350m  \n",
       "14            facebook/opt-350m  \n",
       "15      EleutherAI/gpt-neo-1.3B  \n",
       "16      EleutherAI/gpt-neo-1.3B  \n",
       "17      EleutherAI/gpt-neo-1.3B  \n",
       "18       microsoft/deberta-base  \n",
       "19       microsoft/deberta-base  \n",
       "20       microsoft/deberta-base  \n",
       "21  microsoft/deberta-v2-xlarge  \n",
       "22  microsoft/deberta-v2-xlarge  \n",
       "23  microsoft/deberta-v2-xlarge  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
