{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/software/'\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.join(os.path.dirname(os.getcwd()), '')\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {'bert-base-uncased':{'lr':5.0e-5, 'wd':0.0},\n",
    "                'roberta-large':{'lr':5.0e-5, 'focalloss':True, 'gamma':8, 'wd':0.0},\n",
    "                'gpt2':{'lr':5.0e-5, 'wd':0.01},\n",
    "                'bigscience/bloom-560m':{'lr':5.0e-5, 'focalloss':True, 'gamma':8, 'wd':0.0},\n",
    "                'facebook/opt-350m':{'lr':1.0e-5, 'wd':0.0},\n",
    "                'EleutherAI/gpt-neo-1.3B':{'lr':5.0e-5, 'wd':0.0}, \n",
    "                'microsoft/deberta-base':{'lr':1.0e-5, 'wd':0.01},\n",
    "                'microsoft/deberta-v2-xlarge':{'lr':1.0e-5, 'focalloss':True, 'gamma':4, 'wd':0.01}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'rank, alpha':[],\n",
    "           'model':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4386\tVal Loss:\t2.3611\tAccuracy:\t0.1554\tF1:\t0.0359 *\n",
      "2 / 30: Train Loss:\t2.3651\tVal Loss:\t2.3339\tAccuracy:\t0.1619\tF1:\t0.0429 *\n",
      "3 / 30: Train Loss:\t2.3422\tVal Loss:\t2.2988\tAccuracy:\t0.1860\tF1:\t0.0723 *\n",
      "4 / 30: Train Loss:\t2.2950\tVal Loss:\t2.2318\tAccuracy:\t0.2276\tF1:\t0.1018 *\n",
      "5 / 30: Train Loss:\t2.2238\tVal Loss:\t2.1524\tAccuracy:\t0.2604\tF1:\t0.1201 *\n",
      "6 / 30: Train Loss:\t2.1352\tVal Loss:\t2.0615\tAccuracy:\t0.2845\tF1:\t0.1507 *\n",
      "7 / 30: Train Loss:\t2.0462\tVal Loss:\t1.9746\tAccuracy:\t0.3129\tF1:\t0.1741 *\n",
      "8 / 30: Train Loss:\t1.9507\tVal Loss:\t1.8959\tAccuracy:\t0.3370\tF1:\t0.1940 *\n",
      "9 / 30: Train Loss:\t1.8689\tVal Loss:\t1.8234\tAccuracy:\t0.3545\tF1:\t0.2184 *\n",
      "10 / 30: Train Loss:\t1.8023\tVal Loss:\t1.7666\tAccuracy:\t0.3851\tF1:\t0.2433 *\n",
      "11 / 30: Train Loss:\t1.7494\tVal Loss:\t1.7254\tAccuracy:\t0.4004\tF1:\t0.2604 *\n",
      "12 / 30: Train Loss:\t1.6952\tVal Loss:\t1.6919\tAccuracy:\t0.4267\tF1:\t0.2891 *\n",
      "13 / 30: Train Loss:\t1.6663\tVal Loss:\t1.6681\tAccuracy:\t0.4354\tF1:\t0.2930 *\n",
      "14 / 30: Train Loss:\t1.6428\tVal Loss:\t1.6444\tAccuracy:\t0.4311\tF1:\t0.2969 *\n",
      "15 / 30: Train Loss:\t1.6052\tVal Loss:\t1.6286\tAccuracy:\t0.4398\tF1:\t0.3058 *\n",
      "16 / 30: Train Loss:\t1.5912\tVal Loss:\t1.6123\tAccuracy:\t0.4464\tF1:\t0.3168 *\n",
      "17 / 30: Train Loss:\t1.5618\tVal Loss:\t1.5937\tAccuracy:\t0.4508\tF1:\t0.3166\n",
      "18 / 30: Train Loss:\t1.5440\tVal Loss:\t1.5803\tAccuracy:\t0.4573\tF1:\t0.3256 *\n",
      "19 / 30: Train Loss:\t1.4970\tVal Loss:\t1.5677\tAccuracy:\t0.4595\tF1:\t0.3286 *\n",
      "20 / 30: Train Loss:\t1.4897\tVal Loss:\t1.5549\tAccuracy:\t0.4705\tF1:\t0.3385 *\n",
      "21 / 30: Train Loss:\t1.4703\tVal Loss:\t1.5411\tAccuracy:\t0.4902\tF1:\t0.3567 *\n",
      "22 / 30: Train Loss:\t1.4459\tVal Loss:\t1.5320\tAccuracy:\t0.4726\tF1:\t0.3440\n",
      "23 / 30: Train Loss:\t1.4073\tVal Loss:\t1.5214\tAccuracy:\t0.4836\tF1:\t0.3548\n",
      "24 / 30: Train Loss:\t1.4039\tVal Loss:\t1.5075\tAccuracy:\t0.4967\tF1:\t0.3682 *\n",
      "25 / 30: Train Loss:\t1.3747\tVal Loss:\t1.5038\tAccuracy:\t0.5011\tF1:\t0.3741 *\n",
      "26 / 30: Train Loss:\t1.3539\tVal Loss:\t1.4984\tAccuracy:\t0.5055\tF1:\t0.3796 *\n",
      "27 / 30: Train Loss:\t1.3416\tVal Loss:\t1.4860\tAccuracy:\t0.5033\tF1:\t0.3781\n",
      "28 / 30: Train Loss:\t1.3077\tVal Loss:\t1.4784\tAccuracy:\t0.5098\tF1:\t0.3834 *\n",
      "29 / 30: Train Loss:\t1.3006\tVal Loss:\t1.4739\tAccuracy:\t0.5120\tF1:\t0.3863 *\n",
      "30 / 30: Train Loss:\t1.2774\tVal Loss:\t1.4671\tAccuracy:\t0.5164\tF1:\t0.3890 *\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.57      0.72      0.64        67\n",
      "               anecdote       0.78      0.74      0.76        43\n",
      "         cherry picking       0.59      0.70      0.64        56\n",
      "      conspiracy theory       0.56      0.46      0.51        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.48      0.59      0.53        37\n",
      "      misrepresentation       0.24      0.16      0.19        38\n",
      "     oversimplification       0.51      0.64      0.57        36\n",
      "           single cause       0.41      0.60      0.49        57\n",
      "     slothful induction       0.40      0.31      0.35        45\n",
      "\n",
      "               accuracy                           0.52       457\n",
      "              macro avg       0.38      0.41      0.39       457\n",
      "           weighted avg       0.47      0.52      0.49       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.64      0.76      0.69        37\n",
      "               anecdote       0.67      0.75      0.71        24\n",
      "         cherry picking       0.35      0.39      0.37        31\n",
      "      conspiracy theory       0.60      0.27      0.37        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.60      0.71      0.65        21\n",
      "      misrepresentation       0.35      0.36      0.36        22\n",
      "     oversimplification       0.50      0.70      0.58        20\n",
      "           single cause       0.42      0.62      0.50        32\n",
      "     slothful induction       0.18      0.12      0.14        25\n",
      "\n",
      "               accuracy                           0.48       256\n",
      "              macro avg       0.36      0.39      0.36       256\n",
      "           weighted avg       0.44      0.48      0.45       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375], 'test_f1': [0.3646159243044012], 'eval_acc': [0.5164113785557987], 'eval_f1': [0.38902208831758595], 'rank, alpha': [8], 'model': ['bert-base-uncased']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bert-base-uncased, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4376\tVal Loss:\t2.3581\tAccuracy:\t0.1554\tF1:\t0.0357 *\n",
      "2 / 30: Train Loss:\t2.3594\tVal Loss:\t2.3196\tAccuracy:\t0.1707\tF1:\t0.0524 *\n",
      "3 / 30: Train Loss:\t2.3158\tVal Loss:\t2.2533\tAccuracy:\t0.2254\tF1:\t0.0935 *\n",
      "4 / 30: Train Loss:\t2.2332\tVal Loss:\t2.1610\tAccuracy:\t0.2560\tF1:\t0.1147 *\n",
      "5 / 30: Train Loss:\t2.1414\tVal Loss:\t2.0686\tAccuracy:\t0.2779\tF1:\t0.1435 *\n",
      "6 / 30: Train Loss:\t2.0354\tVal Loss:\t1.9806\tAccuracy:\t0.3173\tF1:\t0.1778 *\n",
      "7 / 30: Train Loss:\t1.9464\tVal Loss:\t1.8908\tAccuracy:\t0.3567\tF1:\t0.2157 *\n",
      "8 / 30: Train Loss:\t1.8515\tVal Loss:\t1.8104\tAccuracy:\t0.3742\tF1:\t0.2428 *\n",
      "9 / 30: Train Loss:\t1.7724\tVal Loss:\t1.7469\tAccuracy:\t0.3982\tF1:\t0.2645 *\n",
      "10 / 30: Train Loss:\t1.7145\tVal Loss:\t1.7007\tAccuracy:\t0.4114\tF1:\t0.2837 *\n",
      "11 / 30: Train Loss:\t1.6641\tVal Loss:\t1.6616\tAccuracy:\t0.4289\tF1:\t0.3010 *\n",
      "12 / 30: Train Loss:\t1.6072\tVal Loss:\t1.6463\tAccuracy:\t0.4267\tF1:\t0.3069 *\n",
      "13 / 30: Train Loss:\t1.5771\tVal Loss:\t1.6105\tAccuracy:\t0.4398\tF1:\t0.3134 *\n",
      "14 / 30: Train Loss:\t1.5452\tVal Loss:\t1.5906\tAccuracy:\t0.4683\tF1:\t0.3467 *\n",
      "15 / 30: Train Loss:\t1.5108\tVal Loss:\t1.5716\tAccuracy:\t0.4595\tF1:\t0.3358\n",
      "16 / 30: Train Loss:\t1.4844\tVal Loss:\t1.5563\tAccuracy:\t0.4639\tF1:\t0.3402\n",
      "17 / 30: Train Loss:\t1.4492\tVal Loss:\t1.5443\tAccuracy:\t0.4705\tF1:\t0.3502 *\n",
      "18 / 30: Train Loss:\t1.4277\tVal Loss:\t1.5270\tAccuracy:\t0.4792\tF1:\t0.3592 *\n",
      "19 / 30: Train Loss:\t1.3738\tVal Loss:\t1.5183\tAccuracy:\t0.4683\tF1:\t0.3532\n",
      "20 / 30: Train Loss:\t1.3589\tVal Loss:\t1.5104\tAccuracy:\t0.4792\tF1:\t0.3652 *\n",
      "21 / 30: Train Loss:\t1.3358\tVal Loss:\t1.4896\tAccuracy:\t0.4989\tF1:\t0.3802 *\n",
      "22 / 30: Train Loss:\t1.3027\tVal Loss:\t1.4791\tAccuracy:\t0.4989\tF1:\t0.3824 *\n",
      "23 / 30: Train Loss:\t1.2670\tVal Loss:\t1.4857\tAccuracy:\t0.5142\tF1:\t0.3931 *\n",
      "24 / 30: Train Loss:\t1.2626\tVal Loss:\t1.4627\tAccuracy:\t0.5098\tF1:\t0.3925\n",
      "25 / 30: Train Loss:\t1.2254\tVal Loss:\t1.4641\tAccuracy:\t0.5033\tF1:\t0.3909\n",
      "26 / 30: Train Loss:\t1.1948\tVal Loss:\t1.4744\tAccuracy:\t0.5055\tF1:\t0.3924\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.59      0.63      0.61        67\n",
      "               anecdote       0.80      0.74      0.77        43\n",
      "         cherry picking       0.62      0.64      0.63        56\n",
      "      conspiracy theory       0.62      0.54      0.58        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.55      0.57      0.56        37\n",
      "      misrepresentation       0.20      0.13      0.16        38\n",
      "     oversimplification       0.45      0.69      0.54        36\n",
      "           single cause       0.40      0.63      0.49        57\n",
      "     slothful induction       0.39      0.38      0.38        45\n",
      "\n",
      "               accuracy                           0.51       457\n",
      "              macro avg       0.38      0.41      0.39       457\n",
      "           weighted avg       0.47      0.51      0.49       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.72      0.76      0.74        37\n",
      "               anecdote       0.73      0.67      0.70        24\n",
      "         cherry picking       0.33      0.35      0.34        31\n",
      "      conspiracy theory       0.67      0.36      0.47        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.62      0.71      0.67        21\n",
      "      misrepresentation       0.28      0.23      0.25        22\n",
      "     oversimplification       0.44      0.70      0.54        20\n",
      "           single cause       0.43      0.75      0.55        32\n",
      "     slothful induction       0.19      0.12      0.15        25\n",
      "\n",
      "               accuracy                           0.48       256\n",
      "              macro avg       0.37      0.39      0.37       256\n",
      "           weighted avg       0.45      0.48      0.45       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375], 'test_f1': [0.3646159243044012, 0.3661463940389753], 'eval_acc': [0.5164113785557987, 0.5142231947483589], 'eval_f1': [0.38902208831758595, 0.3931182317201232], 'rank, alpha': [8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t15.1312\tVal Loss:\t2.4830\tAccuracy:\t0.0328\tF1:\t0.0189 *\n",
      "2 / 30: Train Loss:\t14.8905\tVal Loss:\t2.4209\tAccuracy:\t0.1466\tF1:\t0.1300 *\n",
      "3 / 30: Train Loss:\t11.8537\tVal Loss:\t1.9710\tAccuracy:\t0.3632\tF1:\t0.3666 *\n",
      "4 / 30: Train Loss:\t7.2394\tVal Loss:\t1.6302\tAccuracy:\t0.5383\tF1:\t0.5128 *\n",
      "5 / 30: Train Loss:\t5.0536\tVal Loss:\t1.4881\tAccuracy:\t0.5864\tF1:\t0.5517 *\n",
      "6 / 30: Train Loss:\t4.0893\tVal Loss:\t1.4126\tAccuracy:\t0.6039\tF1:\t0.5800 *\n",
      "7 / 30: Train Loss:\t3.1532\tVal Loss:\t1.3103\tAccuracy:\t0.6389\tF1:\t0.6077 *\n",
      "8 / 30: Train Loss:\t2.7447\tVal Loss:\t1.3031\tAccuracy:\t0.6411\tF1:\t0.6184 *\n",
      "9 / 30: Train Loss:\t2.3744\tVal Loss:\t1.2422\tAccuracy:\t0.6389\tF1:\t0.6228 *\n",
      "10 / 30: Train Loss:\t2.1588\tVal Loss:\t1.2075\tAccuracy:\t0.6674\tF1:\t0.6523 *\n",
      "11 / 30: Train Loss:\t1.7137\tVal Loss:\t1.1901\tAccuracy:\t0.6608\tF1:\t0.6468\n",
      "12 / 30: Train Loss:\t1.5767\tVal Loss:\t1.1745\tAccuracy:\t0.6696\tF1:\t0.6468\n",
      "13 / 30: Train Loss:\t1.3938\tVal Loss:\t1.1429\tAccuracy:\t0.6761\tF1:\t0.6543 *\n",
      "14 / 30: Train Loss:\t1.2717\tVal Loss:\t1.1188\tAccuracy:\t0.6893\tF1:\t0.6739 *\n",
      "15 / 30: Train Loss:\t1.2287\tVal Loss:\t1.1315\tAccuracy:\t0.6674\tF1:\t0.6437\n",
      "16 / 30: Train Loss:\t1.0888\tVal Loss:\t1.1199\tAccuracy:\t0.6761\tF1:\t0.6562\n",
      "17 / 30: Train Loss:\t1.0072\tVal Loss:\t1.1017\tAccuracy:\t0.6827\tF1:\t0.6664\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.75      0.67      0.71        67\n",
      "               anecdote       0.93      0.86      0.89        43\n",
      "         cherry picking       0.66      0.71      0.68        56\n",
      "      conspiracy theory       0.71      0.87      0.78        39\n",
      "           fake experts       0.69      0.75      0.72        12\n",
      "           false choice       0.71      0.77      0.74        13\n",
      "      false equivalence       0.33      0.36      0.34        14\n",
      "impossible expectations       0.65      0.59      0.62        37\n",
      "      misrepresentation       0.66      0.55      0.60        38\n",
      "     oversimplification       0.79      0.61      0.69        36\n",
      "           single cause       0.74      0.60      0.66        57\n",
      "     slothful induction       0.55      0.80      0.65        45\n",
      "\n",
      "               accuracy                           0.69       457\n",
      "              macro avg       0.68      0.68      0.67       457\n",
      "           weighted avg       0.70      0.69      0.69       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.78      0.76      0.77        37\n",
      "               anecdote       0.78      0.88      0.82        24\n",
      "         cherry picking       0.52      0.42      0.46        31\n",
      "      conspiracy theory       0.74      0.77      0.76        22\n",
      "           fake experts       0.80      0.57      0.67         7\n",
      "           false choice       0.50      0.57      0.53         7\n",
      "      false equivalence       0.40      0.25      0.31         8\n",
      "impossible expectations       0.65      0.71      0.68        21\n",
      "      misrepresentation       0.57      0.59      0.58        22\n",
      "     oversimplification       0.50      0.65      0.57        20\n",
      "           single cause       0.78      0.66      0.71        32\n",
      "     slothful induction       0.36      0.40      0.38        25\n",
      "\n",
      "               accuracy                           0.63       256\n",
      "              macro avg       0.61      0.60      0.60       256\n",
      "           weighted avg       0.63      0.63      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565], 'rank, alpha': [8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search roberta-large, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t15.1407\tVal Loss:\t2.4814\tAccuracy:\t0.0350\tF1:\t0.0216 *\n",
      "2 / 30: Train Loss:\t14.6096\tVal Loss:\t2.3184\tAccuracy:\t0.2123\tF1:\t0.2138 *\n",
      "3 / 30: Train Loss:\t9.2426\tVal Loss:\t1.7867\tAccuracy:\t0.4245\tF1:\t0.4337 *\n",
      "4 / 30: Train Loss:\t5.7763\tVal Loss:\t1.5317\tAccuracy:\t0.5996\tF1:\t0.5677 *\n",
      "5 / 30: Train Loss:\t4.2387\tVal Loss:\t1.4097\tAccuracy:\t0.6105\tF1:\t0.5866 *\n",
      "6 / 30: Train Loss:\t3.4006\tVal Loss:\t1.3518\tAccuracy:\t0.6236\tF1:\t0.6006 *\n",
      "7 / 30: Train Loss:\t2.6459\tVal Loss:\t1.2700\tAccuracy:\t0.6565\tF1:\t0.6336 *\n",
      "8 / 30: Train Loss:\t2.3657\tVal Loss:\t1.2621\tAccuracy:\t0.6586\tF1:\t0.6431 *\n",
      "9 / 30: Train Loss:\t2.0616\tVal Loss:\t1.2102\tAccuracy:\t0.6433\tF1:\t0.6290\n",
      "10 / 30: Train Loss:\t1.8194\tVal Loss:\t1.1851\tAccuracy:\t0.6630\tF1:\t0.6470 *\n",
      "11 / 30: Train Loss:\t1.4660\tVal Loss:\t1.1528\tAccuracy:\t0.6718\tF1:\t0.6571 *\n",
      "12 / 30: Train Loss:\t1.3156\tVal Loss:\t1.1371\tAccuracy:\t0.6718\tF1:\t0.6459\n",
      "13 / 30: Train Loss:\t1.1863\tVal Loss:\t1.1277\tAccuracy:\t0.6718\tF1:\t0.6452\n",
      "14 / 30: Train Loss:\t1.1140\tVal Loss:\t1.1152\tAccuracy:\t0.6783\tF1:\t0.6659 *\n",
      "15 / 30: Train Loss:\t1.1359\tVal Loss:\t1.1194\tAccuracy:\t0.6608\tF1:\t0.6432\n",
      "16 / 30: Train Loss:\t0.9463\tVal Loss:\t1.1044\tAccuracy:\t0.6761\tF1:\t0.6603\n",
      "17 / 30: Train Loss:\t0.8650\tVal Loss:\t1.0864\tAccuracy:\t0.6827\tF1:\t0.6718 *\n",
      "18 / 30: Train Loss:\t0.7795\tVal Loss:\t1.0868\tAccuracy:\t0.6740\tF1:\t0.6589\n",
      "19 / 30: Train Loss:\t0.6926\tVal Loss:\t1.0638\tAccuracy:\t0.6805\tF1:\t0.6641\n",
      "20 / 30: Train Loss:\t0.7064\tVal Loss:\t1.0812\tAccuracy:\t0.6805\tF1:\t0.6688\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.73      0.66      0.69        67\n",
      "               anecdote       0.90      0.84      0.87        43\n",
      "         cherry picking       0.65      0.66      0.65        56\n",
      "      conspiracy theory       0.76      0.87      0.81        39\n",
      "           fake experts       0.71      0.83      0.77        12\n",
      "           false choice       0.59      0.77      0.67        13\n",
      "      false equivalence       0.29      0.43      0.34        14\n",
      "impossible expectations       0.73      0.59      0.66        37\n",
      "      misrepresentation       0.63      0.63      0.63        38\n",
      "     oversimplification       0.74      0.64      0.69        36\n",
      "           single cause       0.67      0.56      0.61        57\n",
      "     slothful induction       0.61      0.76      0.67        45\n",
      "\n",
      "               accuracy                           0.68       457\n",
      "              macro avg       0.67      0.69      0.67       457\n",
      "           weighted avg       0.69      0.68      0.68       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.82      0.73      0.77        37\n",
      "               anecdote       0.84      0.88      0.86        24\n",
      "         cherry picking       0.68      0.55      0.61        31\n",
      "      conspiracy theory       0.72      0.82      0.77        22\n",
      "           fake experts       1.00      0.57      0.73         7\n",
      "           false choice       0.40      0.57      0.47         7\n",
      "      false equivalence       0.30      0.38      0.33         8\n",
      "impossible expectations       0.70      0.67      0.68        21\n",
      "      misrepresentation       0.58      0.68      0.62        22\n",
      "     oversimplification       0.57      0.85      0.68        20\n",
      "           single cause       0.79      0.72      0.75        32\n",
      "     slothful induction       0.42      0.32      0.36        25\n",
      "\n",
      "               accuracy                           0.67       256\n",
      "              macro avg       0.65      0.64      0.64       256\n",
      "           weighted avg       0.68      0.67      0.67       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715], 'rank, alpha': [8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mnt/software/miniconda3/lib/python3.11/site-packages/peft/tuners/lora/model.py:311: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t5.4689\tVal Loss:\t3.6016\tAccuracy:\t0.1028\tF1:\t0.0501 *\n",
      "2 / 30: Train Loss:\t3.2795\tVal Loss:\t3.0685\tAccuracy:\t0.1116\tF1:\t0.0579 *\n",
      "3 / 30: Train Loss:\t2.8956\tVal Loss:\t2.8149\tAccuracy:\t0.1204\tF1:\t0.0629 *\n",
      "4 / 30: Train Loss:\t2.7121\tVal Loss:\t2.6848\tAccuracy:\t0.1357\tF1:\t0.0729 *\n",
      "5 / 30: Train Loss:\t2.6753\tVal Loss:\t2.6046\tAccuracy:\t0.1335\tF1:\t0.0763 *\n",
      "6 / 30: Train Loss:\t2.6194\tVal Loss:\t2.5411\tAccuracy:\t0.1422\tF1:\t0.0854 *\n",
      "7 / 30: Train Loss:\t2.5153\tVal Loss:\t2.4992\tAccuracy:\t0.1444\tF1:\t0.0866 *\n",
      "8 / 30: Train Loss:\t2.4712\tVal Loss:\t2.4763\tAccuracy:\t0.1554\tF1:\t0.0934 *\n",
      "9 / 30: Train Loss:\t2.4511\tVal Loss:\t2.4519\tAccuracy:\t0.1641\tF1:\t0.0995 *\n",
      "10 / 30: Train Loss:\t2.4300\tVal Loss:\t2.4301\tAccuracy:\t0.1729\tF1:\t0.1057 *\n",
      "11 / 30: Train Loss:\t2.4037\tVal Loss:\t2.4111\tAccuracy:\t0.1838\tF1:\t0.1112 *\n",
      "12 / 30: Train Loss:\t2.4065\tVal Loss:\t2.3996\tAccuracy:\t0.1772\tF1:\t0.1052\n",
      "13 / 30: Train Loss:\t2.3741\tVal Loss:\t2.3851\tAccuracy:\t0.1751\tF1:\t0.1044\n",
      "14 / 30: Train Loss:\t2.3713\tVal Loss:\t2.3717\tAccuracy:\t0.1816\tF1:\t0.1080\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.23      0.33      0.27        67\n",
      "               anecdote       0.35      0.16      0.22        43\n",
      "         cherry picking       0.20      0.43      0.27        56\n",
      "      conspiracy theory       0.14      0.15      0.15        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.13      0.30      0.18        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.18      0.23      0.20        57\n",
      "     slothful induction       0.07      0.02      0.03        45\n",
      "\n",
      "               accuracy                           0.18       457\n",
      "              macro avg       0.11      0.14      0.11       457\n",
      "           weighted avg       0.14      0.18      0.15       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.22      0.38      0.28        37\n",
      "               anecdote       0.50      0.12      0.20        24\n",
      "         cherry picking       0.22      0.45      0.29        31\n",
      "      conspiracy theory       0.04      0.05      0.04        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.16      0.33      0.22        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.14      0.19      0.16        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.18       256\n",
      "              macro avg       0.11      0.13      0.10       256\n",
      "           weighted avg       0.14      0.18      0.14       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533], 'rank, alpha': [8, 16, 8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search gpt2, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/mnt/software/miniconda3/lib/python3.11/site-packages/peft/tuners/lora/model.py:311: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t5.0242\tVal Loss:\t3.4205\tAccuracy:\t0.1028\tF1:\t0.0459 *\n",
      "2 / 30: Train Loss:\t3.0267\tVal Loss:\t2.8438\tAccuracy:\t0.1291\tF1:\t0.0675 *\n",
      "3 / 30: Train Loss:\t2.7676\tVal Loss:\t2.6795\tAccuracy:\t0.1357\tF1:\t0.0767 *\n",
      "4 / 30: Train Loss:\t2.6261\tVal Loss:\t2.5840\tAccuracy:\t0.1400\tF1:\t0.0847 *\n",
      "5 / 30: Train Loss:\t2.5984\tVal Loss:\t2.5267\tAccuracy:\t0.1488\tF1:\t0.0915 *\n",
      "6 / 30: Train Loss:\t2.5451\tVal Loss:\t2.4769\tAccuracy:\t0.1554\tF1:\t0.0968 *\n",
      "7 / 30: Train Loss:\t2.4658\tVal Loss:\t2.4495\tAccuracy:\t0.1575\tF1:\t0.0978 *\n",
      "8 / 30: Train Loss:\t2.4342\tVal Loss:\t2.4358\tAccuracy:\t0.1532\tF1:\t0.0925\n",
      "9 / 30: Train Loss:\t2.4172\tVal Loss:\t2.4173\tAccuracy:\t0.1685\tF1:\t0.1008 *\n",
      "10 / 30: Train Loss:\t2.4016\tVal Loss:\t2.4024\tAccuracy:\t0.1707\tF1:\t0.1010 *\n",
      "11 / 30: Train Loss:\t2.3854\tVal Loss:\t2.3838\tAccuracy:\t0.1707\tF1:\t0.0981\n",
      "12 / 30: Train Loss:\t2.3811\tVal Loss:\t2.3801\tAccuracy:\t0.1751\tF1:\t0.1010\n",
      "13 / 30: Train Loss:\t2.3583\tVal Loss:\t2.3676\tAccuracy:\t0.1838\tF1:\t0.1071 *\n",
      "14 / 30: Train Loss:\t2.3560\tVal Loss:\t2.3549\tAccuracy:\t0.1904\tF1:\t0.1102 *\n",
      "15 / 30: Train Loss:\t2.3340\tVal Loss:\t2.3385\tAccuracy:\t0.2013\tF1:\t0.1133 *\n",
      "16 / 30: Train Loss:\t2.3123\tVal Loss:\t2.3361\tAccuracy:\t0.2101\tF1:\t0.1264 *\n",
      "17 / 30: Train Loss:\t2.3286\tVal Loss:\t2.3239\tAccuracy:\t0.2166\tF1:\t0.1326 *\n",
      "18 / 30: Train Loss:\t2.3031\tVal Loss:\t2.3094\tAccuracy:\t0.2276\tF1:\t0.1403 *\n",
      "19 / 30: Train Loss:\t2.2970\tVal Loss:\t2.2967\tAccuracy:\t0.2473\tF1:\t0.1545 *\n",
      "20 / 30: Train Loss:\t2.2956\tVal Loss:\t2.2802\tAccuracy:\t0.2560\tF1:\t0.1696 *\n",
      "21 / 30: Train Loss:\t2.2532\tVal Loss:\t2.2565\tAccuracy:\t0.2604\tF1:\t0.1760 *\n",
      "22 / 30: Train Loss:\t2.2333\tVal Loss:\t2.2286\tAccuracy:\t0.2626\tF1:\t0.1823 *\n",
      "23 / 30: Train Loss:\t2.1883\tVal Loss:\t2.1950\tAccuracy:\t0.2757\tF1:\t0.1966 *\n",
      "24 / 30: Train Loss:\t2.1611\tVal Loss:\t2.1447\tAccuracy:\t0.2998\tF1:\t0.2198 *\n",
      "25 / 30: Train Loss:\t2.1072\tVal Loss:\t2.1006\tAccuracy:\t0.3042\tF1:\t0.2196\n",
      "26 / 30: Train Loss:\t2.0441\tVal Loss:\t2.0511\tAccuracy:\t0.3173\tF1:\t0.2348 *\n",
      "27 / 30: Train Loss:\t1.9746\tVal Loss:\t1.9864\tAccuracy:\t0.3479\tF1:\t0.2544 *\n",
      "28 / 30: Train Loss:\t1.9269\tVal Loss:\t1.9217\tAccuracy:\t0.3807\tF1:\t0.2926 *\n",
      "29 / 30: Train Loss:\t1.8529\tVal Loss:\t1.8657\tAccuracy:\t0.3939\tF1:\t0.3035 *\n",
      "30 / 30: Train Loss:\t1.8037\tVal Loss:\t1.8004\tAccuracy:\t0.4114\tF1:\t0.3268 *\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.43      0.61      0.50        67\n",
      "               anecdote       0.55      0.49      0.52        43\n",
      "         cherry picking       0.40      0.36      0.38        56\n",
      "      conspiracy theory       0.46      0.33      0.39        39\n",
      "           fake experts       0.13      0.33      0.19        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.33      0.46      0.39        37\n",
      "      misrepresentation       0.41      0.18      0.25        38\n",
      "     oversimplification       0.69      0.56      0.62        36\n",
      "           single cause       0.38      0.68      0.49        57\n",
      "     slothful induction       0.40      0.13      0.20        45\n",
      "\n",
      "               accuracy                           0.41       457\n",
      "              macro avg       0.35      0.35      0.33       457\n",
      "           weighted avg       0.41      0.41      0.39       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.48      0.59      0.53        37\n",
      "               anecdote       0.54      0.58      0.56        24\n",
      "         cherry picking       0.26      0.19      0.22        31\n",
      "      conspiracy theory       0.62      0.36      0.46        22\n",
      "           fake experts       0.09      0.14      0.11         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.44      0.67      0.53        21\n",
      "      misrepresentation       0.33      0.23      0.27        22\n",
      "     oversimplification       0.45      0.50      0.48        20\n",
      "           single cause       0.31      0.56      0.40        32\n",
      "     slothful induction       0.10      0.04      0.06        25\n",
      "\n",
      "               accuracy                           0.39       256\n",
      "              macro avg       0.30      0.32      0.30       256\n",
      "           weighted avg       0.36      0.39      0.36       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973], 'rank, alpha': [8, 16, 8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t430.4662\tVal Loss:\t20.9324\tAccuracy:\t0.1116\tF1:\t0.0667 *\n",
      "2 / 30: Train Loss:\t139.4984\tVal Loss:\t6.1853\tAccuracy:\t0.1444\tF1:\t0.1254 *\n",
      "3 / 30: Train Loss:\t40.1736\tVal Loss:\t3.4558\tAccuracy:\t0.2057\tF1:\t0.2028 *\n",
      "4 / 30: Train Loss:\t24.2939\tVal Loss:\t2.8245\tAccuracy:\t0.2429\tF1:\t0.2354 *\n",
      "5 / 30: Train Loss:\t18.1128\tVal Loss:\t2.5375\tAccuracy:\t0.2582\tF1:\t0.2472 *\n",
      "6 / 30: Train Loss:\t14.6536\tVal Loss:\t2.3664\tAccuracy:\t0.2735\tF1:\t0.2714 *\n",
      "7 / 30: Train Loss:\t12.4245\tVal Loss:\t2.2279\tAccuracy:\t0.3042\tF1:\t0.3075 *\n",
      "8 / 30: Train Loss:\t10.5713\tVal Loss:\t2.1261\tAccuracy:\t0.3304\tF1:\t0.3419 *\n",
      "9 / 30: Train Loss:\t9.1347\tVal Loss:\t2.0580\tAccuracy:\t0.3523\tF1:\t0.3621 *\n",
      "10 / 30: Train Loss:\t8.0718\tVal Loss:\t1.9931\tAccuracy:\t0.3501\tF1:\t0.3615\n",
      "11 / 30: Train Loss:\t7.0161\tVal Loss:\t1.9399\tAccuracy:\t0.3589\tF1:\t0.3709 *\n",
      "12 / 30: Train Loss:\t6.2128\tVal Loss:\t1.8907\tAccuracy:\t0.3829\tF1:\t0.4058 *\n",
      "13 / 30: Train Loss:\t5.4675\tVal Loss:\t1.8419\tAccuracy:\t0.3807\tF1:\t0.3968\n",
      "14 / 30: Train Loss:\t4.8343\tVal Loss:\t1.7944\tAccuracy:\t0.4114\tF1:\t0.4234 *\n",
      "15 / 30: Train Loss:\t4.2775\tVal Loss:\t1.7303\tAccuracy:\t0.4179\tF1:\t0.4318 *\n",
      "16 / 30: Train Loss:\t3.7673\tVal Loss:\t1.6807\tAccuracy:\t0.4420\tF1:\t0.4533 *\n",
      "17 / 30: Train Loss:\t3.3042\tVal Loss:\t1.6409\tAccuracy:\t0.4508\tF1:\t0.4609 *\n",
      "18 / 30: Train Loss:\t2.8926\tVal Loss:\t1.6096\tAccuracy:\t0.4551\tF1:\t0.4625 *\n",
      "19 / 30: Train Loss:\t2.5285\tVal Loss:\t1.5923\tAccuracy:\t0.4792\tF1:\t0.4875 *\n",
      "20 / 30: Train Loss:\t2.2091\tVal Loss:\t1.5859\tAccuracy:\t0.4770\tF1:\t0.4794\n",
      "21 / 30: Train Loss:\t1.9265\tVal Loss:\t1.5915\tAccuracy:\t0.4836\tF1:\t0.4775\n",
      "22 / 30: Train Loss:\t1.6731\tVal Loss:\t1.6186\tAccuracy:\t0.4945\tF1:\t0.4812\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.48      0.45      0.47        67\n",
      "               anecdote       0.82      0.63      0.71        43\n",
      "         cherry picking       0.48      0.43      0.45        56\n",
      "      conspiracy theory       0.59      0.44      0.50        39\n",
      "           fake experts       0.83      0.83      0.83        12\n",
      "           false choice       0.38      0.23      0.29        13\n",
      "      false equivalence       0.29      0.43      0.34        14\n",
      "impossible expectations       0.36      0.49      0.41        37\n",
      "      misrepresentation       0.27      0.63      0.38        38\n",
      "     oversimplification       0.71      0.47      0.57        36\n",
      "           single cause       0.61      0.54      0.57        57\n",
      "     slothful induction       0.41      0.27      0.32        45\n",
      "\n",
      "               accuracy                           0.48       457\n",
      "              macro avg       0.52      0.49      0.49       457\n",
      "           weighted avg       0.52      0.48      0.49       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.47      0.49      0.48        37\n",
      "               anecdote       0.81      0.71      0.76        24\n",
      "         cherry picking       0.47      0.48      0.48        31\n",
      "      conspiracy theory       0.70      0.32      0.44        22\n",
      "           fake experts       0.67      0.57      0.62         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.25      0.38      0.30         8\n",
      "impossible expectations       0.52      0.71      0.60        21\n",
      "      misrepresentation       0.28      0.59      0.38        22\n",
      "     oversimplification       0.65      0.55      0.59        20\n",
      "           single cause       0.33      0.22      0.26        32\n",
      "     slothful induction       0.39      0.28      0.33        25\n",
      "\n",
      "               accuracy                           0.46       256\n",
      "              macro avg       0.46      0.44      0.44       256\n",
      "           weighted avg       0.48      0.46      0.46       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t413.8233\tVal Loss:\t19.3123\tAccuracy:\t0.1007\tF1:\t0.0578 *\n",
      "2 / 30: Train Loss:\t117.1577\tVal Loss:\t4.8379\tAccuracy:\t0.1772\tF1:\t0.1591 *\n",
      "3 / 30: Train Loss:\t30.0735\tVal Loss:\t2.9307\tAccuracy:\t0.2276\tF1:\t0.2075 *\n",
      "4 / 30: Train Loss:\t18.6807\tVal Loss:\t2.5502\tAccuracy:\t0.2495\tF1:\t0.2307 *\n",
      "5 / 30: Train Loss:\t14.1748\tVal Loss:\t2.3226\tAccuracy:\t0.2779\tF1:\t0.2714 *\n",
      "6 / 30: Train Loss:\t11.4957\tVal Loss:\t2.1631\tAccuracy:\t0.3129\tF1:\t0.3057 *\n",
      "7 / 30: Train Loss:\t9.5099\tVal Loss:\t2.0695\tAccuracy:\t0.3217\tF1:\t0.3300 *\n",
      "8 / 30: Train Loss:\t8.0628\tVal Loss:\t2.0139\tAccuracy:\t0.3326\tF1:\t0.3450 *\n",
      "9 / 30: Train Loss:\t6.9235\tVal Loss:\t1.9767\tAccuracy:\t0.3589\tF1:\t0.3759 *\n",
      "10 / 30: Train Loss:\t5.9599\tVal Loss:\t1.9407\tAccuracy:\t0.3698\tF1:\t0.3927 *\n",
      "11 / 30: Train Loss:\t5.2617\tVal Loss:\t1.9044\tAccuracy:\t0.3764\tF1:\t0.3895\n",
      "12 / 30: Train Loss:\t4.5082\tVal Loss:\t1.8330\tAccuracy:\t0.3895\tF1:\t0.4029 *\n",
      "13 / 30: Train Loss:\t3.7308\tVal Loss:\t1.7574\tAccuracy:\t0.4070\tF1:\t0.4189 *\n",
      "14 / 30: Train Loss:\t3.1319\tVal Loss:\t1.6843\tAccuracy:\t0.4289\tF1:\t0.4383 *\n",
      "15 / 30: Train Loss:\t2.6616\tVal Loss:\t1.6321\tAccuracy:\t0.4508\tF1:\t0.4667 *\n",
      "16 / 30: Train Loss:\t2.2562\tVal Loss:\t1.6077\tAccuracy:\t0.4573\tF1:\t0.4749 *\n",
      "17 / 30: Train Loss:\t1.9851\tVal Loss:\t1.5694\tAccuracy:\t0.4792\tF1:\t0.4835 *\n",
      "18 / 30: Train Loss:\t1.7291\tVal Loss:\t1.5375\tAccuracy:\t0.5077\tF1:\t0.5146 *\n",
      "19 / 30: Train Loss:\t1.4252\tVal Loss:\t1.5489\tAccuracy:\t0.5142\tF1:\t0.5092\n",
      "20 / 30: Train Loss:\t1.2255\tVal Loss:\t1.6174\tAccuracy:\t0.5033\tF1:\t0.4890\n",
      "21 / 30: Train Loss:\t1.1189\tVal Loss:\t1.7569\tAccuracy:\t0.4880\tF1:\t0.4754\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.58      0.43      0.50        67\n",
      "               anecdote       0.71      0.70      0.71        43\n",
      "         cherry picking       0.53      0.41      0.46        56\n",
      "      conspiracy theory       0.54      0.51      0.53        39\n",
      "           fake experts       0.69      0.75      0.72        12\n",
      "           false choice       1.00      0.31      0.47        13\n",
      "      false equivalence       0.32      0.43      0.36        14\n",
      "impossible expectations       0.35      0.57      0.43        37\n",
      "      misrepresentation       0.33      0.58      0.42        38\n",
      "     oversimplification       0.65      0.61      0.63        36\n",
      "           single cause       0.62      0.53      0.57        57\n",
      "     slothful induction       0.39      0.36      0.37        45\n",
      "\n",
      "               accuracy                           0.51       457\n",
      "              macro avg       0.56      0.51      0.51       457\n",
      "           weighted avg       0.54      0.51      0.51       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.58      0.41      0.48        37\n",
      "               anecdote       0.79      0.79      0.79        24\n",
      "         cherry picking       0.55      0.35      0.43        31\n",
      "      conspiracy theory       0.59      0.45      0.51        22\n",
      "           fake experts       0.67      0.57      0.62         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.20      0.38      0.26         8\n",
      "impossible expectations       0.42      0.81      0.56        21\n",
      "      misrepresentation       0.26      0.41      0.32        22\n",
      "     oversimplification       0.54      0.70      0.61        20\n",
      "           single cause       0.44      0.34      0.39        32\n",
      "     slothful induction       0.32      0.28      0.30        25\n",
      "\n",
      "               accuracy                           0.47       256\n",
      "              macro avg       0.45      0.46      0.44       256\n",
      "           weighted avg       0.48      0.47      0.46       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t3.2485\tVal Loss:\t2.9195\tAccuracy:\t0.1050\tF1:\t0.0545 *\n",
      "2 / 30: Train Loss:\t2.6512\tVal Loss:\t2.5914\tAccuracy:\t0.1379\tF1:\t0.0620 *\n",
      "3 / 30: Train Loss:\t2.5340\tVal Loss:\t2.5324\tAccuracy:\t0.1357\tF1:\t0.0671 *\n",
      "4 / 30: Train Loss:\t2.4906\tVal Loss:\t2.5009\tAccuracy:\t0.1379\tF1:\t0.0730 *\n",
      "5 / 30: Train Loss:\t2.4638\tVal Loss:\t2.4754\tAccuracy:\t0.1466\tF1:\t0.0840 *\n",
      "6 / 30: Train Loss:\t2.4356\tVal Loss:\t2.4528\tAccuracy:\t0.1313\tF1:\t0.0762\n",
      "7 / 30: Train Loss:\t2.4317\tVal Loss:\t2.4359\tAccuracy:\t0.1291\tF1:\t0.0740\n",
      "8 / 30: Train Loss:\t2.4080\tVal Loss:\t2.4185\tAccuracy:\t0.1225\tF1:\t0.0688\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.17      0.48      0.25        67\n",
      "               anecdote       0.06      0.07      0.06        43\n",
      "         cherry picking       0.16      0.23      0.19        56\n",
      "      conspiracy theory       0.50      0.05      0.09        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.11      0.03      0.04        37\n",
      "      misrepresentation       0.12      0.03      0.04        38\n",
      "     oversimplification       0.04      0.03      0.03        36\n",
      "           single cause       0.28      0.21      0.24        57\n",
      "     slothful induction       0.06      0.04      0.05        45\n",
      "\n",
      "               accuracy                           0.15       457\n",
      "              macro avg       0.13      0.10      0.08       457\n",
      "           weighted avg       0.16      0.15      0.12       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.19      0.59      0.29        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.12      0.19      0.15        31\n",
      "      conspiracy theory       0.50      0.05      0.08        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.33      0.05      0.08        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.12      0.09      0.11        32\n",
      "     slothful induction       0.17      0.12      0.14        25\n",
      "\n",
      "               accuracy                           0.14       256\n",
      "              macro avg       0.12      0.09      0.07       256\n",
      "           weighted avg       0.14      0.14      0.10       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search facebook/opt-350m, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-350m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t3.1162\tVal Loss:\t2.7311\tAccuracy:\t0.1094\tF1:\t0.0567 *\n",
      "2 / 30: Train Loss:\t2.5637\tVal Loss:\t2.5549\tAccuracy:\t0.1357\tF1:\t0.0655 *\n",
      "3 / 30: Train Loss:\t2.5094\tVal Loss:\t2.5164\tAccuracy:\t0.1247\tF1:\t0.0648\n",
      "4 / 30: Train Loss:\t2.4706\tVal Loss:\t2.4868\tAccuracy:\t0.1291\tF1:\t0.0789 *\n",
      "5 / 30: Train Loss:\t2.4491\tVal Loss:\t2.4568\tAccuracy:\t0.1182\tF1:\t0.0721\n",
      "6 / 30: Train Loss:\t2.4113\tVal Loss:\t2.4284\tAccuracy:\t0.1182\tF1:\t0.0668\n",
      "7 / 30: Train Loss:\t2.4084\tVal Loss:\t2.4092\tAccuracy:\t0.1335\tF1:\t0.0780\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.15      0.42      0.22        67\n",
      "               anecdote       0.06      0.07      0.06        43\n",
      "         cherry picking       0.13      0.18      0.15        56\n",
      "      conspiracy theory       0.50      0.05      0.09        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.18      0.05      0.08        37\n",
      "      misrepresentation       0.11      0.03      0.04        38\n",
      "     oversimplification       0.03      0.03      0.03        36\n",
      "           single cause       0.24      0.16      0.19        57\n",
      "     slothful induction       0.08      0.07      0.07        45\n",
      "\n",
      "               accuracy                           0.13       457\n",
      "              macro avg       0.12      0.09      0.08       457\n",
      "           weighted avg       0.15      0.13      0.11       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.21      0.62      0.31        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.09      0.16      0.11        31\n",
      "      conspiracy theory       1.00      0.05      0.09        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.33      0.05      0.08        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.14      0.09      0.11        32\n",
      "     slothful induction       0.10      0.08      0.09        25\n",
      "\n",
      "               accuracy                           0.14       256\n",
      "              macro avg       0.16      0.09      0.07       256\n",
      "           weighted avg       0.18      0.14      0.10       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t3.0822\tVal Loss:\t2.7442\tAccuracy:\t0.1269\tF1:\t0.0902 *\n",
      "2 / 30: Train Loss:\t2.5431\tVal Loss:\t2.4945\tAccuracy:\t0.1751\tF1:\t0.1308 *\n",
      "3 / 30: Train Loss:\t2.2355\tVal Loss:\t2.2893\tAccuracy:\t0.2429\tF1:\t0.1873 *\n",
      "4 / 30: Train Loss:\t1.9664\tVal Loss:\t2.1344\tAccuracy:\t0.2932\tF1:\t0.2359 *\n",
      "5 / 30: Train Loss:\t1.7230\tVal Loss:\t2.0176\tAccuracy:\t0.3239\tF1:\t0.2628 *\n",
      "6 / 30: Train Loss:\t1.4887\tVal Loss:\t1.9396\tAccuracy:\t0.3501\tF1:\t0.2855 *\n",
      "7 / 30: Train Loss:\t1.2550\tVal Loss:\t1.9004\tAccuracy:\t0.3742\tF1:\t0.3239 *\n",
      "8 / 30: Train Loss:\t1.0152\tVal Loss:\t1.9086\tAccuracy:\t0.4004\tF1:\t0.3511 *\n",
      "9 / 30: Train Loss:\t0.7838\tVal Loss:\t1.9387\tAccuracy:\t0.4092\tF1:\t0.3627 *\n",
      "10 / 30: Train Loss:\t0.5639\tVal Loss:\t1.9781\tAccuracy:\t0.4048\tF1:\t0.3636 *\n",
      "11 / 30: Train Loss:\t0.3850\tVal Loss:\t2.0031\tAccuracy:\t0.4026\tF1:\t0.3602\n",
      "12 / 30: Train Loss:\t0.2544\tVal Loss:\t2.0253\tAccuracy:\t0.4114\tF1:\t0.3691 *\n",
      "13 / 30: Train Loss:\t0.1700\tVal Loss:\t2.0366\tAccuracy:\t0.4092\tF1:\t0.3669\n",
      "14 / 30: Train Loss:\t0.1193\tVal Loss:\t2.0484\tAccuracy:\t0.4311\tF1:\t0.3833 *\n",
      "15 / 30: Train Loss:\t0.0890\tVal Loss:\t2.0621\tAccuracy:\t0.4267\tF1:\t0.3860 *\n",
      "16 / 30: Train Loss:\t0.0681\tVal Loss:\t2.0550\tAccuracy:\t0.4420\tF1:\t0.3899 *\n",
      "17 / 30: Train Loss:\t0.0529\tVal Loss:\t2.0555\tAccuracy:\t0.4354\tF1:\t0.3833\n",
      "18 / 30: Train Loss:\t0.0420\tVal Loss:\t2.0576\tAccuracy:\t0.4442\tF1:\t0.3893\n",
      "19 / 30: Train Loss:\t0.0345\tVal Loss:\t2.0574\tAccuracy:\t0.4464\tF1:\t0.3976 *\n",
      "20 / 30: Train Loss:\t0.0307\tVal Loss:\t2.0641\tAccuracy:\t0.4376\tF1:\t0.3937\n",
      "21 / 30: Train Loss:\t0.0251\tVal Loss:\t2.0713\tAccuracy:\t0.4354\tF1:\t0.3888\n",
      "22 / 30: Train Loss:\t0.0217\tVal Loss:\t2.0784\tAccuracy:\t0.4354\tF1:\t0.3897\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.44      0.55      0.49        67\n",
      "               anecdote       0.69      0.56      0.62        43\n",
      "         cherry picking       0.45      0.48      0.47        56\n",
      "      conspiracy theory       0.57      0.64      0.60        39\n",
      "           fake experts       0.29      0.17      0.21        12\n",
      "           false choice       0.29      0.15      0.20        13\n",
      "      false equivalence       0.08      0.07      0.07        14\n",
      "impossible expectations       0.48      0.35      0.41        37\n",
      "      misrepresentation       0.35      0.47      0.40        38\n",
      "     oversimplification       0.87      0.56      0.68        36\n",
      "           single cause       0.40      0.47      0.43        57\n",
      "     slothful induction       0.21      0.18      0.19        45\n",
      "\n",
      "               accuracy                           0.45       457\n",
      "              macro avg       0.43      0.39      0.40       457\n",
      "           weighted avg       0.46      0.45      0.44       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.40      0.46      0.42        37\n",
      "               anecdote       0.74      0.71      0.72        24\n",
      "         cherry picking       0.44      0.39      0.41        31\n",
      "      conspiracy theory       0.50      0.45      0.48        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.20      0.14      0.17         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.33      0.24      0.28        21\n",
      "      misrepresentation       0.35      0.36      0.36        22\n",
      "     oversimplification       0.56      0.45      0.50        20\n",
      "           single cause       0.40      0.56      0.47        32\n",
      "     slothful induction       0.17      0.24      0.20        25\n",
      "\n",
      "               accuracy                           0.40       256\n",
      "              macro avg       0.34      0.33      0.33       256\n",
      "           weighted avg       0.40      0.40      0.40       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875, 0.40234375], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861, 0.33382669187419745], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967, 0.44638949671772427], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029, 0.3976216398668326], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t3.0576\tVal Loss:\t2.7264\tAccuracy:\t0.1269\tF1:\t0.0907 *\n",
      "2 / 30: Train Loss:\t2.4906\tVal Loss:\t2.4446\tAccuracy:\t0.1882\tF1:\t0.1435 *\n",
      "3 / 30: Train Loss:\t2.1388\tVal Loss:\t2.2251\tAccuracy:\t0.2626\tF1:\t0.2000 *\n",
      "4 / 30: Train Loss:\t1.8230\tVal Loss:\t2.0675\tAccuracy:\t0.3173\tF1:\t0.2458 *\n",
      "5 / 30: Train Loss:\t1.5114\tVal Loss:\t1.9606\tAccuracy:\t0.3457\tF1:\t0.2740 *\n",
      "6 / 30: Train Loss:\t1.1901\tVal Loss:\t1.9346\tAccuracy:\t0.3829\tF1:\t0.3226 *\n",
      "7 / 30: Train Loss:\t0.8686\tVal Loss:\t1.9646\tAccuracy:\t0.3786\tF1:\t0.3321 *\n",
      "8 / 30: Train Loss:\t0.5790\tVal Loss:\t2.0049\tAccuracy:\t0.3764\tF1:\t0.3349 *\n",
      "9 / 30: Train Loss:\t0.3521\tVal Loss:\t2.0475\tAccuracy:\t0.3851\tF1:\t0.3539 *\n",
      "10 / 30: Train Loss:\t0.2136\tVal Loss:\t2.0648\tAccuracy:\t0.4026\tF1:\t0.3692 *\n",
      "11 / 30: Train Loss:\t0.1346\tVal Loss:\t2.0773\tAccuracy:\t0.3632\tF1:\t0.3357\n",
      "12 / 30: Train Loss:\t0.0831\tVal Loss:\t2.0891\tAccuracy:\t0.3829\tF1:\t0.3366\n",
      "13 / 30: Train Loss:\t0.0571\tVal Loss:\t2.0997\tAccuracy:\t0.3851\tF1:\t0.3360\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.44      0.36      0.40        67\n",
      "               anecdote       0.69      0.58      0.63        43\n",
      "         cherry picking       0.41      0.39      0.40        56\n",
      "      conspiracy theory       0.49      0.56      0.52        39\n",
      "           fake experts       0.17      0.08      0.11        12\n",
      "           false choice       0.25      0.23      0.24        13\n",
      "      false equivalence       0.09      0.07      0.08        14\n",
      "impossible expectations       0.54      0.35      0.43        37\n",
      "      misrepresentation       0.24      0.42      0.30        38\n",
      "     oversimplification       0.81      0.61      0.70        36\n",
      "           single cause       0.42      0.44      0.43        57\n",
      "     slothful induction       0.16      0.22      0.19        45\n",
      "\n",
      "               accuracy                           0.40       457\n",
      "              macro avg       0.39      0.36      0.37       457\n",
      "           weighted avg       0.43      0.40      0.41       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.42      0.38      0.40        37\n",
      "               anecdote       0.68      0.71      0.69        24\n",
      "         cherry picking       0.42      0.32      0.36        31\n",
      "      conspiracy theory       0.48      0.45      0.47        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.20      0.14      0.17         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.42      0.24      0.30        21\n",
      "      misrepresentation       0.39      0.55      0.45        22\n",
      "     oversimplification       0.57      0.40      0.47        20\n",
      "           single cause       0.38      0.44      0.41        32\n",
      "     slothful induction       0.15      0.28      0.19        25\n",
      "\n",
      "               accuracy                           0.38       256\n",
      "              macro avg       0.34      0.33      0.33       256\n",
      "           weighted avg       0.40      0.38      0.38       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875, 0.40234375, 0.3828125], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861, 0.33382669187419745, 0.326110292563663], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967, 0.44638949671772427, 0.4026258205689278], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029, 0.3976216398668326, 0.36916333551720854], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4831\tVal Loss:\t2.4771\tAccuracy:\t0.1247\tF1:\t0.0185 *\n",
      "2 / 30: Train Loss:\t2.4729\tVal Loss:\t2.4660\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "3 / 30: Train Loss:\t2.4631\tVal Loss:\t2.4561\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "4 / 30: Train Loss:\t2.4535\tVal Loss:\t2.4472\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.12      1.00      0.22        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.12       457\n",
      "              macro avg       0.01      0.08      0.02       457\n",
      "           weighted avg       0.02      0.12      0.03       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.12      1.00      0.22        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.12       256\n",
      "              macro avg       0.01      0.08      0.02       256\n",
      "           weighted avg       0.02      0.12      0.03       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875, 0.40234375, 0.3828125, 0.125], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861, 0.33382669187419745, 0.326110292563663, 0.018518518518518517], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967, 0.44638949671772427, 0.4026258205689278, 0.12472647702407003], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029, 0.3976216398668326, 0.36916333551720854, 0.01848249027237354], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-base, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.4831\tVal Loss:\t2.4770\tAccuracy:\t0.1247\tF1:\t0.0185 *\n",
      "2 / 30: Train Loss:\t2.4728\tVal Loss:\t2.4659\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "3 / 30: Train Loss:\t2.4629\tVal Loss:\t2.4560\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "4 / 30: Train Loss:\t2.4533\tVal Loss:\t2.4470\tAccuracy:\t0.1247\tF1:\t0.0185\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.00      0.00      0.00        56\n",
      "      conspiracy theory       0.00      0.00      0.00        39\n",
      "           fake experts       0.00      0.00      0.00        12\n",
      "           false choice       0.00      0.00      0.00        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.00      0.00      0.00        37\n",
      "      misrepresentation       0.00      0.00      0.00        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.12      1.00      0.22        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.12       457\n",
      "              macro avg       0.01      0.08      0.02       457\n",
      "           weighted avg       0.02      0.12      0.03       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.00      0.00      0.00        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.00      0.00      0.00        31\n",
      "      conspiracy theory       0.00      0.00      0.00        22\n",
      "           fake experts       0.00      0.00      0.00         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.00      0.00      0.00        21\n",
      "      misrepresentation       0.00      0.00      0.00        22\n",
      "     oversimplification       0.00      0.00      0.00        20\n",
      "           single cause       0.12      1.00      0.22        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.12       256\n",
      "              macro avg       0.01      0.08      0.02       256\n",
      "           weighted avg       0.02      0.12      0.03       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875, 0.40234375, 0.3828125, 0.125, 0.125], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861, 0.33382669187419745, 0.326110292563663, 0.018518518518518517, 0.018518518518518517], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967, 0.44638949671772427, 0.4026258205689278, 0.12472647702407003, 0.12472647702407003], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029, 0.3976216398668326, 0.36916333551720854, 0.01848249027237354, 0.01848249027237354], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t21.8202\tVal Loss:\t2.4792\tAccuracy:\t0.1050\tF1:\t0.0430 *\n",
      "2 / 30: Train Loss:\t21.5403\tVal Loss:\t2.4746\tAccuracy:\t0.1050\tF1:\t0.0468 *\n",
      "3 / 30: Train Loss:\t21.3193\tVal Loss:\t2.4705\tAccuracy:\t0.1116\tF1:\t0.0517 *\n",
      "4 / 30: Train Loss:\t21.2921\tVal Loss:\t2.4683\tAccuracy:\t0.1204\tF1:\t0.0603 *\n",
      "5 / 30: Train Loss:\t21.1363\tVal Loss:\t2.4666\tAccuracy:\t0.1138\tF1:\t0.0603\n",
      "6 / 30: Train Loss:\t21.1976\tVal Loss:\t2.4650\tAccuracy:\t0.1204\tF1:\t0.0652 *\n",
      "7 / 30: Train Loss:\t21.2473\tVal Loss:\t2.4629\tAccuracy:\t0.1204\tF1:\t0.0752 *\n",
      "8 / 30: Train Loss:\t20.9751\tVal Loss:\t2.4610\tAccuracy:\t0.1313\tF1:\t0.0893 *\n",
      "9 / 30: Train Loss:\t20.9785\tVal Loss:\t2.4598\tAccuracy:\t0.1313\tF1:\t0.0832\n",
      "10 / 30: Train Loss:\t21.0905\tVal Loss:\t2.4594\tAccuracy:\t0.1291\tF1:\t0.0843\n",
      "11 / 30: Train Loss:\t20.9729\tVal Loss:\t2.4587\tAccuracy:\t0.1204\tF1:\t0.0758\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.23      0.16      0.19        67\n",
      "               anecdote       0.00      0.00      0.00        43\n",
      "         cherry picking       0.23      0.09      0.13        56\n",
      "      conspiracy theory       0.11      0.49      0.18        39\n",
      "           fake experts       0.08      0.08      0.08        12\n",
      "           false choice       0.33      0.08      0.12        13\n",
      "      false equivalence       0.00      0.00      0.00        14\n",
      "impossible expectations       0.11      0.35      0.17        37\n",
      "      misrepresentation       0.15      0.26      0.19        38\n",
      "     oversimplification       0.00      0.00      0.00        36\n",
      "           single cause       0.00      0.00      0.00        57\n",
      "     slothful induction       0.00      0.00      0.00        45\n",
      "\n",
      "               accuracy                           0.13       457\n",
      "              macro avg       0.10      0.13      0.09       457\n",
      "           weighted avg       0.10      0.13      0.10       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.18      0.11      0.14        37\n",
      "               anecdote       0.00      0.00      0.00        24\n",
      "         cherry picking       0.10      0.06      0.08        31\n",
      "      conspiracy theory       0.08      0.32      0.12        22\n",
      "           fake experts       0.08      0.14      0.11         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.00      0.00      0.00         8\n",
      "impossible expectations       0.11      0.33      0.17        21\n",
      "      misrepresentation       0.09      0.14      0.11        22\n",
      "     oversimplification       0.25      0.05      0.08        20\n",
      "           single cause       0.00      0.00      0.00        32\n",
      "     slothful induction       0.00      0.00      0.00        25\n",
      "\n",
      "               accuracy                           0.10       256\n",
      "              macro avg       0.07      0.10      0.07       256\n",
      "           weighted avg       0.08      0.10      0.07       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875, 0.40234375, 0.3828125, 0.125, 0.125, 0.09765625], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861, 0.33382669187419745, 0.326110292563663, 0.018518518518518517, 0.018518518518518517, 0.06675012158430622], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967, 0.44638949671772427, 0.4026258205689278, 0.12472647702407003, 0.12472647702407003, 0.13129102844638948], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029, 0.3976216398668326, 0.36916333551720854, 0.01848249027237354, 0.01848249027237354, 0.08927427380230585], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-v2-xlarge']}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t21.8170\tVal Loss:\t2.4787\tAccuracy:\t0.1028\tF1:\t0.0414 *\n",
      "2 / 30: Train Loss:\t21.5306\tVal Loss:\t2.4738\tAccuracy:\t0.1050\tF1:\t0.0467 *\n",
      "3 / 30: Train Loss:\t21.3093\tVal Loss:\t2.4694\tAccuracy:\t0.1138\tF1:\t0.0552 *\n",
      "4 / 30: Train Loss:\t21.2677\tVal Loss:\t2.4671\tAccuracy:\t0.1182\tF1:\t0.0605 *\n",
      "5 / 30: Train Loss:\t21.1078\tVal Loss:\t2.4653\tAccuracy:\t0.1182\tF1:\t0.0633 *\n",
      "6 / 30: Train Loss:\t21.1736\tVal Loss:\t2.4634\tAccuracy:\t0.1247\tF1:\t0.0772 *\n",
      "7 / 30: Train Loss:\t21.2132\tVal Loss:\t2.4605\tAccuracy:\t0.1335\tF1:\t0.0838 *\n",
      "8 / 30: Train Loss:\t20.9446\tVal Loss:\t2.4580\tAccuracy:\t0.1291\tF1:\t0.0816\n",
      "9 / 30: Train Loss:\t20.9299\tVal Loss:\t2.4562\tAccuracy:\t0.1357\tF1:\t0.0920 *\n",
      "10 / 30: Train Loss:\t21.0513\tVal Loss:\t2.4555\tAccuracy:\t0.1335\tF1:\t0.0921 *\n",
      "11 / 30: Train Loss:\t20.8897\tVal Loss:\t2.4534\tAccuracy:\t0.1335\tF1:\t0.0928 *\n",
      "12 / 30: Train Loss:\t20.8101\tVal Loss:\t2.4517\tAccuracy:\t0.1225\tF1:\t0.0858\n",
      "13 / 30: Train Loss:\t21.0208\tVal Loss:\t2.4491\tAccuracy:\t0.1225\tF1:\t0.0888\n",
      "14 / 30: Train Loss:\t20.7791\tVal Loss:\t2.4455\tAccuracy:\t0.1313\tF1:\t0.0940 *\n",
      "15 / 30: Train Loss:\t20.7034\tVal Loss:\t2.4432\tAccuracy:\t0.1269\tF1:\t0.0925\n",
      "16 / 30: Train Loss:\t20.5754\tVal Loss:\t2.4392\tAccuracy:\t0.1269\tF1:\t0.0951 *\n",
      "17 / 30: Train Loss:\t20.5031\tVal Loss:\t2.4322\tAccuracy:\t0.1357\tF1:\t0.1002 *\n",
      "18 / 30: Train Loss:\t20.4205\tVal Loss:\t2.4229\tAccuracy:\t0.1597\tF1:\t0.1149 *\n",
      "19 / 30: Train Loss:\t20.3494\tVal Loss:\t2.4132\tAccuracy:\t0.1641\tF1:\t0.1202 *\n",
      "20 / 30: Train Loss:\t20.0338\tVal Loss:\t2.3991\tAccuracy:\t0.1904\tF1:\t0.1435 *\n",
      "21 / 30: Train Loss:\t20.1470\tVal Loss:\t2.3860\tAccuracy:\t0.2101\tF1:\t0.1672 *\n",
      "22 / 30: Train Loss:\t19.6636\tVal Loss:\t2.3654\tAccuracy:\t0.2407\tF1:\t0.1959 *\n",
      "23 / 30: Train Loss:\t19.3172\tVal Loss:\t2.3347\tAccuracy:\t0.2779\tF1:\t0.2390 *\n",
      "24 / 30: Train Loss:\t19.0833\tVal Loss:\t2.2982\tAccuracy:\t0.3107\tF1:\t0.2776 *\n",
      "25 / 30: Train Loss:\t18.2388\tVal Loss:\t2.2312\tAccuracy:\t0.3348\tF1:\t0.2915 *\n",
      "26 / 30: Train Loss:\t17.6349\tVal Loss:\t2.1608\tAccuracy:\t0.3764\tF1:\t0.3218 *\n",
      "27 / 30: Train Loss:\t16.8214\tVal Loss:\t2.0934\tAccuracy:\t0.4026\tF1:\t0.3415 *\n",
      "28 / 30: Train Loss:\t15.7898\tVal Loss:\t2.0261\tAccuracy:\t0.4311\tF1:\t0.3742 *\n",
      "29 / 30: Train Loss:\t15.0930\tVal Loss:\t1.9576\tAccuracy:\t0.4551\tF1:\t0.3943 *\n",
      "30 / 30: Train Loss:\t14.1072\tVal Loss:\t1.8974\tAccuracy:\t0.4792\tF1:\t0.4317 *\n",
      "best (higgest macro f1-score) val results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.49      0.51      0.50        67\n",
      "               anecdote       0.83      0.81      0.82        43\n",
      "         cherry picking       0.40      0.52      0.45        56\n",
      "      conspiracy theory       0.52      0.72      0.60        39\n",
      "           fake experts       0.23      0.67      0.34        12\n",
      "           false choice       0.23      0.38      0.29        13\n",
      "      false equivalence       0.08      0.07      0.08        14\n",
      "impossible expectations       0.58      0.30      0.39        37\n",
      "      misrepresentation       0.53      0.24      0.33        38\n",
      "     oversimplification       0.51      0.50      0.51        36\n",
      "           single cause       0.58      0.49      0.53        57\n",
      "     slothful induction       0.41      0.29      0.34        45\n",
      "\n",
      "               accuracy                           0.48       457\n",
      "              macro avg       0.45      0.46      0.43       457\n",
      "           weighted avg       0.50      0.48      0.48       457\n",
      "\n",
      "test results:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             ad hominem       0.61      0.46      0.52        37\n",
      "               anecdote       0.72      0.75      0.73        24\n",
      "         cherry picking       0.37      0.52      0.43        31\n",
      "      conspiracy theory       0.45      0.59      0.51        22\n",
      "           fake experts       0.27      0.86      0.41         7\n",
      "           false choice       0.00      0.00      0.00         7\n",
      "      false equivalence       0.14      0.25      0.18         8\n",
      "impossible expectations       0.65      0.52      0.58        21\n",
      "      misrepresentation       0.33      0.09      0.14        22\n",
      "     oversimplification       0.42      0.55      0.48        20\n",
      "           single cause       0.50      0.41      0.45        32\n",
      "     slothful induction       0.25      0.08      0.12        25\n",
      "\n",
      "               accuracy                           0.43       256\n",
      "              macro avg       0.39      0.42      0.38       256\n",
      "           weighted avg       0.45      0.43      0.42       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.484375, 0.484375, 0.62890625, 0.66796875, 0.17578125, 0.38671875, 0.45703125, 0.46875, 0.140625, 0.13671875, 0.40234375, 0.3828125, 0.125, 0.125, 0.09765625, 0.43359375], 'test_f1': [0.3646159243044012, 0.3661463940389753, 0.6026852104346269, 0.6365439651652807, 0.09888484884250909, 0.3010418468999964, 0.43594254347056466, 0.4383035758990264, 0.07107360701295194, 0.06668783249456861, 0.33382669187419745, 0.326110292563663, 0.018518518518518517, 0.018518518518518517, 0.06675012158430622, 0.38043098366833], 'eval_acc': [0.5164113785557987, 0.5142231947483589, 0.6892778993435449, 0.6827133479212254, 0.1838074398249453, 0.4113785557986871, 0.47921225382932164, 0.5076586433260394, 0.14660831509846828, 0.12910284463894967, 0.44638949671772427, 0.4026258205689278, 0.12472647702407003, 0.12472647702407003, 0.13129102844638948, 0.47921225382932164], 'eval_f1': [0.38902208831758595, 0.3931182317201232, 0.673935585146565, 0.6717652146645715, 0.1112172005853533, 0.3267728410007973, 0.48751567457574757, 0.5145796115643907, 0.08397386617461318, 0.07893648231792029, 0.3976216398668326, 0.36916333551720854, 0.01848249027237354, 0.01848249027237354, 0.08927427380230585, 0.43166963654983653], 'rank, alpha': [8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16, 8, 16], 'model': ['bert-base-uncased', 'bert-base-uncased', 'roberta-large', 'roberta-large', 'gpt2', 'gpt2', 'bigscience/bloom-560m', 'bigscience/bloom-560m', 'facebook/opt-350m', 'facebook/opt-350m', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-1.3B', 'microsoft/deberta-base', 'microsoft/deberta-base', 'microsoft/deberta-v2-xlarge', 'microsoft/deberta-v2-xlarge']}\n",
      "### ### ### ### ### ### ### ### ### ### \n"
     ]
    }
   ],
   "source": [
    "alphas = [8, 16]\n",
    "ranks = [8, 16]\n",
    "\n",
    "for model_checkpoint in best_config.keys():\n",
    "    for a,r in zip(alphas, ranks):\n",
    "        print(f'Grid search {model_checkpoint}, learning rate {best_config[model_checkpoint][\"lr\"]}')\n",
    "        data = ClimateDataset(model_to_train=4,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=32)\n",
    "        data.setup_dataloaders()\n",
    "        model = ClassificationModel(model_checkpoint=data.model_checkpoint,\n",
    "                                    num_labels=data.num_labels,\n",
    "                                    lora=True,\n",
    "                                    alpha=a,\n",
    "                                    r=r,\n",
    "                                    dropout=0.0)\n",
    "        trainer = Engine(epochs=30,labels=data.labels)\n",
    "        trainer.model = model.model\n",
    "        trainer.dataset_encoded = data.dataset_encoded\n",
    "        test_acc, test_f1, eval_acc, eval_f1 = trainer.run(**best_config[model_checkpoint],\n",
    "                                                            train_dataloader=data.train_dataloader,\n",
    "                                                            eval_dataloader=data.eval_dataloader,\n",
    "                                                            test_dataloader=data.test_dataloader,\n",
    "                                                            early_stop=3)\n",
    "        results['test_acc'].append(test_acc)\n",
    "        results['test_f1'].append(test_f1)\n",
    "        results['eval_acc'].append(eval_acc)\n",
    "        results['eval_f1'].append(eval_f1)\n",
    "        results['rank, alpha'].append(r)\n",
    "        results['model'].append(model_checkpoint)\n",
    "        print('### '*10)\n",
    "        print(results)\n",
    "        print('### '*10)\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        del data, model, trainer\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>eval_acc</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>rank, alpha</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.364616</td>\n",
       "      <td>0.516411</td>\n",
       "      <td>0.389022</td>\n",
       "      <td>8</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.366146</td>\n",
       "      <td>0.514223</td>\n",
       "      <td>0.393118</td>\n",
       "      <td>16</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628906</td>\n",
       "      <td>0.602685</td>\n",
       "      <td>0.689278</td>\n",
       "      <td>0.673936</td>\n",
       "      <td>8</td>\n",
       "      <td>roberta-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.667969</td>\n",
       "      <td>0.636544</td>\n",
       "      <td>0.682713</td>\n",
       "      <td>0.671765</td>\n",
       "      <td>16</td>\n",
       "      <td>roberta-large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.098885</td>\n",
       "      <td>0.183807</td>\n",
       "      <td>0.111217</td>\n",
       "      <td>8</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.301042</td>\n",
       "      <td>0.411379</td>\n",
       "      <td>0.326773</td>\n",
       "      <td>16</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.457031</td>\n",
       "      <td>0.435943</td>\n",
       "      <td>0.479212</td>\n",
       "      <td>0.487516</td>\n",
       "      <td>8</td>\n",
       "      <td>bigscience/bloom-560m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.438304</td>\n",
       "      <td>0.507659</td>\n",
       "      <td>0.514580</td>\n",
       "      <td>16</td>\n",
       "      <td>bigscience/bloom-560m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.071074</td>\n",
       "      <td>0.146608</td>\n",
       "      <td>0.083974</td>\n",
       "      <td>8</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.136719</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>0.078936</td>\n",
       "      <td>16</td>\n",
       "      <td>facebook/opt-350m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.402344</td>\n",
       "      <td>0.333827</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>0.397622</td>\n",
       "      <td>8</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.326110</td>\n",
       "      <td>0.402626</td>\n",
       "      <td>0.369163</td>\n",
       "      <td>16</td>\n",
       "      <td>EleutherAI/gpt-neo-1.3B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.124726</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>8</td>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.124726</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>16</td>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.097656</td>\n",
       "      <td>0.066750</td>\n",
       "      <td>0.131291</td>\n",
       "      <td>0.089274</td>\n",
       "      <td>8</td>\n",
       "      <td>microsoft/deberta-v2-xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.433594</td>\n",
       "      <td>0.380431</td>\n",
       "      <td>0.479212</td>\n",
       "      <td>0.431670</td>\n",
       "      <td>16</td>\n",
       "      <td>microsoft/deberta-v2-xlarge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_acc   test_f1  eval_acc   eval_f1  rank, alpha  \\\n",
       "0   0.484375  0.364616  0.516411  0.389022            8   \n",
       "1   0.484375  0.366146  0.514223  0.393118           16   \n",
       "2   0.628906  0.602685  0.689278  0.673936            8   \n",
       "3   0.667969  0.636544  0.682713  0.671765           16   \n",
       "4   0.175781  0.098885  0.183807  0.111217            8   \n",
       "5   0.386719  0.301042  0.411379  0.326773           16   \n",
       "6   0.457031  0.435943  0.479212  0.487516            8   \n",
       "7   0.468750  0.438304  0.507659  0.514580           16   \n",
       "8   0.140625  0.071074  0.146608  0.083974            8   \n",
       "9   0.136719  0.066688  0.129103  0.078936           16   \n",
       "10  0.402344  0.333827  0.446389  0.397622            8   \n",
       "11  0.382812  0.326110  0.402626  0.369163           16   \n",
       "12  0.125000  0.018519  0.124726  0.018482            8   \n",
       "13  0.125000  0.018519  0.124726  0.018482           16   \n",
       "14  0.097656  0.066750  0.131291  0.089274            8   \n",
       "15  0.433594  0.380431  0.479212  0.431670           16   \n",
       "\n",
       "                          model  \n",
       "0             bert-base-uncased  \n",
       "1             bert-base-uncased  \n",
       "2                 roberta-large  \n",
       "3                 roberta-large  \n",
       "4                          gpt2  \n",
       "5                          gpt2  \n",
       "6         bigscience/bloom-560m  \n",
       "7         bigscience/bloom-560m  \n",
       "8             facebook/opt-350m  \n",
       "9             facebook/opt-350m  \n",
       "10      EleutherAI/gpt-neo-1.3B  \n",
       "11      EleutherAI/gpt-neo-1.3B  \n",
       "12       microsoft/deberta-base  \n",
       "13       microsoft/deberta-base  \n",
       "14  microsoft/deberta-v2-xlarge  \n",
       "15  microsoft/deberta-v2-xlarge  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
