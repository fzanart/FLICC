{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/software/'\n",
    "import sys\n",
    "import gc\n",
    "# assuming data, models, engine in flicc directory:\n",
    "flicc_path = os.path.join(os.path.dirname(os.getcwd()), '')\n",
    "sys.path.append(flicc_path)\n",
    "import torch\n",
    "from data import ClimateDataset\n",
    "from models import ClassificationModel\n",
    "from engine import Engine\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoints=['EleutherAI/gpt-neo-1.3B', 'bigscience/bloom-560m', 'microsoft/deberta-v2-xlarge'] #'EleutherAI/gpt-j-6B', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'test_acc':[],\n",
    "           'test_f1':[],\n",
    "           'eval_acc':[],\n",
    "           'eval_f1':[],\n",
    "           'lr':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ceaf7c59ba4833afb8836c47e1d183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917807a38b3e49a1965bcbc9410465b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dcdf1874224c7ca4ee59108eba1df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82da25e013f5412e8264cedcf1c69ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9814f7d52d4ed68ef9a87b58d3e1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854f10457cd7436e96a91a60ec9dc38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4395de250c349bd999b06f67c40ab62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9381c7fc4ce415db869e0524ce86a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c66452f519438d9e444479295a365f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6039\tVal Loss:\t0.4725\tAccuracy:\t0.7965\tF1:\t0.6561 *\n",
      "2 / 30: Train Loss:\t0.2434\tVal Loss:\t0.5836\tAccuracy:\t0.7943\tF1:\t0.6828 *\n",
      "3 / 30: Train Loss:\t0.1067\tVal Loss:\t0.5921\tAccuracy:\t0.7549\tF1:\t0.6627\n",
      "4 / 30: Train Loss:\t0.0569\tVal Loss:\t1.2122\tAccuracy:\t0.5711\tF1:\t0.5643\n",
      "5 / 30: Train Loss:\t0.0873\tVal Loss:\t0.6382\tAccuracy:\t0.7330\tF1:\t0.6765\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.69      0.39      0.49       119\n",
      "      struct       0.81      0.94      0.87       338\n",
      "\n",
      "    accuracy                           0.79       457\n",
      "   macro avg       0.75      0.66      0.68       457\n",
      "weighted avg       0.78      0.79      0.77       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.55      0.31      0.40        67\n",
      "      struct       0.79      0.91      0.85       189\n",
      "\n",
      "    accuracy                           0.75       256\n",
      "   macro avg       0.67      0.61      0.62       256\n",
      "weighted avg       0.73      0.75      0.73       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625], 'test_f1': [0.6226044226044227], 'eval_acc': [0.7943107221006565], 'eval_f1': [0.6827513883965497], 'lr': [1e-05]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9190894e687b422bb21d42e0b943a2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6895\tVal Loss:\t0.4433\tAccuracy:\t0.7987\tF1:\t0.6870 *\n",
      "2 / 30: Train Loss:\t0.4122\tVal Loss:\t0.4394\tAccuracy:\t0.8096\tF1:\t0.7549 *\n",
      "3 / 30: Train Loss:\t0.2080\tVal Loss:\t0.5369\tAccuracy:\t0.7943\tF1:\t0.7151\n",
      "4 / 30: Train Loss:\t0.0816\tVal Loss:\t0.6084\tAccuracy:\t0.7877\tF1:\t0.7106\n",
      "5 / 30: Train Loss:\t0.1022\tVal Loss:\t0.6202\tAccuracy:\t0.7965\tF1:\t0.7208\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.63      0.65      0.64       119\n",
      "      struct       0.87      0.87      0.87       338\n",
      "\n",
      "    accuracy                           0.81       457\n",
      "   macro avg       0.75      0.76      0.75       457\n",
      "weighted avg       0.81      0.81      0.81       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.57      0.58      0.58        67\n",
      "      struct       0.85      0.85      0.85       189\n",
      "\n",
      "    accuracy                           0.78       256\n",
      "   macro avg       0.71      0.71      0.71       256\n",
      "weighted avg       0.78      0.78      0.78       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375], 'test_f1': [0.6226044226044227, 0.7132920719127616], 'eval_acc': [0.7943107221006565, 0.8096280087527352], 'eval_f1': [0.6827513883965497, 0.7548661162935516], 'lr': [1e-05, 5e-05]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c30476d84eb4a6caa9a4291ee9a4e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6923\tVal Loss:\t0.4209\tAccuracy:\t0.8140\tF1:\t0.6970 *\n",
      "2 / 30: Train Loss:\t0.3206\tVal Loss:\t0.4470\tAccuracy:\t0.8184\tF1:\t0.7372 *\n",
      "3 / 30: Train Loss:\t0.3018\tVal Loss:\t1.6330\tAccuracy:\t0.4420\tF1:\t0.4411\n",
      "4 / 30: Train Loss:\t0.3428\tVal Loss:\t0.6431\tAccuracy:\t0.7287\tF1:\t0.6891\n",
      "5 / 30: Train Loss:\t0.1495\tVal Loss:\t0.8439\tAccuracy:\t0.8074\tF1:\t0.6956\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.71      0.50      0.59       119\n",
      "      struct       0.84      0.93      0.88       338\n",
      "\n",
      "    accuracy                           0.82       457\n",
      "   macro avg       0.78      0.72      0.74       457\n",
      "weighted avg       0.81      0.82      0.81       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.59      0.39      0.47        67\n",
      "      struct       0.81      0.90      0.85       189\n",
      "\n",
      "    accuracy                           0.77       256\n",
      "   macro avg       0.70      0.65      0.66       256\n",
      "weighted avg       0.75      0.77      0.75       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983], 'lr': [1e-05, 5e-05, 0.0001]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search EleutherAI/gpt-neo-1.3B, learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t1.2489\tVal Loss:\t0.5963\tAccuracy:\t0.7396\tF1:\t0.4252 *\n",
      "2 / 30: Train Loss:\t0.6287\tVal Loss:\t0.5840\tAccuracy:\t0.7440\tF1:\t0.4428 *\n",
      "3 / 30: Train Loss:\t0.4367\tVal Loss:\t0.9823\tAccuracy:\t0.7681\tF1:\t0.5581 *\n",
      "4 / 30: Train Loss:\t0.2146\tVal Loss:\t0.9252\tAccuracy:\t0.7571\tF1:\t0.6144 *\n",
      "5 / 30: Train Loss:\t0.1276\tVal Loss:\t1.1665\tAccuracy:\t0.7287\tF1:\t0.6478 *\n",
      "6 / 30: Train Loss:\t0.1141\tVal Loss:\t1.1944\tAccuracy:\t0.6543\tF1:\t0.6106\n",
      "7 / 30: Train Loss:\t0.1421\tVal Loss:\t1.2166\tAccuracy:\t0.6586\tF1:\t0.6180\n",
      "8 / 30: Train Loss:\t0.1096\tVal Loss:\t1.4009\tAccuracy:\t0.7068\tF1:\t0.6107\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.48      0.48      0.48       119\n",
      "      struct       0.82      0.82      0.82       338\n",
      "\n",
      "    accuracy                           0.73       457\n",
      "   macro avg       0.65      0.65      0.65       457\n",
      "weighted avg       0.73      0.73      0.73       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.43      0.42      0.42        67\n",
      "      struct       0.80      0.80      0.80       189\n",
      "\n",
      "    accuracy                           0.70       256\n",
      "   macro avg       0.61      0.61      0.61       256\n",
      "weighted avg       0.70      0.70      0.70       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668], 'lr': [1e-05, 5e-05, 0.0001, 0.001]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cd5b48eee84886ad1a8e2e7c7d4af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98a374f482f4668a5c3bb39df1c3da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a920809e2210450e8c71dc7427bde03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff36d25cbe524decb0f391e051053b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048789e4c92b45e2b17a136b373e17c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdd6214ff2943428f8dc29359c8249e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb567b8a8b64ccdb331e7a641382007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4345de1c63db42829e046e3367ea39de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t1.2349\tVal Loss:\t0.4349\tAccuracy:\t0.7987\tF1:\t0.7263 *\n",
      "2 / 30: Train Loss:\t0.2699\tVal Loss:\t0.5054\tAccuracy:\t0.8337\tF1:\t0.7635 *\n",
      "3 / 30: Train Loss:\t0.2722\tVal Loss:\t1.0108\tAccuracy:\t0.8293\tF1:\t0.7207\n",
      "4 / 30: Train Loss:\t0.0741\tVal Loss:\t0.5129\tAccuracy:\t0.8359\tF1:\t0.7802 *\n",
      "5 / 30: Train Loss:\t0.0416\tVal Loss:\t0.7441\tAccuracy:\t0.8468\tF1:\t0.7918 *\n",
      "6 / 30: Train Loss:\t0.0183\tVal Loss:\t0.7027\tAccuracy:\t0.8206\tF1:\t0.7786\n",
      "7 / 30: Train Loss:\t0.0092\tVal Loss:\t0.7016\tAccuracy:\t0.8359\tF1:\t0.7864\n",
      "8 / 30: Train Loss:\t0.0139\tVal Loss:\t0.7043\tAccuracy:\t0.8490\tF1:\t0.7874\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.74      0.64      0.68       119\n",
      "      struct       0.88      0.92      0.90       338\n",
      "\n",
      "    accuracy                           0.85       457\n",
      "   macro avg       0.81      0.78      0.79       457\n",
      "weighted avg       0.84      0.85      0.84       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.68      0.57      0.62        67\n",
      "      struct       0.85      0.90      0.88       189\n",
      "\n",
      "    accuracy                           0.82       256\n",
      "   macro avg       0.77      0.74      0.75       256\n",
      "weighted avg       0.81      0.82      0.81       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8d5200b6b94d3989e209b091e401a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t2.3121\tVal Loss:\t0.5016\tAccuracy:\t0.7593\tF1:\t0.6288 *\n",
      "2 / 30: Train Loss:\t0.3576\tVal Loss:\t0.6745\tAccuracy:\t0.8009\tF1:\t0.6635 *\n",
      "3 / 30: Train Loss:\t0.5050\tVal Loss:\t1.1716\tAccuracy:\t0.8096\tF1:\t0.7587 *\n",
      "4 / 30: Train Loss:\t0.3210\tVal Loss:\t1.5493\tAccuracy:\t0.8009\tF1:\t0.6352\n",
      "5 / 30: Train Loss:\t0.1811\tVal Loss:\t0.8372\tAccuracy:\t0.7834\tF1:\t0.7132\n",
      "6 / 30: Train Loss:\t0.0505\tVal Loss:\t1.1329\tAccuracy:\t0.7877\tF1:\t0.6971\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.62      0.67      0.65       119\n",
      "      struct       0.88      0.86      0.87       338\n",
      "\n",
      "    accuracy                           0.81       457\n",
      "   macro avg       0.75      0.77      0.76       457\n",
      "weighted avg       0.81      0.81      0.81       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.60      0.61      0.61        67\n",
      "      struct       0.86      0.86      0.86       189\n",
      "\n",
      "    accuracy                           0.79       256\n",
      "   macro avg       0.73      0.73      0.73       256\n",
      "weighted avg       0.79      0.79      0.79       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ebd61a67714a46baa896e1fc20cc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t3.2166\tVal Loss:\t0.5872\tAccuracy:\t0.7418\tF1:\t0.7042 *\n",
      "2 / 30: Train Loss:\t0.4308\tVal Loss:\t0.5799\tAccuracy:\t0.7396\tF1:\t0.7091 *\n",
      "3 / 30: Train Loss:\t0.3143\tVal Loss:\t1.5433\tAccuracy:\t0.7877\tF1:\t0.6024\n",
      "4 / 30: Train Loss:\t0.2822\tVal Loss:\t0.8559\tAccuracy:\t0.8074\tF1:\t0.7553 *\n",
      "5 / 30: Train Loss:\t0.1695\tVal Loss:\t1.4949\tAccuracy:\t0.8249\tF1:\t0.7278\n",
      "6 / 30: Train Loss:\t0.1297\tVal Loss:\t1.6206\tAccuracy:\t0.7746\tF1:\t0.7404\n",
      "7 / 30: Train Loss:\t0.2391\tVal Loss:\t1.1835\tAccuracy:\t0.7921\tF1:\t0.7365\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.62      0.66      0.64       119\n",
      "      struct       0.88      0.86      0.87       338\n",
      "\n",
      "    accuracy                           0.81       457\n",
      "   macro avg       0.75      0.76      0.76       457\n",
      "weighted avg       0.81      0.81      0.81       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.57      0.63      0.60        67\n",
      "      struct       0.86      0.83      0.85       189\n",
      "\n",
      "    accuracy                           0.78       256\n",
      "   macro avg       0.72      0.73      0.72       256\n",
      "weighted avg       0.79      0.78      0.78       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875, 0.77734375], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749, 0.7210529334174456], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352, 0.8074398249452954], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656, 0.7552699479090599], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search bigscience/bloom-560m, learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BloomForSequenceClassification were not initialized from the model checkpoint at bigscience/bloom-560m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t14.5349\tVal Loss:\t16.6338\tAccuracy:\t0.7396\tF1:\t0.4252 *\n",
      "2 / 30: Train Loss:\t6.6603\tVal Loss:\t1.1317\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "3 / 30: Train Loss:\t0.8375\tVal Loss:\t0.7811\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "4 / 30: Train Loss:\t0.6024\tVal Loss:\t0.7398\tAccuracy:\t0.7702\tF1:\t0.6322 *\n",
      "5 / 30: Train Loss:\t0.4724\tVal Loss:\t0.7451\tAccuracy:\t0.7768\tF1:\t0.7037 *\n",
      "6 / 30: Train Loss:\t0.2492\tVal Loss:\t0.7080\tAccuracy:\t0.7615\tF1:\t0.7036\n",
      "7 / 30: Train Loss:\t0.1918\tVal Loss:\t0.9606\tAccuracy:\t0.7615\tF1:\t0.6895\n",
      "8 / 30: Train Loss:\t0.1738\tVal Loss:\t0.8603\tAccuracy:\t0.7527\tF1:\t0.6897\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.58      0.54      0.56       119\n",
      "      struct       0.84      0.86      0.85       338\n",
      "\n",
      "    accuracy                           0.78       457\n",
      "   macro avg       0.71      0.70      0.70       457\n",
      "weighted avg       0.77      0.78      0.77       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.41      0.46      0.44        67\n",
      "      struct       0.80      0.77      0.78       189\n",
      "\n",
      "    accuracy                           0.69       256\n",
      "   macro avg       0.61      0.61      0.61       256\n",
      "weighted avg       0.70      0.69      0.69       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875, 0.77734375, 0.6875], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749, 0.7210529334174456, 0.6102017510468215], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352, 0.8074398249452954, 0.7768052516411379], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656, 0.7552699479090599, 0.7036994660564455], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001, 0.001]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 1e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ed90f6e3a74df68a8e60d59fb7572c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44033aa3487343419e7115dbaea6862f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8a7b6946aa46e4ba497665bc89b7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spm.model:   0%|          | 0.00/2.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7986ae74a99e4effaa8c2c071d13b698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d35c82edfd74bcdbd1388ba09b554d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d362ef063cca460cb2aa655e009146c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29d6f8ac2ea4e08b7b56f9f582be6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.4862\tVal Loss:\t0.3669\tAccuracy:\t0.8228\tF1:\t0.7654 *\n",
      "2 / 30: Train Loss:\t0.3263\tVal Loss:\t0.3145\tAccuracy:\t0.8665\tF1:\t0.8281 *\n",
      "3 / 30: Train Loss:\t0.1904\tVal Loss:\t0.3806\tAccuracy:\t0.8643\tF1:\t0.8030\n",
      "4 / 30: Train Loss:\t0.1998\tVal Loss:\t0.4779\tAccuracy:\t0.8118\tF1:\t0.7165\n",
      "5 / 30: Train Loss:\t0.5844\tVal Loss:\t0.5729\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.74      0.76      0.75       119\n",
      "      struct       0.91      0.91      0.91       338\n",
      "\n",
      "    accuracy                           0.87       457\n",
      "   macro avg       0.83      0.83      0.83       457\n",
      "weighted avg       0.87      0.87      0.87       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.67      0.66      0.66        67\n",
      "      struct       0.88      0.88      0.88       189\n",
      "\n",
      "    accuracy                           0.82       256\n",
      "   macro avg       0.77      0.77      0.77       256\n",
      "weighted avg       0.82      0.82      0.82       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875, 0.77734375, 0.6875, 0.82421875], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749, 0.7210529334174456, 0.6102017510468215, 0.7714603130517588], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352, 0.8074398249452954, 0.7768052516411379, 0.8665207877461707], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656, 0.7552699479090599, 0.7036994660564455, 0.828124518320766], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001, 0.001, 1e-05]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 5e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12d698416df4140a8ec9b23c43c3c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/256 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6190\tVal Loss:\t0.6607\tAccuracy:\t0.7396\tF1:\t0.4252 *\n",
      "2 / 30: Train Loss:\t0.5885\tVal Loss:\t0.6134\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "3 / 30: Train Loss:\t0.5889\tVal Loss:\t0.6102\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "4 / 30: Train Loss:\t0.5895\tVal Loss:\t0.5918\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.00      0.00      0.00       119\n",
      "      struct       0.74      1.00      0.85       338\n",
      "\n",
      "    accuracy                           0.74       457\n",
      "   macro avg       0.37      0.50      0.43       457\n",
      "weighted avg       0.55      0.74      0.63       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.00      0.00      0.00        67\n",
      "      struct       0.74      1.00      0.85       189\n",
      "\n",
      "    accuracy                           0.74       256\n",
      "   macro avg       0.37      0.50      0.42       256\n",
      "weighted avg       0.55      0.74      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875, 0.77734375, 0.6875, 0.82421875, 0.73828125], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749, 0.7210529334174456, 0.6102017510468215, 0.7714603130517588, 0.4247191011235955], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352, 0.8074398249452954, 0.7768052516411379, 0.8665207877461707, 0.7396061269146609], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656, 0.7552699479090599, 0.7036994660564455, 0.828124518320766, 0.42515723270440253], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 0.0001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef84b6b6d3ae49839d1a301226c8b233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/457 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.6261\tVal Loss:\t0.5888\tAccuracy:\t0.7396\tF1:\t0.4252 *\n",
      "2 / 30: Train Loss:\t0.5840\tVal Loss:\t0.5834\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "3 / 30: Train Loss:\t0.5811\tVal Loss:\t0.5848\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "4 / 30: Train Loss:\t0.5842\tVal Loss:\t0.5837\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.00      0.00      0.00       119\n",
      "      struct       0.74      1.00      0.85       338\n",
      "\n",
      "    accuracy                           0.74       457\n",
      "   macro avg       0.37      0.50      0.43       457\n",
      "weighted avg       0.55      0.74      0.63       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.00      0.00      0.00        67\n",
      "      struct       0.74      1.00      0.85       189\n",
      "\n",
      "    accuracy                           0.74       256\n",
      "   macro avg       0.37      0.50      0.42       256\n",
      "weighted avg       0.55      0.74      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875, 0.77734375, 0.6875, 0.82421875, 0.73828125, 0.73828125], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749, 0.7210529334174456, 0.6102017510468215, 0.7714603130517588, 0.4247191011235955, 0.4247191011235955], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352, 0.8074398249452954, 0.7768052516411379, 0.8665207877461707, 0.7396061269146609, 0.7396061269146609], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656, 0.7552699479090599, 0.7036994660564455, 0.828124518320766, 0.42515723270440253, 0.42515723270440253], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001]}\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "Grid search microsoft/deberta-v2-xlarge, learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30: Train Loss:\t0.8361\tVal Loss:\t0.5845\tAccuracy:\t0.7396\tF1:\t0.4252 *\n",
      "2 / 30: Train Loss:\t0.5833\tVal Loss:\t0.5866\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "3 / 30: Train Loss:\t0.5802\tVal Loss:\t0.5843\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "4 / 30: Train Loss:\t0.5766\tVal Loss:\t0.5844\tAccuracy:\t0.7396\tF1:\t0.4252\n",
      "No improvement for 3 epochs. Stopping early.\n",
      "best (higgest macro f1-score) val results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.00      0.00      0.00       119\n",
      "      struct       0.74      1.00      0.85       338\n",
      "\n",
      "    accuracy                           0.74       457\n",
      "   macro avg       0.37      0.50      0.43       457\n",
      "weighted avg       0.55      0.74      0.63       457\n",
      "\n",
      "test results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bknow       0.00      0.00      0.00        67\n",
      "      struct       0.74      1.00      0.85       189\n",
      "\n",
      "    accuracy                           0.74       256\n",
      "   macro avg       0.37      0.50      0.42       256\n",
      "weighted avg       0.55      0.74      0.63       256\n",
      "\n",
      "### ### ### ### ### ### ### ### ### ### \n",
      "{'test_acc': [0.75390625, 0.77734375, 0.76953125, 0.703125, 0.81640625, 0.79296875, 0.77734375, 0.6875, 0.82421875, 0.73828125, 0.73828125, 0.73828125], 'test_f1': [0.6226044226044227, 0.7132920719127616, 0.6606681494462043, 0.6121212121212121, 0.7485317783769097, 0.7334119265153749, 0.7210529334174456, 0.6102017510468215, 0.7714603130517588, 0.4247191011235955, 0.4247191011235955, 0.4247191011235955], 'eval_acc': [0.7943107221006565, 0.8096280087527352, 0.8183807439824945, 0.7286652078774617, 0.8468271334792122, 0.8096280087527352, 0.8074398249452954, 0.7768052516411379, 0.8665207877461707, 0.7396061269146609, 0.7396061269146609, 0.7396061269146609], 'eval_f1': [0.6827513883965497, 0.7548661162935516, 0.7371980073856983, 0.6477798219879668, 0.7917643076602614, 0.7586692483717656, 0.7552699479090599, 0.7036994660564455, 0.828124518320766, 0.42515723270440253, 0.42515723270440253, 0.42515723270440253], 'lr': [1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001, 0.001, 1e-05, 5e-05, 0.0001, 0.001]}\n",
      "### ### ### ### ### ### ### ### ### ### \n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1.0e-5, 5.0e-5 ,1.0e-4]\n",
    "for model_checkpoint in model_checkpoints:\n",
    "    for lr in learning_rates:\n",
    "        print(f'Grid search {model_checkpoint}, learning rate {lr}')\n",
    "        data = ClimateDataset(model_to_train=1,model_checkpoint=model_checkpoint,dataset_url=flicc_path,batch_size=32)\n",
    "        data.setup_dataloaders()\n",
    "        model = ClassificationModel(model_checkpoint=data.model_checkpoint,num_labels=data.num_labels)\n",
    "        trainer = Engine(epochs=30,labels=data.labels)\n",
    "        trainer.model = model.model\n",
    "        test_acc, test_f1, eval_acc, eval_f1 = trainer.run(lr=lr,\n",
    "                                                            wd=0.0,\n",
    "                                                            train_dataloader=data.train_dataloader,\n",
    "                                                            eval_dataloader=data.eval_dataloader,\n",
    "                                                            test_dataloader=data.test_dataloader,\n",
    "                                                            # accumulation_steps=32,\n",
    "                                                            early_stop=3)\n",
    "        results['test_acc'].append(test_acc)\n",
    "        results['test_f1'].append(test_f1)\n",
    "        results['eval_acc'].append(eval_acc)\n",
    "        results['eval_f1'].append(eval_f1)\n",
    "        results['lr'].append(lr)\n",
    "        print('### '*10)\n",
    "        print(results)\n",
    "        print('### '*10)\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        del data, model, trainer\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
